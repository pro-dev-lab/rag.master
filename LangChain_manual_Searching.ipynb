{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1ë‹¨ê³„: íŒŒì¼ ì‹œìŠ¤í…œ ëª¨ë“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ ì œí•œ í•´ì œ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì¶œë ¥ ì œí•œ í•´ì œ ì„¤ì •\n",
    "import sys\n",
    "\n",
    "# IPython ì„¤ì • (ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œë§Œ ë™ì‘)\n",
    "try:\n",
    "    from IPython.core.getipython import get_ipython\n",
    "    ipython = get_ipython()\n",
    "    if ipython:\n",
    "        ipython.ast_node_interactivity = \"all\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# pandas ì¶œë ¥ ì œí•œ í•´ì œ (ìˆëŠ” ê²½ìš°)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "print(\"ì¶œë ¥ ì œí•œ í•´ì œ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_directory(root_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ë¥¼ ìŠ¤ìº”í•˜ì—¬ .md íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        root_path (str): ìŠ¤ìº”í•  ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: ë°œê²¬ëœ .md íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Example:\n",
    "        >>> scan_directory(\"./manual/user/firstUser\")\n",
    "        ['/path/to/manual/user/firstUser/login/login.md', \n",
    "         '/path/to/manual/user/firstUser/approval/approval.md']\n",
    "    \"\"\"\n",
    "    md_files = []\n",
    "    \n",
    "    if not os.path.exists(root_path):\n",
    "        print(f\"âš ï¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {root_path}\")\n",
    "        return md_files\n",
    "    \n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        #print(root,dirs,files)\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith('.md'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                md_files.append(os.path.abspath(file_path))\n",
    "    \n",
    "    return sorted(md_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_markdown_file(file_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ì½ì„ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        Optional[str]: íŒŒì¼ ë‚´ìš© (ì‹¤íŒ¨ ì‹œ None)\n",
    "    \n",
    "    Example:\n",
    "        >>> content = read_markdown_file(\"./manual/user/firstUser/login/login.md\")\n",
    "        >>> print(content[:50])\n",
    "        # Login\n",
    "        \n",
    "        ---\n",
    "        ## ëª©ì°¨\n",
    "        1. [ë¡œê·¸ì¸ í˜ì´ì§€](#1-ë¡œê·¸ì¸-í˜ì´ì§€)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return None\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"âŒ íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_path} - {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_path_info(file_path: str, root_path: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    íŒŒì¼ ê²½ë¡œì—ì„œ ê²½ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ì „ì²´ íŒŒì¼ ê²½ë¡œ\n",
    "        root_path (str): ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[str, str, str]: (ìƒëŒ€ê²½ë¡œ, íŒŒì¼ëª…_í™•ì¥ìì œê±°, ë””ë ‰í† ë¦¬ëª…)\n",
    "    \n",
    "    Example:\n",
    "        >>> extract_path_info(\"/path/manual/user/firstUser/login/login.md\", \"/path/manual/user/firstUser\")\n",
    "        ('login', 'login', 'login')\n",
    "    \"\"\"\n",
    "    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜\n",
    "    abs_file_path = os.path.abspath(file_path)\n",
    "    abs_root_path = os.path.abspath(root_path)\n",
    "    \n",
    "    # ìƒëŒ€ ê²½ë¡œ ê³„ì‚°\n",
    "    rel_path = os.path.relpath(abs_file_path, abs_root_path)\n",
    "    \n",
    "    # íŒŒì¼ëª…ê³¼ í™•ì¥ì ë¶„ë¦¬\n",
    "    file_name_with_ext = os.path.basename(abs_file_path)\n",
    "    file_name = os.path.splitext(file_name_with_ext)[0]\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ëª… ì¶”ì¶œ\n",
    "    dir_name = os.path.basename(os.path.dirname(abs_file_path))\n",
    "    \n",
    "    return (rel_path, file_name, dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1ë‹¨ê³„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "\n",
    "* ì™¸ë¶€ì— ì§ì ‘ ë…¸ì¶œë˜ì§€ ì•ŠìŒ\n",
    "1. scan_directory       <- process_markdown_files\n",
    "2. read_markdown_file   <- process_markdown_files\n",
    "3. extract_path_info    <- process_markdown_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "í…ŒìŠ¤íŠ¸ ê²½ë¡œ: ./manual/user/firstUser/namespaces\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1ë‹¨ê³„ í†µí•© í…ŒìŠ¤íŠ¸ - ì…€ ë‹¨ìœ„ ì‹¤í–‰ìœ¼ë¡œ ë³€ìˆ˜ ê³µìœ \n",
    "print(\"1ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "# í…ŒìŠ¤íŠ¸ ê²½ë¡œ ì„¤ì • (ì „ì—­ ë³€ìˆ˜ë¡œ ì‚¬ìš©)\n",
    "#test_path = \"./manual/user/firstUser/\"\n",
    "test_path = \"./manual/user/firstUser/namespaces\"\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ê²½ë¡œ: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. scan_directory() í…ŒìŠ¤íŠ¸\n",
      "ë°œê²¬ëœ íŒŒì¼ ìˆ˜: 1\n",
      "ë°œê²¬ëœ ëª¨ë“  íŒŒì¼ë“¤:\n",
      "  1. filename: namespaces.md, filepath: /Users/gu.han/Documents/AI.WORK/RAG_Master/manual/user/firstUser/namespaces\n"
     ]
    }
   ],
   "source": [
    "# 1-1. scan_directory í…ŒìŠ¤íŠ¸\n",
    "print(\"1. scan_directory() í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "md_files = scan_directory(test_path)\n",
    "print(f\"ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(md_files)}\")\n",
    "\n",
    "if md_files:\n",
    "    print(\"ë°œê²¬ëœ ëª¨ë“  íŒŒì¼ë“¤:\")\n",
    "    for i, file_path in enumerate(md_files, 1):\n",
    "        print(f\"  {i}. filename: {os.path.basename(file_path)}, filepath: {os.path.dirname(file_path)}\")\n",
    "else:\n",
    "    print(\"ë°œê²¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. read_markdown_file() í…ŒìŠ¤íŠ¸\n",
      "['/Users/gu.han/Documents/AI.WORK/RAG_Master/manual/user/firstUser/namespaces/namespaces.md']\n",
      "í…ŒìŠ¤íŠ¸ íŒŒì¼: namespaces.md\n",
      "íŒŒì¼ ë‚´ìš© ê¸¸ì´: 1966ì\n",
      "ì´ ë¼ì¸ ìˆ˜: 58\n",
      "ì²« 5ì¤„ ë¯¸ë¦¬ë³´ê¸°:\n",
      "  1: # Namespaces\n",
      "  2: \n",
      "  3: > NamespacesëŠ” ìƒë‹¨ì˜ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì„œë¹„ìŠ¤ì¤‘ì¸ Namespace ëª©ë¡ì„ í™•ì¸í•˜ê³  ìƒì„±, ì‚­ì œí•˜ëŠ” ì„œë¹„ìŠ¤ ì…ë‹ˆë‹¤.&#x20;\n",
      "  4: \n",
      "  5: ---\n",
      "\n",
      "ëª¨ë“  íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸:\n",
      "  âœ… namespaces.md: 1966ì\n",
      "\n",
      "âœ… 1-2ë‹¨ê³„ ì™„ë£Œ: test_file_contents ë³€ìˆ˜ ìƒì„±ë¨ (1ê°œ íŒŒì¼)\n"
     ]
    }
   ],
   "source": [
    "# 1-2. read_markdown_file í…ŒìŠ¤íŠ¸ (md_files ë³€ìˆ˜ í™œìš©)\n",
    "print(\"2. read_markdown_file() í…ŒìŠ¤íŠ¸\")\n",
    "test_file_contents = {}  # íŒŒì¼ë³„ ë‚´ìš© ì €ì¥\n",
    "\n",
    "print(md_files)\n",
    "\n",
    "if md_files:\n",
    "    # ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ìƒì„¸ í…ŒìŠ¤íŠ¸\n",
    "    test_file = md_files[0]\n",
    "    for test_file in md_files:\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ íŒŒì¼: {os.path.basename(test_file)}\")\n",
    "        \n",
    "        content = read_markdown_file(test_file)\n",
    "        if content:\n",
    "            test_file_contents[test_file] = content\n",
    "            lines = content.split('\\n')\n",
    "            print(f\"íŒŒì¼ ë‚´ìš© ê¸¸ì´: {len(content)}ì\")\n",
    "            print(f\"ì´ ë¼ì¸ ìˆ˜: {len(lines)}\")\n",
    "            print(\"ì²« 5ì¤„ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "            for i, line in enumerate(lines[:5], 1):\n",
    "                print(f\"  {i}: {line}\")\n",
    "        else:\n",
    "            print(\"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨\")\n",
    "        \n",
    "        # ëª¨ë“  íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\n",
    "        print(f\"\\nëª¨ë“  íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸:\")\n",
    "        for file_path in md_files:\n",
    "            content = read_markdown_file(file_path)\n",
    "            if content:\n",
    "                test_file_contents[file_path] = content\n",
    "                print(f\"  âœ… {os.path.basename(file_path)}: {len(content)}ì\")\n",
    "            else:\n",
    "                print(f\"  âŒ {os.path.basename(file_path)}: ì½ê¸° ì‹¤íŒ¨\")\n",
    "else:\n",
    "    print(\"í…ŒìŠ¤íŠ¸í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print()\n",
    "print(f\"âœ… 1-2ë‹¨ê³„ ì™„ë£Œ: test_file_contents ë³€ìˆ˜ ìƒì„±ë¨ ({len(test_file_contents)}ê°œ íŒŒì¼)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. extract_path_info() í…ŒìŠ¤íŠ¸\n",
      "ëª¨ë“  íŒŒì¼ì˜ ê²½ë¡œ ì •ë³´:\n",
      "  íŒŒì¼ 1: namespaces.md\n",
      "  ìƒëŒ€ê²½ë¡œ: namespaces.md\n",
      "  íŒŒì¼ëª…: namespaces\n",
      "  ë””ë ‰í† ë¦¬ëª…: namespaces\n",
      "\n",
      "--------------------------------------------------\n",
      "1ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
      "âœ… 1-3ë‹¨ê³„ ì™„ë£Œ: test_path_info ë³€ìˆ˜ ìƒì„±ë¨ (1ê°œ íŒŒì¼)\n",
      "\n",
      "ğŸ“‹ 1ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜:\n",
      "  - test_path: ./manual/user/firstUser/namespaces\n",
      "  - md_files: 1ê°œ íŒŒì¼\n",
      "  - test_file_contents: 1ê°œ íŒŒì¼ ë‚´ìš©\n",
      "  - test_path_info: 1ê°œ íŒŒì¼ ê²½ë¡œ ì •ë³´\n"
     ]
    }
   ],
   "source": [
    "# 1-3. extract_path_info í…ŒìŠ¤íŠ¸ (md_files ë³€ìˆ˜ í™œìš©)\n",
    "print(\"3. extract_path_info() í…ŒìŠ¤íŠ¸\")\n",
    "test_path_info = {}  # íŒŒì¼ë³„ ê²½ë¡œ ì •ë³´ ì €ì¥\n",
    "\n",
    "# md_files ë°ì´í„° í¬ë§· ì˜ˆì‹œ:\n",
    "# md_files = [\n",
    "#     'C:/Users/docs/manual/user/firstUser/approval/approval.md',\n",
    "#     'C:/Users/docs/manual/user/firstUser/login/login.md',\n",
    "#     'C:/Users/docs/manual/admin/settings/settings.md'\n",
    "# ]\n",
    "if md_files:\n",
    "    print(\"ëª¨ë“  íŒŒì¼ì˜ ê²½ë¡œ ì •ë³´:\")\n",
    "    for i, file_path in enumerate(md_files, 1):\n",
    "        \n",
    "        # scan_directory()ë¡œ ìˆ˜ì§‘ëœ .md íŒŒì¼ë“¤ì˜ ê²½ë¡œë¥¼ ì²˜ë¦¬\n",
    "        # file_path: scan_directory()ê°€ ì°¾ì€ .md íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ\n",
    "        # test_path: scan_directory()ì— ì „ë‹¬ëœ ê²€ìƒ‰ ì‹œì‘ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "        rel_path, file_name, dir_name = extract_path_info(file_path, test_path)\n",
    "        \n",
    "        # ê²½ë¡œ ì •ë³´ ì €ì¥\n",
    "        # ì˜ˆì‹œ ë°ì´í„° êµ¬ì¡°:\n",
    "        # test_path_info[file_path] = {\n",
    "        #     'rel_path': 'manual/user/firstUser/approval',  # ìƒëŒ€ ê²½ë¡œ\n",
    "        #     'file_name': 'approval',                       # íŒŒì¼ëª…\n",
    "        #     'dir_name': 'approval'                         # ë””ë ‰í† ë¦¬ëª…\n",
    "        # }\n",
    "        test_path_info[file_path] = {\n",
    "            'rel_path': rel_path,\n",
    "            'file_name': file_name,\n",
    "            'dir_name': dir_name\n",
    "        }\n",
    "        \n",
    "        print(f\"  íŒŒì¼ {i}: {file_name}.md\")\n",
    "        print(f\"  ìƒëŒ€ê²½ë¡œ: {rel_path}\")\n",
    "        print(f\"  íŒŒì¼ëª…: {file_name}\")\n",
    "        print(f\"  ë””ë ‰í† ë¦¬ëª…: {dir_name}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"í…ŒìŠ¤íŠ¸í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"1ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "print(f\"âœ… 1-3ë‹¨ê³„ ì™„ë£Œ: test_path_info ë³€ìˆ˜ ìƒì„±ë¨ ({len(test_path_info)}ê°œ íŒŒì¼)\")\n",
    "print()\n",
    "print(\"ğŸ“‹ 1ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜:\")\n",
    "print(f\"  - test_path: {test_path}\")\n",
    "print(f\"  - md_files: {len(md_files) if md_files else 0}ê°œ íŒŒì¼\")\n",
    "print(f\"  - test_file_contents: {len(test_file_contents)}ê°œ íŒŒì¼ ë‚´ìš©\")\n",
    "print(f\"  - test_path_info: {len(test_path_info)}ê°œ íŒŒì¼ ê²½ë¡œ ì •ë³´\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ë‹¨ê³„: íŒŒì‹± ëª¨ë“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# =============================================================================\n",
    "# 2ë‹¨ê³„: íŒŒì‹± ëª¨ë“ˆ (í•µì‹¬ 2ê°œ í•¨ìˆ˜ë§Œ)\n",
    "# =============================================================================\n",
    "\n",
    "def parse_markdown_lines(content: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì„ ë¼ì¸ë³„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        content (str): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‚´ìš©\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: ë¼ì¸ë³„ë¡œ ë¶„í• ëœ ë‚´ìš©\n",
    "    \n",
    "    Example:\n",
    "        >>> content = \"# Title\\n\\n## Section\\nContent here\"\n",
    "        >>> parse_markdown_lines(content)\n",
    "        ['# Title', '', '## Section', 'Content here']\n",
    "    \"\"\"\n",
    "    if not content:\n",
    "        return []\n",
    "    \n",
    "    # ë¼ì¸ë³„ë¡œ ë¶„í• í•˜ê³  ì˜¤ë¥¸ìª½ ê³µë°± ì œê±°\n",
    "    lines = [line.rstrip() for line in content.split('\\n')]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_header_level(line: str) -> Tuple[Optional[int], Optional[str]]:\n",
    "    \"\"\"\n",
    "    ë¼ì¸ì—ì„œ ë§ˆí¬ë‹¤ìš´ í—¤ë” ë ˆë²¨ê³¼ ì œëª©ì„ ê°ì§€í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        line (str): ê²€ì‚¬í•  ë¼ì¸\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Optional[int], Optional[str]]: (í—¤ë”ë ˆë²¨, ì œëª©) ë˜ëŠ” (None, None)\n",
    "    \"\"\"\n",
    "    # ë§ˆí¬ë‹¤ìš´ í—¤ë” íŒ¨í„´ ë§¤ì¹­ (# ~ ######)\n",
    "    header_pattern = r'^(#{1,6})\\s+(.+)$'\n",
    "    match = re.match(header_pattern, line.strip())\n",
    "    \n",
    "    if match:\n",
    "        header_level = len(match.group(1))  # # ê°œìˆ˜\n",
    "        header_title = match.group(2).strip()  # ì œëª© ë¶€ë¶„\n",
    "        return (header_level, header_title)\n",
    "    \n",
    "    return (None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "\n",
    "def process_markdown_files(root_path: str) -> List[Dict[str, any]]:\n",
    "    \"\"\"\n",
    "    1ë‹¨ê³„ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•´ì„œ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë“¤ì„ íŒŒì‹±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        root_path (str): ìŠ¤ìº”í•  ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict]: íŒŒì‹±ëœ íŒŒì¼ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "        ê° ë”•ì…”ë„ˆë¦¬ëŠ” ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨:\n",
    "        - 'file_path': íŒŒì¼ ê²½ë¡œ\n",
    "        - 'rel_path': ìƒëŒ€ ê²½ë¡œ  \n",
    "        - 'file_name': íŒŒì¼ëª…\n",
    "        - 'dir_name': ë””ë ‰í† ë¦¬ëª…\n",
    "        - 'lines': íŒŒì‹±ëœ ë¼ì¸ ë¦¬ìŠ¤íŠ¸\n",
    "        - 'headers': ê°ì§€ëœ í—¤ë” ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # 1ë‹¨ê³„ í•¨ìˆ˜ ì‚¬ìš©: íŒŒì¼ ìŠ¤ìº”\n",
    "    md_files = scan_directory(root_path)\n",
    "    \n",
    "    parsed_files = []\n",
    "    \n",
    "    for file_path in md_files:\n",
    "        print(f\"ğŸ“– íŒŒì‹± ì¤‘: {file_path}\")\n",
    "        \n",
    "        # 1ë‹¨ê³„ í•¨ìˆ˜ ì‚¬ìš©: íŒŒì¼ ì½ê¸°\n",
    "        content = read_markdown_file(file_path)\n",
    "        if content is None:\n",
    "            continue\n",
    "            \n",
    "        # 1ë‹¨ê³„ í•¨ìˆ˜ ì‚¬ìš©: ê²½ë¡œ ì •ë³´ ì¶”ì¶œ\n",
    "        rel_path, file_name, dir_name = extract_path_info(file_path, root_path)\n",
    "        \n",
    "        # 2ë‹¨ê³„ í•¨ìˆ˜ ì‚¬ìš©: ë¼ì¸ë³„ íŒŒì‹±\n",
    "        lines = parse_markdown_lines(content)\n",
    "        \n",
    "        # 2ë‹¨ê³„ í•¨ìˆ˜ ì‚¬ìš©: í—¤ë” ê°ì§€\n",
    "        headers = []\n",
    "        for line_num, line in enumerate(lines):\n",
    "            level, title = detect_header_level(line)\n",
    "            if level is not None:\n",
    "                headers.append({\n",
    "                    'line_num': line_num,\n",
    "                    'level': level,\n",
    "                    'title': title,\n",
    "                    'line': line\n",
    "                })\n",
    "        \n",
    "        # íŒŒì‹± ê²°ê³¼ ì €ì¥\n",
    "        parsed_file = {\n",
    "            'file_path': file_path,\n",
    "            'rel_path': rel_path,\n",
    "            'file_name': file_name,\n",
    "            'dir_name': dir_name,\n",
    "            'lines': lines,\n",
    "            'headers': headers,\n",
    "            'total_lines': len(lines),\n",
    "            'header_count': len(headers)\n",
    "        }\n",
    "        \n",
    "        parsed_files.append(parsed_file)\n",
    "    \n",
    "    return parsed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2ë‹¨ê³„ ë‹¨ìœ„&í†µí•© í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "\n",
    "(public)Parse_markdown_lines() â†’ (private)detect_header_level() â†’ (private)process_markdown_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (1ë‹¨ê³„ ê²°ê³¼ í™œìš©)\n",
      "--------------------------------------------------\n",
      "ğŸ“‹ 1ë‹¨ê³„ ê²°ê³¼ í™•ì¸:\n",
      "  - ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼: 1ê°œ\n",
      "  - ì²« ë²ˆì§¸ íŒŒì¼: namespaces.md\n",
      "\n",
      "1. parse_markdown_lines() í…ŒìŠ¤íŠ¸ (ì‹¤ì œ íŒŒì¼ ì‚¬ìš©)\n",
      "  ğŸ“„ namespaces.md:\n",
      "    - ì›ë³¸ ê¸¸ì´: 1966ì\n",
      "    - íŒŒì‹±ëœ ë¼ì¸ ìˆ˜: 58\n",
      "    - ì²« 3ì¤„: ['# Namespaces', '', '> NamespacesëŠ” ìƒë‹¨ì˜ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì„œë¹„ìŠ¤ì¤‘ì¸...']\n",
      "\n",
      "âœ… 2-1ë‹¨ê³„ ì™„ë£Œ: test_parsed_lines ë³€ìˆ˜ ìƒì„±ë¨ (1ê°œ íŒŒì¼)\n"
     ]
    }
   ],
   "source": [
    "# 2-1. parse_markdown_lines í†µí•©í…ŒìŠ¤íŠ¸ (1ë‹¨ê³„ í•¨ìˆ˜ í™œìš©)\n",
    "print(\"2ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (1ë‹¨ê³„ ê²°ê³¼ í™œìš©)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 1ë‹¨ê³„ ê²°ê³¼ í™•ì¸\n",
    "print(\"ğŸ“‹ 1ë‹¨ê³„ ê²°ê³¼ í™•ì¸:\")\n",
    "print(f\"  - ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼: {len(test_file_contents)}ê°œ\")  # test_file_contents = {\n",
    "                                                           #   'C:/docs/file1.md': '# ì œëª©\\në³¸ë¬¸ë‚´ìš©...',\n",
    "                                                           #   'C:/docs/file2.md': '## ì†Œì œëª©\\n- ë¦¬ìŠ¤íŠ¸...'\n",
    "                                                           # }\n",
    "if test_file_contents:\n",
    "    first_file = list(test_file_contents.keys())[0]\n",
    "    print(f\"  - ì²« ë²ˆì§¸ íŒŒì¼: {os.path.basename(first_file)}\")\n",
    "print()\n",
    "\n",
    "# ì‹¤ì œ íŒŒì¼ ë‚´ìš©ìœ¼ë¡œ parse_markdown_lines í…ŒìŠ¤íŠ¸\n",
    "print(\"1. parse_markdown_lines() í…ŒìŠ¤íŠ¸ (ì‹¤ì œ íŒŒì¼ ì‚¬ìš©)\")\n",
    "test_parsed_lines = {}  # íŒŒì¼ë³„ íŒŒì‹±ëœ ë¼ì¸ ì €ì¥\n",
    "\n",
    "if test_file_contents:\n",
    "    for file_path, content in test_file_contents.items():\n",
    "        lines = parse_markdown_lines(content)\n",
    "        test_parsed_lines[file_path] = lines\n",
    "        \n",
    "        file_name = os.path.basename(file_path)\n",
    "        print(f\"  ğŸ“„ {file_name}:\")\n",
    "        print(f\"    - ì›ë³¸ ê¸¸ì´: {len(content)}ì\")\n",
    "        print(f\"    - íŒŒì‹±ëœ ë¼ì¸ ìˆ˜: {len(lines)}\")\n",
    "        print(f\"    - ì²« 3ì¤„: {[line[:30] + '...' if len(line) > 30 else line for line in lines[:3]]}\")\n",
    "        print()\n",
    "\n",
    "print(f\"âœ… 2-1ë‹¨ê³„ ì™„ë£Œ: test_parsed_lines ë³€ìˆ˜ ìƒì„±ë¨ ({len(test_parsed_lines)}ê°œ íŒŒì¼)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. detect_header_level() í…ŒìŠ¤íŠ¸ (íŒŒì‹±ëœ ë¼ì¸ ì‚¬ìš©)\n",
      "  ğŸ“„ namespaces.md:\n",
      "    - ì´ ë¼ì¸ ìˆ˜: 58\n",
      "    - ê²€ì¶œëœ í—¤ë” ìˆ˜: 5\n",
      "    - í—¤ë” ëª©ë¡:\n",
      "      â”” ë ˆë²¨ 1: Namespaces (ë¼ì¸ 1)\n",
      "        â”” ë ˆë²¨ 2: **ëª©ì°¨** (ë¼ì¸ 6)\n",
      "        â”” ë ˆë²¨ 2: 1. Namespace ë©”ë‰´ ì§„ì… (ë¼ì¸ 11)\n",
      "        â”” ë ˆë²¨ 2: 2. Namespace ìƒì„± ì‹ ì²­ (ë¼ì¸ 22)\n",
      "        â”” ë ˆë²¨ 2: 3. Namespace ìƒì„± í™•ì¸ (ë¼ì¸ 50)\n",
      "\n",
      "âœ… 2-2ë‹¨ê³„ ì™„ë£Œ: test_headers ë³€ìˆ˜ ìƒì„±ë¨ (1ê°œ íŒŒì¼)\n",
      "ğŸ“Š í—¤ë” ê²€ì¶œ í†µê³„: ì´ 5ê°œ í—¤ë” ê²€ì¶œë¨\n"
     ]
    }
   ],
   "source": [
    "# 2-2. detect_header_level ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (test_parsed_lines í™œìš©)\n",
    "print(\"2. detect_header_level() í…ŒìŠ¤íŠ¸ (íŒŒì‹±ëœ ë¼ì¸ ì‚¬ìš©)\")\n",
    "test_headers = {}  # íŒŒì¼ë³„ í—¤ë” ì •ë³´ ì €ì¥\n",
    "\n",
    "if test_parsed_lines:\n",
    "    for file_path, lines in test_parsed_lines.items():\n",
    "        file_headers = []\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            level, title = detect_header_level(line)\n",
    "            if level is not None:\n",
    "                file_headers.append({\n",
    "                    'line_num': line_num,\n",
    "                    'level': level,\n",
    "                    'title': title,\n",
    "                    'line': line\n",
    "                })\n",
    "        \n",
    "        test_headers[file_path] = file_headers\n",
    "        \n",
    "        file_name = os.path.basename(file_path)\n",
    "        print(f\"  ğŸ“„ {file_name}:\")\n",
    "        print(f\"    - ì´ ë¼ì¸ ìˆ˜: {len(lines)}\")\n",
    "        print(f\"    - ê²€ì¶œëœ í—¤ë” ìˆ˜: {len(file_headers)}\")\n",
    "        \n",
    "        if file_headers:\n",
    "            print(\"    - í—¤ë” ëª©ë¡:\")\n",
    "            for header in file_headers:\n",
    "                indent = \"    \" + \"  \" * header['level']\n",
    "                print(f\"{indent}â”” ë ˆë²¨ {header['level']}: {header['title']} (ë¼ì¸ {header['line_num']+1})\")\n",
    "        else:\n",
    "            print(\"    - í—¤ë” ì—†ìŒ\")\n",
    "        print()\n",
    "\n",
    "print(f\"âœ… 2-2ë‹¨ê³„ ì™„ë£Œ: test_headers ë³€ìˆ˜ ìƒì„±ë¨ ({len(test_headers)}ê°œ íŒŒì¼)\")\n",
    "\n",
    "# í—¤ë” ê²€ì¶œ í†µê³„\n",
    "total_headers = sum(len(headers) for headers in test_headers.values())\n",
    "print(f\"ğŸ“Š í—¤ë” ê²€ì¶œ í†µê³„: ì´ {total_headers}ê°œ í—¤ë” ê²€ì¶œë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. process_markdown_files() í†µí•© í…ŒìŠ¤íŠ¸ (1ë‹¨ê³„ ê²°ê³¼ ë¹„êµ)\n",
      "------------------------------\n",
      "ğŸ“– íŒŒì‹± ì¤‘: /Users/gu.han/Documents/AI.WORK/RAG_Master/manual/user/firstUser/namespaces/namespaces.md\n",
      "ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: 1\n",
      "\n",
      "ğŸ“Š 1ë‹¨ê³„ vs 2ë‹¨ê³„ ê²°ê³¼ ë¹„êµ:\n",
      "  - 1ë‹¨ê³„ íŒŒì¼ ìˆ˜: 1\n",
      "  - 2ë‹¨ê³„ íŒŒì¼ ìˆ˜: 1\n",
      "  - íŒŒì¼ ìˆ˜ ì¼ì¹˜: âœ…\n",
      "\n",
      "íŒŒì¼ 1: namespaces.md\n",
      "  ğŸ“ ê²½ë¡œ: namespaces.md\n",
      "  ğŸ“Š ì´ ë¼ì¸ ìˆ˜: 58\n",
      "  ğŸ·ï¸ í—¤ë” ìˆ˜: 5\n",
      "  ğŸ” 1ë‹¨ê³„ ë¼ì¸ ìˆ˜: 58\n",
      "  âœ… ë¼ì¸ ìˆ˜ ì¼ì¹˜: âœ…\n",
      "  ğŸ” ìˆ˜ë™ í—¤ë” ê²€ì¶œ: 5ê°œ\n",
      "  âœ… í—¤ë” ìˆ˜ ì¼ì¹˜: âœ…\n",
      "  ğŸ“ˆ í—¤ë” ë ˆë²¨ ë¶„í¬:\n",
      "    ë ˆë²¨ 1: 1ê°œ\n",
      "    ë ˆë²¨ 2: 4ê°œ\n",
      "\n",
      "--------------------------------------------------\n",
      "2ë‹¨ê³„ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
      "\n",
      "ğŸ“‹ 2ë‹¨ê³„ ìµœì¢… ê²°ê³¼ ë³€ìˆ˜:\n",
      "  - test_parsed_lines: 1ê°œ íŒŒì¼ì˜ íŒŒì‹±ëœ ë¼ì¸\n",
      "  - test_headers: 1ê°œ íŒŒì¼ì˜ í—¤ë” ì •ë³´\n",
      "  - parsed_files_result: 1ê°œ íŒŒì¼ì˜ í†µí•© ê²°ê³¼\n",
      "  - step2_output: 3ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 2-3. process_markdown_files í†µí•© í…ŒìŠ¤íŠ¸ (1ë‹¨ê³„ ê²°ê³¼ì™€ ë¹„êµ ê²€ì¦)\n",
    "print(\"3. process_markdown_files() í†µí•© í…ŒìŠ¤íŠ¸ (1ë‹¨ê³„ ê²°ê³¼ ë¹„êµ)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# process_markdown_files í•¨ìˆ˜ ì‹¤í–‰ (1ë‹¨ê³„ í•¨ìˆ˜ë“¤ì„ ë‚´ë¶€ì ìœ¼ë¡œ í˜¸ì¶œ)\n",
    "parsed_files_result = process_markdown_files(test_path)\n",
    "\n",
    "print(f\"ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {len(parsed_files_result)}\")\n",
    "print()\n",
    "\n",
    "# 1ë‹¨ê³„ ê²°ê³¼ì™€ 2ë‹¨ê³„ ê²°ê³¼ ë¹„êµ ê²€ì¦\n",
    "print(\"ğŸ“Š 1ë‹¨ê³„ vs 2ë‹¨ê³„ ê²°ê³¼ ë¹„êµ:\")\n",
    "print(f\"  - 1ë‹¨ê³„ íŒŒì¼ ìˆ˜: {len(md_files)}\")\n",
    "print(f\"  - 2ë‹¨ê³„ íŒŒì¼ ìˆ˜: {len(parsed_files_result)}\")\n",
    "print(f\"  - íŒŒì¼ ìˆ˜ ì¼ì¹˜: {'âœ…' if len(md_files) == len(parsed_files_result) else 'âŒ'}\")\n",
    "print()\n",
    "\n",
    "# ê° íŒŒì¼ë³„ ìƒì„¸ ë¹„êµ\n",
    "for i, parsed_file in enumerate(parsed_files_result):\n",
    "    file_path = parsed_file['file_path']\n",
    "    file_name = parsed_file['file_name']\n",
    "    \n",
    "    print(f\"íŒŒì¼ {i+1}: {file_name}.md\")\n",
    "    print(f\"  ğŸ“ ê²½ë¡œ: {parsed_file['rel_path']}\")\n",
    "    print(f\"  ğŸ“Š ì´ ë¼ì¸ ìˆ˜: {parsed_file['total_lines']}\")\n",
    "    print(f\"  ğŸ·ï¸ í—¤ë” ìˆ˜: {parsed_file['header_count']}\")\n",
    "    \n",
    "    # 1ë‹¨ê³„ ê²°ê³¼ì™€ ë¹„êµ\n",
    "    if file_path in test_file_contents:\n",
    "        original_content = test_file_contents[file_path]\n",
    "        original_lines = len(original_content.split('\\n'))\n",
    "        print(f\"  ğŸ” 1ë‹¨ê³„ ë¼ì¸ ìˆ˜: {original_lines}\")\n",
    "        print(f\"  âœ… ë¼ì¸ ìˆ˜ ì¼ì¹˜: {'âœ…' if original_lines == parsed_file['total_lines'] else 'âŒ'}\")\n",
    "        \n",
    "        # í—¤ë” ì •ë³´ì™€ ë¹„êµ\n",
    "        if file_path in test_headers:\n",
    "            manual_headers = test_headers[file_path]\n",
    "            print(f\"  ğŸ” ìˆ˜ë™ í—¤ë” ê²€ì¶œ: {len(manual_headers)}ê°œ\")\n",
    "            print(f\"  âœ… í—¤ë” ìˆ˜ ì¼ì¹˜: {'âœ…' if len(manual_headers) == parsed_file['header_count'] else 'âŒ'}\")\n",
    "    \n",
    "    # í—¤ë” ë ˆë²¨ë³„ ë¶„í¬\n",
    "    if parsed_file['headers']:\n",
    "        level_count = {}\n",
    "        for header in parsed_file['headers']:\n",
    "            level = header['level']\n",
    "            level_count[level] = level_count.get(level, 0) + 1\n",
    "        \n",
    "        print(\"  ğŸ“ˆ í—¤ë” ë ˆë²¨ ë¶„í¬:\")\n",
    "        for level in sorted(level_count.keys()):\n",
    "            print(f\"    ë ˆë²¨ {level}: {level_count[level]}ê°œ\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"2ë‹¨ê³„ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "print()\n",
    "print(\"ğŸ“‹ 2ë‹¨ê³„ ìµœì¢… ê²°ê³¼ ë³€ìˆ˜:\")\n",
    "print(f\"  - test_parsed_lines: {len(test_parsed_lines)}ê°œ íŒŒì¼ì˜ íŒŒì‹±ëœ ë¼ì¸\")\n",
    "print(f\"  - test_headers: {len(test_headers)}ê°œ íŒŒì¼ì˜ í—¤ë” ì •ë³´\")\n",
    "print(f\"  - parsed_files_result: {len(parsed_files_result)}ê°œ íŒŒì¼ì˜ í†µí•© ê²°ê³¼\")\n",
    "\n",
    "# 3ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë³€ìˆ˜ ì¤€ë¹„\n",
    "step2_output = parsed_files_result\n",
    "print(f\"  - step2_output: 3ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3ë‹¨ê³„: ì„¹ì…˜ ì²˜ë¦¬ ëª¨ë“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "# =============================================================================\n",
    "# 3ë‹¨ê³„: ì„¹ì…˜ ì²˜ë¦¬ ëª¨ë“ˆ (2ë‹¨ê³„ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ)\n",
    "# =============================================================================\n",
    "\n",
    "def should_skip_section(section_title: str, skip_patterns: List[str] = None) -> bool:\n",
    "    if skip_patterns is None:\n",
    "        skip_patterns = [\"^ëª©ì°¨$\", \"^\\\\*\\\\*ëª©ì°¨\\\\*\\\\*$\", \"^table of contents$\"]\n",
    "    \n",
    "    section_lower = section_title.lower().strip()\n",
    "    \n",
    "    for pattern in skip_patterns:\n",
    "        if re.match(pattern.lower(), section_lower):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ê°œì„ ëœ 3ë‹¨ê³„ í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def create_section(header: Dict[str, Any], content: List[str], preserve_structure: bool = False) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ ì„¹ì…˜ ìƒì„± í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        header (Dict): í—¤ë” ì •ë³´ {'line_num': int, 'level': int, 'title': str}\n",
    "        content (List[str]): ì„¹ì…˜ ë‚´ìš© ë¼ì¸ë“¤\n",
    "        preserve_structure (bool): êµ¬ì¡° ë³´ì¡´ ì—¬ë¶€ (ì—°ì† ë¹ˆ ë¼ì¸ì„ í•˜ë‚˜ë¡œ ì¶•ì†Œ)\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: ì„¹ì…˜ ì •ë³´\n",
    "    \"\"\"\n",
    "    # ë¹ˆ ë¼ì¸ ì²˜ë¦¬ ë¡œì§ ê°œì„ \n",
    "    if preserve_structure:\n",
    "        # êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ: ì—°ì†ëœ ë¹ˆ ë¼ì¸ì„ í•˜ë‚˜ë¡œ ì¶•ì†Œ\n",
    "        cleaned_content = []\n",
    "        prev_empty = False\n",
    "        \n",
    "        for line in content:\n",
    "            line_stripped = line.strip()\n",
    "            if line_stripped:  # ë‚´ìš©ì´ ìˆëŠ” ë¼ì¸\n",
    "                cleaned_content.append(line)\n",
    "                prev_empty = False\n",
    "            elif not prev_empty:  # ì²« ë²ˆì§¸ ë¹ˆ ë¼ì¸ë§Œ ìœ ì§€\n",
    "                cleaned_content.append(\"\")\n",
    "                prev_empty = True\n",
    "            # ì—°ì†ëœ ë¹ˆ ë¼ì¸ì€ ë¬´ì‹œ\n",
    "    else:\n",
    "        # ê¸°ì¡´ ë¡œì§: ë¹ˆ ë¼ì¸ ì™„ì „ ì œê±°\n",
    "        cleaned_content = [line for line in content if line.strip()]\n",
    "    \n",
    "    # ì •í™•í•œ ë¼ì¸ ë²ˆí˜¸ ê³„ì‚°\n",
    "    content_start_line = header['line_num'] + 1  # ë‚´ìš© ì‹œì‘ ë¼ì¸\n",
    "    content_end_line = content_start_line + len(content) - 1 if content else content_start_line\n",
    "    \n",
    "    # ì„¹ì…˜ ì •ë³´ ìƒì„± (í™•ì¥ëœ ë©”íƒ€ë°ì´í„°)\n",
    "    section = {\n",
    "        'level': header['level'],\n",
    "        'title': header['title'],\n",
    "        'content': cleaned_content,\n",
    "        'header_line': header['line_num'],           # í—¤ë” ë¼ì¸ ë²ˆí˜¸\n",
    "        'content_start_line': content_start_line,   # ë‚´ìš© ì‹œì‘ ë¼ì¸\n",
    "        'content_end_line': content_end_line,       # ë‚´ìš© ì¢…ë£Œ ë¼ì¸\n",
    "        'original_content_length': len(content),    # ì›ë³¸ ë‚´ìš© ê¸¸ì´\n",
    "        'cleaned_content_length': len(cleaned_content),  # ì •ë¦¬ëœ ë‚´ìš© ê¸¸ì´\n",
    "        'total_characters': sum(len(line) for line in cleaned_content),  # ì´ ë¬¸ì ìˆ˜\n",
    "        'is_empty': len(cleaned_content) == 0,      # ë¹ˆ ì„¹ì…˜ ì—¬ë¶€\n",
    "        'preserve_structure': preserve_structure    # êµ¬ì¡° ë³´ì¡´ ì—¬ë¶€\n",
    "    }\n",
    "    \n",
    "    return section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3ë‹¨ê³„ ë‹¨ìœ„&í†µí•© í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "\n",
    "print(\"3ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (2ë‹¨ê³„ ê²°ê³¼ í™œìš©)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2ë‹¨ê³„ ê²°ê³¼ í™•ì¸\n",
    "if 'step2_output' in locals() and step2_output:\n",
    "    print(\"ğŸ“‹ 2ë‹¨ê³„ ê²°ê³¼ í™•ì¸:\")\n",
    "    print(f\"  - ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼: {len(step2_output)}ê°œ\")\n",
    "    print(f\"  - ì²« ë²ˆì§¸ íŒŒì¼: {step2_output[0]['file_name']}.md\")\n",
    "    \n",
    "    # ì „ì²´ í—¤ë” í†µê³„\n",
    "    total_headers = sum(len(f['headers']) for f in step2_output)\n",
    "    level2_headers = sum(len([h for h in f['headers'] if h['level'] == 2]) for f in step2_output)\n",
    "    print(f\"  - ì´ í—¤ë” ìˆ˜: {total_headers}ê°œ\")\n",
    "    print(f\"  - ë ˆë²¨ 2 í—¤ë”: {level2_headers}ê°œ\")\n",
    "else:\n",
    "    print(\"âš ï¸ step2_output ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 2ë‹¨ê³„ í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"ëŒ€ì‹  ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "    step2_output = [\n",
    "        {\n",
    "            'file_name': 'sample',\n",
    "            'lines': [\n",
    "                '# ìƒ˜í”Œ ë¬¸ì„œ',\n",
    "                '',\n",
    "                '> ì´ê²ƒì€ ìƒ˜í”Œ ë¬¸ì„œì…ë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '## ëª©ì°¨',\n",
    "                '',\n",
    "                '1. [ì„¹ì…˜ 1](#ì„¹ì…˜-1)',\n",
    "                '2. [ì„¹ì…˜ 2](#ì„¹ì…˜-2)',\n",
    "                '',\n",
    "                '## 1. ë¡œê·¸ì¸ í˜ì´ì§€',\n",
    "                '',\n",
    "                'ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†í•©ë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '```',\n",
    "                'https://portal.example.com',\n",
    "                '```',\n",
    "                '',\n",
    "                'ë¡œê·¸ì¸ í™”ë©´ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '## 2. ì‚¬ìš©ì ê´€ë¦¬',\n",
    "                '',\n",
    "                'ì‚¬ìš©ì ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '### 2.1 ì‚¬ìš©ì ì¶”ê°€',\n",
    "                '',\n",
    "                'ìƒˆë¡œìš´ ì‚¬ìš©ìë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.'\n",
    "            ],\n",
    "            'headers': [\n",
    "                {'line_num': 0, 'level': 1, 'title': 'ìƒ˜í”Œ ë¬¸ì„œ'},\n",
    "                {'line_num': 4, 'level': 2, 'title': 'ëª©ì°¨'},\n",
    "                {'line_num': 9, 'level': 2, 'title': '1. ë¡œê·¸ì¸ í˜ì´ì§€'},\n",
    "                {'line_num': 19, 'level': 2, 'title': '2. ì‚¬ìš©ì ê´€ë¦¬'},\n",
    "                {'line_num': 23, 'level': 3, 'title': '2.1 ì‚¬ìš©ì ì¶”ê°€'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-1. should_skip_section í•¨ìˆ˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸\n",
    "print(\"1. should_skip_section() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤\n",
    "skip_test_cases = [\n",
    "    (\"ëª©ì°¨\", True, \"ì •í™•í•œ ëª©ì°¨\"),\n",
    "    (\"**ëª©ì°¨**\", True, \"ë³¼ë“œ ëª©ì°¨\"),\n",
    "    (\"Table of Contents\", True, \"ì˜ë¬¸ ëª©ì°¨\"),\n",
    "    (\"ëª©ì°¨ ì„¤ëª…\", False, \"ëª©ì°¨ê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©\"),\n",
    "    (\"1. ë¡œê·¸ì¸ í˜ì´ì§€\", False, \"ì¼ë°˜ ì„¹ì…˜\"),\n",
    "    (\"ì‚¬ìš©ì ê´€ë¦¬\", False, \"ì¼ë°˜ ì„¹ì…˜\"),\n",
    "    (\"Contents Management\", False, \"contentsê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©\"),\n",
    "    (\"TOC ìƒì„±\", False, \"tocê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©\")\n",
    "]\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ê²°ê³¼:\")\n",
    "test_skip_results = {}\n",
    "\n",
    "for title, expected, description in skip_test_cases:\n",
    "    # ê¸°ì¡´ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (ì •ê·œì‹ ê¸°ë°˜)\n",
    "    try:\n",
    "        result = should_skip_section(title)\n",
    "        status = \"âœ… í†µê³¼\" if result == expected else \"âŒ ì‹¤íŒ¨\"\n",
    "        test_skip_results[title] = result\n",
    "        \n",
    "        print(f\"  '{title}' â†’ {result} {status} ({description})\")\n",
    "        if result != expected:\n",
    "            print(f\"    ì˜ˆìƒ: {expected}, ì‹¤ì œ: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  '{title}' â†’ âŒ ì˜¤ë¥˜: {e}\")\n",
    "        test_skip_results[title] = None\n",
    "\n",
    "print(f\"\\nğŸ“Š should_skip_section í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "passed = sum(1 for title, expected, _ in skip_test_cases if test_skip_results.get(title) == expected)\n",
    "total = len(skip_test_cases)\n",
    "print(f\"  - í†µê³¼: {passed}/{total} ({passed/total*100:.1f}%)\")\n",
    "\n",
    "# ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ” ì‹¤ì œ ë§¤ë‰´ì–¼ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸:\")\n",
    "actual_skip_count = 0\n",
    "actual_process_count = 0\n",
    "\n",
    "for parsed_file in step2_output:\n",
    "    file_name = parsed_file['file_name']\n",
    "    level2_headers = [h for h in parsed_file['headers'] if h['level'] == 2]\n",
    "    \n",
    "    print(f\"\\nğŸ“„ {file_name}.md:\")\n",
    "    for header in level2_headers:\n",
    "        title = header['title']\n",
    "        skip_result = should_skip_section(title)\n",
    "        \n",
    "        if skip_result:\n",
    "            actual_skip_count += 1\n",
    "            print(f\"  â­ï¸ ìŠ¤í‚µ: '{title}'\")\n",
    "        else:\n",
    "            actual_process_count += 1\n",
    "            print(f\"  âœ… ì²˜ë¦¬: '{title}'\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ í†µê³„:\")\n",
    "print(f\"  - ìŠ¤í‚µëœ ì„¹ì…˜: {actual_skip_count}ê°œ\")\n",
    "print(f\"  - ì²˜ë¦¬í•  ì„¹ì…˜: {actual_process_count}ê°œ\")\n",
    "print(f\"  - ì´ ë ˆë²¨ 2 í—¤ë”: {actual_skip_count + actual_process_count}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-2. create_section í•¨ìˆ˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. create_section() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© í—¤ë”ì™€ ë‚´ìš©\n",
    "test_header = {\n",
    "    'line_num': 9,\n",
    "    'level': 2,\n",
    "    'title': '1. ë¡œê·¸ì¸ í˜ì´ì§€'\n",
    "}\n",
    "\n",
    "test_content = [\n",
    "    'ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†í•©ë‹ˆë‹¤.',\n",
    "    '',\n",
    "    '```',\n",
    "    'https://portal.example.com',\n",
    "    '```',\n",
    "    '',\n",
    "    '',\n",
    "    'ë¡œê·¸ì¸ í™”ë©´ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.',\n",
    "    ''\n",
    "]\n",
    "\n",
    "print(\"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°:\")\n",
    "print(f\"  í—¤ë”: {test_header}\")\n",
    "print(f\"  ì›ë³¸ ë‚´ìš© ë¼ì¸ ìˆ˜: {len(test_content)}\")\n",
    "print(f\"  ì›ë³¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {test_content[:3]}...\")\n",
    "\n",
    "# ê¸°ë³¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ê¸°ë³¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (preserve_structure=False):\")\n",
    "section_basic = create_section(test_header, test_content, preserve_structure=False)\n",
    "\n",
    "print(f\"  - í—¤ë” ë¼ì¸: {section_basic['header_line']}\")\n",
    "print(f\"  - ë‚´ìš© ë²”ìœ„: {section_basic['content_start_line']} ~ {section_basic['content_end_line']}\")\n",
    "print(f\"  - ì›ë³¸ ê¸¸ì´: {section_basic['original_content_length']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ê¸¸ì´: {section_basic['cleaned_content_length']}\")\n",
    "print(f\"  - ì´ ë¬¸ì ìˆ˜: {section_basic['total_characters']}\")\n",
    "print(f\"  - ë¹ˆ ì„¹ì…˜ ì—¬ë¶€: {section_basic['is_empty']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ë‚´ìš©: {section_basic['content']}\")\n",
    "\n",
    "# êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (preserve_structure=True):\")\n",
    "section_preserve = create_section(test_header, test_content, preserve_structure=True)\n",
    "\n",
    "print(f\"  - í—¤ë” ë¼ì¸: {section_preserve['header_line']}\")\n",
    "print(f\"  - ë‚´ìš© ë²”ìœ„: {section_preserve['content_start_line']} ~ {section_preserve['content_end_line']}\")\n",
    "print(f\"  - ì›ë³¸ ê¸¸ì´: {section_preserve['original_content_length']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ê¸¸ì´: {section_preserve['cleaned_content_length']}\")\n",
    "print(f\"  - ì´ ë¬¸ì ìˆ˜: {section_preserve['total_characters']}\")\n",
    "print(f\"  - êµ¬ì¡° ë³´ì¡´: {section_preserve['preserve_structure']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ë‚´ìš©: {section_preserve['content']}\")\n",
    "\n",
    "# ë‘ ëª¨ë“œ ë¹„êµ\n",
    "print(f\"\\nğŸ“Š ë‘ ëª¨ë“œ ë¹„êµ:\")\n",
    "print(f\"  - ê¸°ë³¸ ëª¨ë“œ ë¼ì¸ ìˆ˜: {section_basic['cleaned_content_length']}\")\n",
    "print(f\"  - êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ ë¼ì¸ ìˆ˜: {section_preserve['cleaned_content_length']}\")\n",
    "print(f\"  - ì°¨ì´: {section_preserve['cleaned_content_length'] - section_basic['cleaned_content_length']} ë¼ì¸\")\n",
    "\n",
    "# ë¹ˆ ì„¹ì…˜ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ë¹ˆ ì„¹ì…˜ í…ŒìŠ¤íŠ¸:\")\n",
    "empty_content = ['', '', '   ', '\\t', '']\n",
    "section_empty = create_section(test_header, empty_content)\n",
    "print(f\"  - ë¹ˆ ë‚´ìš© ì…ë ¥: {empty_content}\")\n",
    "print(f\"  - ë¹ˆ ì„¹ì…˜ ê°ì§€: {section_empty['is_empty']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ê¸¸ì´: {section_empty['cleaned_content_length']}\")\n",
    "\n",
    "# 3-2ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜ ì €ì¥\n",
    "test_create_section_results = {\n",
    "    'basic_mode': section_basic,\n",
    "    'preserve_mode': section_preserve,\n",
    "    'empty_section': section_empty\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ… 3-2ë‹¨ê³„ ì™„ë£Œ: test_create_section_results ë³€ìˆ˜ ìƒì„±ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-3. extract_sections_from_parsed_data í†µí•© í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. extract_sections_from_parsed_data() í†µí•© í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ì²« ë²ˆì§¸ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "test_file = step2_output[0]\n",
    "test_lines = test_file['lines']\n",
    "test_headers = test_file['headers']\n",
    "\n",
    "print(\"ğŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë³´:\")\n",
    "print(f\"  íŒŒì¼ëª…: {test_file['file_name']}.md\")\n",
    "print(f\"  ì´ ë¼ì¸ ìˆ˜: {len(test_lines)}\")\n",
    "print(f\"  ì´ í—¤ë” ìˆ˜: {len(test_headers)}\")\n",
    "\n",
    "# í—¤ë” ë ˆë²¨ë³„ ë¶„í¬\n",
    "header_levels = {}\n",
    "for header in test_headers:\n",
    "    level = header['level']\n",
    "    header_levels[level] = header_levels.get(level, 0) + 1\n",
    "\n",
    "print(f\"  í—¤ë” ë ˆë²¨ ë¶„í¬: {dict(sorted(header_levels.items()))}\")\n",
    "\n",
    "# ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (ë ˆë²¨ 2ë§Œ)\n",
    "print(f\"\\nğŸ”§ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (target_levels=[2]):\")\n",
    "sections_level2 = extract_sections_from_parsed_data(test_lines, test_headers, target_levels=[2])\n",
    "\n",
    "print(f\"\\nğŸ“Š ë ˆë²¨ 2 ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"  - ìƒì„±ëœ ì„¹ì…˜ ìˆ˜: {len(sections_level2)}\")\n",
    "\n",
    "if sections_level2:\n",
    "    print(f\"  - ì„¹ì…˜ ëª©ë¡:\")\n",
    "    for i, section in enumerate(sections_level2, 1):\n",
    "        print(f\"    {i}. '{section['title']}' ({section['cleaned_content_length']} ë¼ì¸, {section['total_characters']} ë¬¸ì)\")\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ ì„¹ì…˜ ìƒì„¸ ì •ë³´\n",
    "    first_section = sections_level2[0]\n",
    "    print(f\"\\nğŸ” ì²« ë²ˆì§¸ ì„¹ì…˜ ìƒì„¸ ì •ë³´:\")\n",
    "    print(f\"  - ì œëª©: {first_section['title']}\")\n",
    "    print(f\"  - ë ˆë²¨: {first_section['level']}\")\n",
    "    print(f\"  - í—¤ë” ë¼ì¸: {first_section['header_line']}\")\n",
    "    print(f\"  - ë‚´ìš© ë²”ìœ„: {first_section['content_start_line']} ~ {first_section['content_end_line']}\")\n",
    "    print(f\"  - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {first_section['content'][:2]}...\")\n",
    "\n",
    "# ë‹¤ì¤‘ ë ˆë²¨ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ë‹¤ì¤‘ ë ˆë²¨ í…ŒìŠ¤íŠ¸ (target_levels=[2, 3]):\")\n",
    "sections_multi = extract_sections_from_parsed_data(test_lines, test_headers, target_levels=[2, 3])\n",
    "\n",
    "print(f\"\\nğŸ“Š ë‹¤ì¤‘ ë ˆë²¨ ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"  - ìƒì„±ëœ ì„¹ì…˜ ìˆ˜: {len(sections_multi)}\")\n",
    "\n",
    "if sections_multi:\n",
    "    print(f\"  - ë ˆë²¨ë³„ ì„¹ì…˜ ë¶„í¬:\")\n",
    "    level_dist = {}\n",
    "    for section in sections_multi:\n",
    "        level = section['level']\n",
    "        level_dist[level] = level_dist.get(level, 0) + 1\n",
    "    \n",
    "    for level in sorted(level_dist.keys()):\n",
    "        print(f\"    ë ˆë²¨ {level}: {level_dist[level]}ê°œ\")\n",
    "    \n",
    "    print(f\"  - ì„¹ì…˜ ëª©ë¡:\")\n",
    "    for i, section in enumerate(sections_multi, 1):\n",
    "        indent = \"  \" * (section['level'] - 1)\n",
    "        print(f\"    {i}. {indent}[L{section['level']}] '{section['title']}' ({section['cleaned_content_length']} ë¼ì¸)\")\n",
    "\n",
    "# ì „ì²´ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ì „ì²´ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:\")\n",
    "all_sections = []\n",
    "total_processed_files = 0\n",
    "total_skipped_sections = 0\n",
    "total_created_sections = 0\n",
    "\n",
    "for parsed_file in step2_output:\n",
    "    file_name = parsed_file['file_name']\n",
    "    lines = parsed_file['lines']\n",
    "    headers = parsed_file['headers']\n",
    "    \n",
    "    print(f\"\\nğŸ“„ ì²˜ë¦¬ ì¤‘: {file_name}.md\")\n",
    "    \n",
    "    # ì„¹ì…˜ ì¶”ì¶œ\n",
    "    file_sections = extract_sections_from_parsed_data(lines, headers, target_levels=[2])\n",
    "    all_sections.extend(file_sections)\n",
    "    \n",
    "    total_processed_files += 1\n",
    "    level2_count = len([h for h in headers if h['level'] == 2])\n",
    "    created_count = len(file_sections)\n",
    "    skipped_count = level2_count - created_count\n",
    "    \n",
    "    total_created_sections += created_count\n",
    "    total_skipped_sections += skipped_count\n",
    "    \n",
    "    print(f\"  ê²°ê³¼: {created_count}ê°œ ì„¹ì…˜ ìƒì„±, {skipped_count}ê°œ ìŠ¤í‚µ\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì „ì²´ ì²˜ë¦¬ í†µê³„:\")\n",
    "print(f\"  - ì²˜ë¦¬ëœ íŒŒì¼: {total_processed_files}ê°œ\")\n",
    "print(f\"  - ìƒì„±ëœ ì„¹ì…˜: {total_created_sections}ê°œ\")\n",
    "print(f\"  - ìŠ¤í‚µëœ ì„¹ì…˜: {total_skipped_sections}ê°œ\")\n",
    "print(f\"  - í‰ê·  ì„¹ì…˜/íŒŒì¼: {total_created_sections/total_processed_files:.1f}ê°œ\")\n",
    "\n",
    "if all_sections:\n",
    "    total_chars = sum(s['total_characters'] for s in all_sections)\n",
    "    avg_chars = total_chars // len(all_sections)\n",
    "    print(f\"  - ì´ ë¬¸ì ìˆ˜: {total_chars:,}ì\")\n",
    "    print(f\"  - í‰ê·  ì„¹ì…˜ í¬ê¸°: {avg_chars}ì\")\n",
    "\n",
    "# 3-3ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜ ì €ì¥\n",
    "test_extract_sections_results = {\n",
    "    'level2_sections': sections_level2,\n",
    "    'multi_level_sections': sections_multi,\n",
    "    'all_sections': all_sections,\n",
    "    'stats': {\n",
    "        'total_files': total_processed_files,\n",
    "        'total_sections': total_created_sections,\n",
    "        'total_skipped': total_skipped_sections,\n",
    "        'total_characters': total_chars if all_sections else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ… 3-3ë‹¨ê³„ ì™„ë£Œ: test_extract_sections_results ë³€ìˆ˜ ìƒì„±ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ë‹¨ê³„ ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° 4ë‹¨ê³„ ì¤€ë¹„\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ğŸ“‹ 3ë‹¨ê³„ ìµœì¢… ê²°ê³¼ ë³€ìˆ˜:\")\n",
    "print(f\"  - test_skip_results: should_skip_section í…ŒìŠ¤íŠ¸ ê²°ê³¼\")\n",
    "print(f\"  - test_create_section_results: create_section í…ŒìŠ¤íŠ¸ ê²°ê³¼ (3ê°€ì§€ ëª¨ë“œ)\")\n",
    "print(f\"  - test_extract_sections_results: extract_sections í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼\")\n",
    "\n",
    "# ì „ì²´ í†µê³„ ìš”ì•½\n",
    "if 'test_extract_sections_results' in locals():\n",
    "    stats = test_extract_sections_results['stats']\n",
    "    print(f\"\\nğŸ“Š 3ë‹¨ê³„ ì „ì²´ ì²˜ë¦¬ í†µê³„:\")\n",
    "    print(f\"  - ì²˜ë¦¬ëœ íŒŒì¼: {stats['total_files']}ê°œ\")\n",
    "    print(f\"  - ìƒì„±ëœ ì„¹ì…˜: {stats['total_sections']}ê°œ\")\n",
    "    print(f\"  - ìŠ¤í‚µëœ ì„¹ì…˜: {stats['total_skipped']}ê°œ\")\n",
    "    print(f\"  - ì´ ë¬¸ì ìˆ˜: {stats['total_characters']:,}ì\")\n",
    "    \n",
    "    if stats['total_sections'] > 0:\n",
    "        avg_size = stats['total_characters'] // stats['total_sections']\n",
    "        print(f\"  - í‰ê·  ì„¹ì…˜ í¬ê¸°: {avg_size}ì\")\n",
    "\n",
    "# 4ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë³€ìˆ˜ ì¤€ë¹„\n",
    "if 'test_extract_sections_results' in locals() and test_extract_sections_results['all_sections']:\n",
    "    step3_output = test_extract_sections_results['all_sections']\n",
    "    print(f\"\\nğŸ¯ 4ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë°ì´í„°:\")\n",
    "    print(f\"  - step3_output: {len(step3_output)}ê°œ ì„¹ì…˜\")\n",
    "    print(f\"  - ê° ì„¹ì…˜ í¬í•¨ ì •ë³´: level, title, content, ë©”íƒ€ë°ì´í„°\")\n",
    "    print(f\"  - 4ë‹¨ê³„ ë©”íƒ€ë°ì´í„° ìƒì„± ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ì„¹ì…˜ ë°ì´í„°ê°€ ì—†ì–´ì„œ step3_output ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\nâœ… 3ë‹¨ê³„ ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"ë‹¤ìŒ ë‹¨ê³„: 4ë‹¨ê³„ ë©”íƒ€ë°ì´í„° ìƒì„± ëª¨ë“ˆ ê°œë°œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections_from_parsed_data(\n",
    "    lines: List[str], \n",
    "    headers: List[Dict[str, Any]], \n",
    "    target_levels: List[int] = [2]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ ì„¹ì…˜ ì¶”ì¶œ í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        lines (List[str]): íŒŒì‹±ëœ ë¼ì¸ ë¦¬ìŠ¤íŠ¸\n",
    "        headers (List[Dict]): í—¤ë” ë¦¬ìŠ¤íŠ¸\n",
    "        target_levels (List[int]): ì²˜ë¦¬í•  í—¤ë” ë ˆë²¨ ë¦¬ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: ì²˜ë¦¬ëœ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    if not lines or not headers:\n",
    "        return []\n",
    "    \n",
    "    # ì§€ì •ëœ ë ˆë²¨ì˜ í—¤ë”ë§Œ í•„í„°ë§\n",
    "    target_headers = [h for h in headers if h['level'] in target_levels]\n",
    "    \n",
    "    if not target_headers:\n",
    "        return []\n",
    "    \n",
    "    sections = []\n",
    "    \n",
    "    # í—¤ë”ë¥¼ ë¼ì¸ ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬ (ì•ˆì „ì¥ì¹˜)\n",
    "    target_headers.sort(key=lambda h: h['line_num'])\n",
    "    \n",
    "    for i, header in enumerate(target_headers):\n",
    "        # ìŠ¤í‚µ ëŒ€ìƒ ì„¹ì…˜ í™•ì¸ (ì •ê·œì‹ ê¸°ë°˜)\n",
    "        if should_skip_section(header['title']):\n",
    "            print(f\"   â­ï¸ ìŠ¤í‚µ: {header['title']}\")\n",
    "            continue\n",
    "        \n",
    "        # í˜„ì¬ ì„¹ì…˜ì˜ ì‹œì‘ê³¼ ë ë¼ì¸ ê³„ì‚°\n",
    "        start_line = header['line_num'] + 1  # í—¤ë” ë‹¤ìŒ ë¼ì¸ë¶€í„°\n",
    "        \n",
    "        # ë‹¤ìŒ ë™ì¼ ë ˆë²¨ í—¤ë” ì°¾ê¸° (ë” ì •í™•í•œ ê²½ê³„ ê³„ì‚°)\n",
    "        next_header_line = None\n",
    "        for j in range(i + 1, len(target_headers)):\n",
    "            next_header = target_headers[j]\n",
    "            if next_header['level'] <= header['level']:  # ê°™ê±°ë‚˜ ìƒìœ„ ë ˆë²¨\n",
    "                next_header_line = next_header['line_num']\n",
    "                break\n",
    "        \n",
    "        if next_header_line is not None:\n",
    "            end_line = next_header_line\n",
    "        else:\n",
    "            end_line = len(lines)\n",
    "        \n",
    "        # ì„¹ì…˜ ë‚´ìš© ì¶”ì¶œ\n",
    "        if start_line < len(lines) and start_line < end_line:\n",
    "            section_content = lines[start_line:end_line]\n",
    "        else:\n",
    "            section_content = []\n",
    "        \n",
    "        # ì„¹ì…˜ ìƒì„± (ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "        section = create_section(header, section_content)\n",
    "        \n",
    "        # ë¹ˆ ì„¹ì…˜ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€\n",
    "        if not section['is_empty']:\n",
    "            sections.append(section)\n",
    "            print(f\"   âœ… ìƒì„±: {section['title']} ({section['cleaned_content_length']} ë¼ì¸)\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸ ë¹ˆ ì„¹ì…˜ ì œì™¸: {section['title']}\")\n",
    "    \n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3ë‹¨ê³„ ë‹¨ìœ„&í†µí•© í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "\n",
    "extract_sections() â†’ should_skip_section() \n",
    "\n",
    "                  â†’ create_section()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (2ë‹¨ê³„ ê²°ê³¼ í™œìš©)\n",
      "============================================================\n",
      "âš ï¸ step2_output ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 2ë‹¨ê³„ í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n",
      "ëŒ€ì‹  ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### 3ë‹¨ê³„ ë‹¨ìœ„&í†µí•© í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "print(\"3ë‹¨ê³„ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ (2ë‹¨ê³„ ê²°ê³¼ í™œìš©)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2ë‹¨ê³„ ê²°ê³¼ í™•ì¸\n",
    "if 'step2_output' in locals() and step2_output:\n",
    "    print(\"ğŸ“‹ 2ë‹¨ê³„ ê²°ê³¼ í™•ì¸:\")\n",
    "    print(f\"  - ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼: {len(step2_output)}ê°œ\")\n",
    "    print(f\"  - ì²« ë²ˆì§¸ íŒŒì¼: {step2_output[0]['file_name']}.md\")\n",
    "    \n",
    "    # ì „ì²´ í—¤ë” í†µê³„\n",
    "    total_headers = sum(len(f['headers']) for f in step2_output)\n",
    "    level2_headers = sum(len([h for h in f['headers'] if h['level'] == 2]) for f in step2_output)\n",
    "    print(f\"  - ì´ í—¤ë” ìˆ˜: {total_headers}ê°œ\")\n",
    "    print(f\"  - ë ˆë²¨ 2 í—¤ë”: {level2_headers}ê°œ\")\n",
    "else:\n",
    "    print(\"âš ï¸ step2_output ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 2ë‹¨ê³„ í…ŒìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"ëŒ€ì‹  ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "    step2_output = [\n",
    "        {\n",
    "            'file_name': 'sample',\n",
    "            'lines': [\n",
    "                '# ìƒ˜í”Œ ë¬¸ì„œ',\n",
    "                '',\n",
    "                '> ì´ê²ƒì€ ìƒ˜í”Œ ë¬¸ì„œì…ë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '## ëª©ì°¨',\n",
    "                '',\n",
    "                '1. [ì„¹ì…˜ 1](#ì„¹ì…˜-1)',\n",
    "                '2. [ì„¹ì…˜ 2](#ì„¹ì…˜-2)',\n",
    "                '',\n",
    "                '## 1. ë¡œê·¸ì¸ í˜ì´ì§€',\n",
    "                '',\n",
    "                'ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†í•©ë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '```',\n",
    "                'https://portal.example.com',\n",
    "                '```',\n",
    "                '',\n",
    "                'ë¡œê·¸ì¸ í™”ë©´ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '## 2. ì‚¬ìš©ì ê´€ë¦¬',\n",
    "                '',\n",
    "                'ì‚¬ìš©ì ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',\n",
    "                '',\n",
    "                '### 2.1 ì‚¬ìš©ì ì¶”ê°€',\n",
    "                '',\n",
    "                'ìƒˆë¡œìš´ ì‚¬ìš©ìë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.'\n",
    "            ],\n",
    "            'headers': [\n",
    "                {'line_num': 0, 'level': 1, 'title': 'ìƒ˜í”Œ ë¬¸ì„œ'},\n",
    "                {'line_num': 4, 'level': 2, 'title': 'ëª©ì°¨'},\n",
    "                {'line_num': 9, 'level': 2, 'title': '1. ë¡œê·¸ì¸ í˜ì´ì§€'},\n",
    "                {'line_num': 19, 'level': 2, 'title': '2. ì‚¬ìš©ì ê´€ë¦¬'},\n",
    "                {'line_num': 23, 'level': 3, 'title': '2.1 ì‚¬ìš©ì ì¶”ê°€'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. should_skip_section() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\n",
      "----------------------------------------\n",
      "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ê²°ê³¼:\n",
      "  'ëª©ì°¨' â†’ True âœ… í†µê³¼ (ì •í™•í•œ ëª©ì°¨)\n",
      "  '**ëª©ì°¨**' â†’ True âœ… í†µê³¼ (ë³¼ë“œ ëª©ì°¨)\n",
      "  'Table of Contents' â†’ True âœ… í†µê³¼ (ì˜ë¬¸ ëª©ì°¨)\n",
      "  'ëª©ì°¨ ì„¤ëª…' â†’ False âœ… í†µê³¼ (ëª©ì°¨ê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©)\n",
      "  '1. ë¡œê·¸ì¸ í˜ì´ì§€' â†’ False âœ… í†µê³¼ (ì¼ë°˜ ì„¹ì…˜)\n",
      "  'ì‚¬ìš©ì ê´€ë¦¬' â†’ False âœ… í†µê³¼ (ì¼ë°˜ ì„¹ì…˜)\n",
      "  'Contents Management' â†’ False âœ… í†µê³¼ (contentsê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©)\n",
      "  'TOC ìƒì„±' â†’ False âœ… í†µê³¼ (tocê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©)\n",
      "\n",
      "ğŸ“Š should_skip_section í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n",
      "  - í†µê³¼: 8/8 (100.0%)\n",
      "\n",
      "ğŸ” ì‹¤ì œ ë§¤ë‰´ì–¼ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸:\n",
      "\n",
      "ğŸ“„ sample.md:\n",
      "  â­ï¸ ìŠ¤í‚µ: 'ëª©ì°¨'\n",
      "  âœ… ì²˜ë¦¬: '1. ë¡œê·¸ì¸ í˜ì´ì§€'\n",
      "  âœ… ì²˜ë¦¬: '2. ì‚¬ìš©ì ê´€ë¦¬'\n",
      "\n",
      "ğŸ“ˆ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ í†µê³„:\n",
      "  - ìŠ¤í‚µëœ ì„¹ì…˜: 1ê°œ\n",
      "  - ì²˜ë¦¬í•  ì„¹ì…˜: 2ê°œ\n",
      "  - ì´ ë ˆë²¨ 2 í—¤ë”: 3ê°œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3-1. should_skip_section í•¨ìˆ˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸\n",
    "print(\"1. should_skip_section() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤\n",
    "skip_test_cases = [\n",
    "    (\"ëª©ì°¨\", True, \"ì •í™•í•œ ëª©ì°¨\"),\n",
    "    (\"**ëª©ì°¨**\", True, \"ë³¼ë“œ ëª©ì°¨\"),\n",
    "    (\"Table of Contents\", True, \"ì˜ë¬¸ ëª©ì°¨\"),\n",
    "    (\"ëª©ì°¨ ì„¤ëª…\", False, \"ëª©ì°¨ê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©\"),\n",
    "    (\"1. ë¡œê·¸ì¸ í˜ì´ì§€\", False, \"ì¼ë°˜ ì„¹ì…˜\"),\n",
    "    (\"ì‚¬ìš©ì ê´€ë¦¬\", False, \"ì¼ë°˜ ì„¹ì…˜\"),\n",
    "    (\"Contents Management\", False, \"contentsê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©\"),\n",
    "    (\"TOC ìƒì„±\", False, \"tocê°€ í¬í•¨ëœ ë‹¤ë¥¸ ì œëª©\")\n",
    "]\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ê²°ê³¼:\")\n",
    "test_skip_results = {}\n",
    "\n",
    "for title, expected, description in skip_test_cases:\n",
    "    # ê¸°ì¡´ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (ì •ê·œì‹ ê¸°ë°˜)\n",
    "    try:\n",
    "        result = should_skip_section(title)\n",
    "        status = \"âœ… í†µê³¼\" if result == expected else \"âŒ ì‹¤íŒ¨\"\n",
    "        test_skip_results[title] = result\n",
    "        \n",
    "        print(f\"  '{title}' â†’ {result} {status} ({description})\")\n",
    "        if result != expected:\n",
    "            print(f\"    ì˜ˆìƒ: {expected}, ì‹¤ì œ: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  '{title}' â†’ âŒ ì˜¤ë¥˜: {e}\")\n",
    "        test_skip_results[title] = None\n",
    "\n",
    "print(f\"\\nğŸ“Š should_skip_section í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "passed = sum(1 for title, expected, _ in skip_test_cases if test_skip_results.get(title) == expected)\n",
    "total = len(skip_test_cases)\n",
    "print(f\"  - í†µê³¼: {passed}/{total} ({passed/total*100:.1f}%)\")\n",
    "\n",
    "# ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ” ì‹¤ì œ ë§¤ë‰´ì–¼ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸:\")\n",
    "actual_skip_count = 0\n",
    "actual_process_count = 0\n",
    "\n",
    "for parsed_file in step2_output:\n",
    "    file_name = parsed_file['file_name']\n",
    "    level2_headers = [h for h in parsed_file['headers'] if h['level'] == 2]\n",
    "    \n",
    "    print(f\"\\nğŸ“„ {file_name}.md:\")\n",
    "    for header in level2_headers:\n",
    "        title = header['title']\n",
    "        skip_result = should_skip_section(title)\n",
    "        \n",
    "        if skip_result:\n",
    "            actual_skip_count += 1\n",
    "            print(f\"  â­ï¸ ìŠ¤í‚µ: '{title}'\")\n",
    "        else:\n",
    "            actual_process_count += 1\n",
    "            print(f\"  âœ… ì²˜ë¦¬: '{title}'\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ í†µê³„:\")\n",
    "print(f\"  - ìŠ¤í‚µëœ ì„¹ì…˜: {actual_skip_count}ê°œ\")\n",
    "print(f\"  - ì²˜ë¦¬í•  ì„¹ì…˜: {actual_process_count}ê°œ\")\n",
    "print(f\"  - ì´ ë ˆë²¨ 2 í—¤ë”: {actual_skip_count + actual_process_count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. create_section() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\n",
      "----------------------------------------\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°:\n",
      "  í—¤ë”: {'line_num': 9, 'level': 2, 'title': '1. ë¡œê·¸ì¸ í˜ì´ì§€'}\n",
      "  ì›ë³¸ ë‚´ìš© ë¼ì¸ ìˆ˜: 9\n",
      "  ì›ë³¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: ['ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†í•©ë‹ˆë‹¤.', '', '```']...\n",
      "\n",
      "ğŸ”§ ê¸°ë³¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (preserve_structure=False):\n",
      "  - í—¤ë” ë¼ì¸: 9\n",
      "  - ë‚´ìš© ë²”ìœ„: 10 ~ 18\n",
      "  - ì›ë³¸ ê¸¸ì´: 9\n",
      "  - ì •ë¦¬ëœ ê¸¸ì´: 5\n",
      "  - ì´ ë¬¸ì ìˆ˜: 67\n",
      "  - ë¹ˆ ì„¹ì…˜ ì—¬ë¶€: False\n",
      "  - ì •ë¦¬ëœ ë‚´ìš©: ['ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†í•©ë‹ˆë‹¤.', '```', 'https://portal.example.com', '```', 'ë¡œê·¸ì¸ í™”ë©´ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.']\n",
      "\n",
      "ğŸ”§ êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (preserve_structure=True):\n",
      "  - í—¤ë” ë¼ì¸: 9\n",
      "  - ë‚´ìš© ë²”ìœ„: 10 ~ 18\n",
      "  - ì›ë³¸ ê¸¸ì´: 9\n",
      "  - ì •ë¦¬ëœ ê¸¸ì´: 8\n",
      "  - ì´ ë¬¸ì ìˆ˜: 67\n",
      "  - êµ¬ì¡° ë³´ì¡´: True\n",
      "  - ì •ë¦¬ëœ ë‚´ìš©: ['ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†í•©ë‹ˆë‹¤.', '', '```', 'https://portal.example.com', '```', '', 'ë¡œê·¸ì¸ í™”ë©´ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.', '']\n",
      "\n",
      "ğŸ“Š ë‘ ëª¨ë“œ ë¹„êµ:\n",
      "  - ê¸°ë³¸ ëª¨ë“œ ë¼ì¸ ìˆ˜: 5\n",
      "  - êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ ë¼ì¸ ìˆ˜: 8\n",
      "  - ì°¨ì´: 3 ë¼ì¸\n",
      "\n",
      "ğŸ”§ ë¹ˆ ì„¹ì…˜ í…ŒìŠ¤íŠ¸:\n",
      "  - ë¹ˆ ë‚´ìš© ì…ë ¥: ['', '', '   ', '\\t', '']\n",
      "  - ë¹ˆ ì„¹ì…˜ ê°ì§€: True\n",
      "  - ì •ë¦¬ëœ ê¸¸ì´: 0\n",
      "\n",
      "âœ… 3-2ë‹¨ê³„ ì™„ë£Œ: test_create_section_results ë³€ìˆ˜ ìƒì„±ë¨\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3-2. create_section í•¨ìˆ˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. create_section() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš© í—¤ë”ì™€ ë‚´ìš©\n",
    "test_header = {\n",
    "    'line_num': 9,\n",
    "    'level': 2,\n",
    "    'title': '1. ë¡œê·¸ì¸ í˜ì´ì§€'\n",
    "}\n",
    "\n",
    "test_content = [\n",
    "    'ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†í•©ë‹ˆë‹¤.',\n",
    "    '',\n",
    "    '```',\n",
    "    'https://portal.example.com',\n",
    "    '```',\n",
    "    '',\n",
    "    '',\n",
    "    'ë¡œê·¸ì¸ í™”ë©´ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.',\n",
    "    ''\n",
    "]\n",
    "\n",
    "print(\"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„°:\")\n",
    "print(f\"  í—¤ë”: {test_header}\")\n",
    "print(f\"  ì›ë³¸ ë‚´ìš© ë¼ì¸ ìˆ˜: {len(test_content)}\")\n",
    "print(f\"  ì›ë³¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {test_content[:3]}...\")\n",
    "\n",
    "# ê¸°ë³¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ê¸°ë³¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (preserve_structure=False):\")\n",
    "section_basic = create_section(test_header, test_content, preserve_structure=False)\n",
    "\n",
    "print(f\"  - í—¤ë” ë¼ì¸: {section_basic['header_line']}\")\n",
    "print(f\"  - ë‚´ìš© ë²”ìœ„: {section_basic['content_start_line']} ~ {section_basic['content_end_line']}\")\n",
    "print(f\"  - ì›ë³¸ ê¸¸ì´: {section_basic['original_content_length']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ê¸¸ì´: {section_basic['cleaned_content_length']}\")\n",
    "print(f\"  - ì´ ë¬¸ì ìˆ˜: {section_basic['total_characters']}\")\n",
    "print(f\"  - ë¹ˆ ì„¹ì…˜ ì—¬ë¶€: {section_basic['is_empty']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ë‚´ìš©: {section_basic['content']}\")\n",
    "\n",
    "# êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (preserve_structure=True):\")\n",
    "section_preserve = create_section(test_header, test_content, preserve_structure=True)\n",
    "\n",
    "print(f\"  - í—¤ë” ë¼ì¸: {section_preserve['header_line']}\")\n",
    "print(f\"  - ë‚´ìš© ë²”ìœ„: {section_preserve['content_start_line']} ~ {section_preserve['content_end_line']}\")\n",
    "print(f\"  - ì›ë³¸ ê¸¸ì´: {section_preserve['original_content_length']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ê¸¸ì´: {section_preserve['cleaned_content_length']}\")\n",
    "print(f\"  - ì´ ë¬¸ì ìˆ˜: {section_preserve['total_characters']}\")\n",
    "print(f\"  - êµ¬ì¡° ë³´ì¡´: {section_preserve['preserve_structure']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ë‚´ìš©: {section_preserve['content']}\")\n",
    "\n",
    "# ë‘ ëª¨ë“œ ë¹„êµ\n",
    "print(f\"\\nğŸ“Š ë‘ ëª¨ë“œ ë¹„êµ:\")\n",
    "print(f\"  - ê¸°ë³¸ ëª¨ë“œ ë¼ì¸ ìˆ˜: {section_basic['cleaned_content_length']}\")\n",
    "print(f\"  - êµ¬ì¡° ë³´ì¡´ ëª¨ë“œ ë¼ì¸ ìˆ˜: {section_preserve['cleaned_content_length']}\")\n",
    "print(f\"  - ì°¨ì´: {section_preserve['cleaned_content_length'] - section_basic['cleaned_content_length']} ë¼ì¸\")\n",
    "\n",
    "# ë¹ˆ ì„¹ì…˜ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ë¹ˆ ì„¹ì…˜ í…ŒìŠ¤íŠ¸:\")\n",
    "empty_content = ['', '', '   ', '\\t', '']\n",
    "section_empty = create_section(test_header, empty_content)\n",
    "print(f\"  - ë¹ˆ ë‚´ìš© ì…ë ¥: {empty_content}\")\n",
    "print(f\"  - ë¹ˆ ì„¹ì…˜ ê°ì§€: {section_empty['is_empty']}\")\n",
    "print(f\"  - ì •ë¦¬ëœ ê¸¸ì´: {section_empty['cleaned_content_length']}\")\n",
    "\n",
    "# 3-2ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜ ì €ì¥\n",
    "test_create_section_results = {\n",
    "    'basic_mode': section_basic,\n",
    "    'preserve_mode': section_preserve,\n",
    "    'empty_section': section_empty\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ… 3-2ë‹¨ê³„ ì™„ë£Œ: test_create_section_results ë³€ìˆ˜ ìƒì„±ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2872608888.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m->\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3-3. extract_sections_from_parsed_data í†µí•© í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. extract_sections_from_parsed_data() í†µí•© í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ì²« ë²ˆì§¸ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "test_file = step2_output[0]\n",
    "test_lines = test_file['lines']\n",
    "test_headers = test_file['headers']\n",
    "\n",
    "print(\"ğŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë³´:\")\n",
    "print(f\"  íŒŒì¼ëª…: {test_file['file_name']}.md\")\n",
    "print(f\"  ì´ ë¼ì¸ ìˆ˜: {len(test_lines)}\")\n",
    "print(f\"  ì´ í—¤ë” ìˆ˜: {len(test_headers)}\")\n",
    "\n",
    "# í—¤ë” ë ˆë²¨ë³„ ë¶„í¬\n",
    "header_levels = {}\n",
    "for header in test_headers:\n",
    "    level = header['level']\n",
    "    header_levels[level] = header_levels.get(level, 0) + 1\n",
    "\n",
    "print(f\"  í—¤ë” ë ˆë²¨ ë¶„í¬: {dict(sorted(header_levels.items()))}\")\n",
    "\n",
    "# ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (ë ˆë²¨ 2ë§Œ)\n",
    "print(f\"\\nğŸ”§ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (target_levels=[2]):\")\n",
    "sections_level2 = extract_sections_from_parsed_data(test_lines, test_headers, target_levels=[2])\n",
    "\n",
    "print(f\"\\nğŸ“Š ë ˆë²¨ 2 ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"  - ìƒì„±ëœ ì„¹ì…˜ ìˆ˜: {len(sections_level2)}\")\n",
    "\n",
    "if sections_level2:\n",
    "    print(f\"  - ì„¹ì…˜ ëª©ë¡:\")\n",
    "    for i, section in enumerate(sections_level2, 1):\n",
    "        print(f\"    {i}. '{section['title']}' ({section['cleaned_content_length']} ë¼ì¸, {section['total_characters']} ë¬¸ì)\")\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ ì„¹ì…˜ ìƒì„¸ ì •ë³´\n",
    "    first_section = sections_level2[0]\n",
    "    print(f\"\\nğŸ” ì²« ë²ˆì§¸ ì„¹ì…˜ ìƒì„¸ ì •ë³´:\")\n",
    "    print(f\"  - ì œëª©: {first_section['title']}\")\n",
    "    print(f\"  - ë ˆë²¨: {first_section['level']}\")\n",
    "    print(f\"  - í—¤ë” ë¼ì¸: {first_section['header_line']}\")\n",
    "    print(f\"  - ë‚´ìš© ë²”ìœ„: {first_section['content_start_line']} ~ {first_section['content_end_line']}\")\n",
    "    print(f\"  - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {first_section['content'][:2]}...\")\n",
    "\n",
    "# ë‹¤ì¤‘ ë ˆë²¨ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ë‹¤ì¤‘ ë ˆë²¨ í…ŒìŠ¤íŠ¸ (target_levels=[2, 3]):\")\n",
    "sections_multi = extract_sections_from_parsed_data(test_lines, test_headers, target_levels=[2, 3])\n",
    "\n",
    "print(f\"\\nğŸ“Š ë‹¤ì¤‘ ë ˆë²¨ ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"  - ìƒì„±ëœ ì„¹ì…˜ ìˆ˜: {len(sections_multi)}\")\n",
    "\n",
    "if sections_multi:\n",
    "    print(f\"  - ë ˆë²¨ë³„ ì„¹ì…˜ ë¶„í¬:\")\n",
    "    level_dist = {}\n",
    "    for section in sections_multi:\n",
    "        level = section['level']\n",
    "        level_dist[level] = level_dist.get(level, 0) + 1\n",
    "    \n",
    "    for level in sorted(level_dist.keys()):\n",
    "        print(f\"    ë ˆë²¨ {level}: {level_dist[level]}ê°œ\")\n",
    "    \n",
    "    print(f\"  - ì„¹ì…˜ ëª©ë¡:\")\n",
    "    for i, section in enumerate(sections_multi, 1):\n",
    "        indent = \"  \" * (section['level'] - 1)\n",
    "        print(f\"    {i}. {indent}[L{section['level']}] '{section['title']}' ({section['cleaned_content_length']} ë¼ì¸)\")\n",
    "\n",
    "# ì „ì²´ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ”§ ì „ì²´ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:\")\n",
    "all_sections = []\n",
    "total_processed_files = 0\n",
    "total_skipped_sections = 0\n",
    "total_created_sections = 0\n",
    "\n",
    "for parsed_file in step2_output:\n",
    "    file_name = parsed_file['file_name']\n",
    "    lines = parsed_file['lines']\n",
    "    headers = parsed_file['headers']\n",
    "    \n",
    "    print(f\"\\nğŸ“„ ì²˜ë¦¬ ì¤‘: {file_name}.md\")\n",
    "    \n",
    "    # ì„¹ì…˜ ì¶”ì¶œ\n",
    "    file_sections = extract_sections_from_parsed_data(lines, headers, target_levels=[2])\n",
    "    all_sections.extend(file_sections)\n",
    "    \n",
    "    total_processed_files += 1\n",
    "    level2_count = len([h for h in headers if h['level'] == 2])\n",
    "    created_count = len(file_sections)\n",
    "    skipped_count = level2_count - created_count\n",
    "    \n",
    "    total_created_sections += created_count\n",
    "    total_skipped_sections += skipped_count\n",
    "    \n",
    "    print(f\"  ê²°ê³¼: {created_count}ê°œ ì„¹ì…˜ ìƒì„±, {skipped_count}ê°œ ìŠ¤í‚µ\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì „ì²´ ì²˜ë¦¬ í†µê³„:\")\n",
    "print(f\"  - ì²˜ë¦¬ëœ íŒŒì¼: {total_processed_files}ê°œ\")\n",
    "print(f\"  - ìƒì„±ëœ ì„¹ì…˜: {total_created_sections}ê°œ\")\n",
    "print(f\"  - ìŠ¤í‚µëœ ì„¹ì…˜: {total_skipped_sections}ê°œ\")\n",
    "print(f\"  - í‰ê·  ì„¹ì…˜/íŒŒì¼: {total_created_sections/total_processed_files:.1f}ê°œ\")\n",
    "\n",
    "if all_sections:\n",
    "    total_chars = sum(s['total_characters'] for s in all_sections)\n",
    "    avg_chars = total_chars // len(all_sections)\n",
    "    print(f\"  - ì´ ë¬¸ì ìˆ˜: {total_chars:,}ì\")\n",
    "    print(f\"  - í‰ê·  ì„¹ì…˜ í¬ê¸°: {avg_chars}ì\")\n",
    "\n",
    "# 3-3ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜ ì €ì¥\n",
    "test_extract_sections_results = {\n",
    "    'level2_sections': sections_level2,\n",
    "    'multi_level_sections': sections_multi,\n",
    "    'all_sections': all_sections,\n",
    "    'stats': {\n",
    "        'total_files': total_processed_files,\n",
    "        'total_sections': total_created_sections,\n",
    "        'total_skipped': total_skipped_sections,\n",
    "        'total_characters': total_chars if all_sections else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ… 3-3ë‹¨ê³„ ì™„ë£Œ: test_extract_sections_results ë³€ìˆ˜ ìƒì„±ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ê²°ê³¼ ìš”ì•½\n",
      "============================================================\n",
      "ğŸ“‹ 3ë‹¨ê³„ ìµœì¢… ê²°ê³¼ ë³€ìˆ˜:\n",
      "  - test_skip_results: should_skip_section í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
      "  - test_create_section_results: create_section í…ŒìŠ¤íŠ¸ ê²°ê³¼ (3ê°€ì§€ ëª¨ë“œ)\n",
      "  - test_extract_sections_results: extract_sections í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
      "\n",
      "âš ï¸ ì„¹ì…˜ ë°ì´í„°ê°€ ì—†ì–´ì„œ step3_output ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.\n",
      "\n",
      "âœ… 3ë‹¨ê³„ ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ë‹¤ìŒ ë‹¨ê³„: 4ë‹¨ê³„ ë©”íƒ€ë°ì´í„° ìƒì„± ëª¨ë“ˆ ê°œë°œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3ë‹¨ê³„ ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° 4ë‹¨ê³„ ì¤€ë¹„\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ğŸ“‹ 3ë‹¨ê³„ ìµœì¢… ê²°ê³¼ ë³€ìˆ˜:\")\n",
    "print(f\"  - test_skip_results: should_skip_section í…ŒìŠ¤íŠ¸ ê²°ê³¼\")\n",
    "print(f\"  - test_create_section_results: create_section í…ŒìŠ¤íŠ¸ ê²°ê³¼ (3ê°€ì§€ ëª¨ë“œ)\")\n",
    "print(f\"  - test_extract_sections_results: extract_sections í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼\")\n",
    "\n",
    "# ì „ì²´ í†µê³„ ìš”ì•½\n",
    "if 'test_extract_sections_results' in locals():\n",
    "    stats = test_extract_sections_results['stats']\n",
    "    print(f\"\\nğŸ“Š 3ë‹¨ê³„ ì „ì²´ ì²˜ë¦¬ í†µê³„:\")\n",
    "    print(f\"  - ì²˜ë¦¬ëœ íŒŒì¼: {stats['total_files']}ê°œ\")\n",
    "    print(f\"  - ìƒì„±ëœ ì„¹ì…˜: {stats['total_sections']}ê°œ\")\n",
    "    print(f\"  - ìŠ¤í‚µëœ ì„¹ì…˜: {stats['total_skipped']}ê°œ\")\n",
    "    print(f\"  - ì´ ë¬¸ì ìˆ˜: {stats['total_characters']:,}ì\")\n",
    "    \n",
    "    if stats['total_sections'] > 0:\n",
    "        avg_size = stats['total_characters'] // stats['total_sections']\n",
    "        print(f\"  - í‰ê·  ì„¹ì…˜ í¬ê¸°: {avg_size}ì\")\n",
    "\n",
    "# 4ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë³€ìˆ˜ ì¤€ë¹„\n",
    "if 'test_extract_sections_results' in locals() and test_extract_sections_results['all_sections']:\n",
    "    step3_output = test_extract_sections_results['all_sections']\n",
    "    print(f\"\\nğŸ¯ 4ë‹¨ê³„ë¡œ ì „ë‹¬í•  ë°ì´í„°:\")\n",
    "    print(f\"  - step3_output: {len(step3_output)}ê°œ ì„¹ì…˜\")\n",
    "    print(f\"  - ê° ì„¹ì…˜ í¬í•¨ ì •ë³´: level, title, content, ë©”íƒ€ë°ì´í„°\")\n",
    "    print(f\"  - 4ë‹¨ê³„ ë©”íƒ€ë°ì´í„° ìƒì„± ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ì„¹ì…˜ ë°ì´í„°ê°€ ì—†ì–´ì„œ step3_output ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\nâœ… 3ë‹¨ê³„ ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"ë‹¤ìŒ ë‹¨ê³„: 4ë‹¨ê³„ ë©”íƒ€ë°ì´í„° ìƒì„± ëª¨ë“ˆ ê°œë°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ë‹¨ê³„ í…ìŠ¤íŠ¸ ì •ì œ ëª¨ë“ˆ(í…ìŠ¤íŠ¸ í´ë¦¬ë‹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_markdown_text(text):\n",
    "    \"\"\"\n",
    "    ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ìŒ ìš”ì†Œë“¤ì„ ì œê±°í•©ë‹ˆë‹¤:\n",
    "    - ì½”ë“œ ë¸”ë¡ (```ë¡œ ê°ì‹¸ì§„ ë¶€ë¶„)\n",
    "    - ì¸ë¼ì¸ ì½”ë“œ (`ë¡œ ê°ì‹¸ì§„ ë¶€ë¶„) \n",
    "    - ë§í¬ ([text](url) í˜•ì‹)\n",
    "    - ì´ë¯¸ì§€ (![alt](src) í˜•ì‹)\n",
    "    - HTML íƒœê·¸ (<tag>)\n",
    "    - ê°•ì¡° í‘œì‹œ (**, __, *, _)\n",
    "    - ì¸ìš©êµ¬ (> ë¡œ ì‹œì‘í•˜ëŠ” ì¤„)\n",
    "    - ëª©ë¡ ê¸°í˜¸ (-, *, +)\n",
    "    - í—¤ë” ê¸°í˜¸ (#)\n",
    "    - ìˆ˜í‰ì„  (---, ___, ***)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ì—¬ ë¶ˆí•„ìš”í•œ ìš”ì†Œë¥¼ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ì •ì œí•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: ì •ì œëœ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ì˜ˆì‹œ êµ¬í˜„: ë§ˆí¬ë‹¤ìš´ íƒœê·¸ ì œê±°\n",
    "    return re.sub(r'\\\\[.*?\\\\]', '', text)\n",
    "\n",
    "def remove_empty_lines(text):\n",
    "    \"\"\"\n",
    "    ë¹ˆ ì¤„ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ì²˜ë¦¬í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: ë¹ˆ ì¤„ì´ ì œê±°ëœ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    return '\\\\n'.join([line for line in text.split('\\\\n') if line.strip()])\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì •ê·œí™”í•˜ê³  ì•ë’¤ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ì˜ˆì‹œ:\n",
    "    ì…ë ¥: \"Hello   World  !   \"\n",
    "    ì¶œë ¥: \"Hello World !\"\n",
    "    \n",
    "    ì…ë ¥: \"ì—¬ëŸ¬    ì¤„ì˜     í…ìŠ¤íŠ¸ë¥¼\\n\\n   ì •ê·œí™”   í•©ë‹ˆë‹¤\"  \n",
    "    ì¶œë ¥: \"ì—¬ëŸ¬ ì¤„ì˜ í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™” í•©ë‹ˆë‹¤\"\n",
    "    \n",
    "    Args:\n",
    "        text (str): ì²˜ë¦¬í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: ê³µë°±ì´ ì •ê·œí™”ëœ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ê³µë°±ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ì²˜ë¦¬í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: ê³µë°±ì´ ì •ê·œí™”ëœ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\\\s+', ' ', text).strip()\n",
    "\n",
    "def extract_plain_text(text):\n",
    "    \"\"\"\n",
    "    ë§ˆí¬ë‹¤ìš´ì—ì„œ í”Œë ˆì¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ì²˜ë¦¬í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: í”Œë ˆì¸ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ì˜ˆì‹œ êµ¬í˜„: ë§ˆí¬ë‹¤ìš´ íƒœê·¸ ì œê±° í›„ í…ìŠ¤íŠ¸ ë°˜í™˜\n",
    "    return clean_markdown_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4ë‹¨ê³„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ í…ìŠ¤íŠ¸ ì •ì œ í…ŒìŠ¤íŠ¸:\n",
      "  - ì •ì œëœ í…ìŠ¤íŠ¸: # ì œëª©\\n\\nì´ê²ƒì€ **ìƒ˜í”Œ** í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\n\\n- í•­ëª© 1\\n- í•­ëª© 2\\n\n",
      "  - ë¹ˆ ì¤„ ì œê±°: # ì œëª©\\nì´ê²ƒì€ **ìƒ˜í”Œ** í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\n- í•­ëª© 1\\n- í•­ëª© 2\n",
      "  - ê³µë°± ì •ê·œí™”: # ì œëª©\\nì´ê²ƒì€ **ìƒ˜í”Œ** í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\n- í•­ëª© 1\\n- í•­ëª© 2\n",
      "  - í”Œë ˆì¸ í…ìŠ¤íŠ¸: # ì œëª©\\n\\nì´ê²ƒì€ **ìƒ˜í”Œ** í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\n\\n- í•­ëª© 1\\n- í•­ëª© 2\\n\n",
      "\n",
      "âœ… 4ë‹¨ê³„ ì™„ë£Œ: test_cleaning_results ë³€ìˆ˜ ìƒì„±ë¨\n"
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ ì •ì œ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ”§ í…ìŠ¤íŠ¸ ì •ì œ í…ŒìŠ¤íŠ¸:\")\n",
    "sample_text = '# ì œëª©\\\\n\\\\nì´ê²ƒì€ **ìƒ˜í”Œ** í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\\\\n\\\\n- í•­ëª© 1\\\\n- í•­ëª© 2\\\\n'\n",
    "cleaned_text = clean_markdown_text(sample_text)\n",
    "print(f\"  - ì •ì œëœ í…ìŠ¤íŠ¸: {cleaned_text}\")\n",
    "\n",
    "no_empty_lines = remove_empty_lines(cleaned_text)\n",
    "print(f\"  - ë¹ˆ ì¤„ ì œê±°: {no_empty_lines}\")\n",
    "\n",
    "normalized_text = normalize_whitespace(no_empty_lines)\n",
    "print(f\"  - ê³µë°± ì •ê·œí™”: {normalized_text}\")\n",
    "\n",
    "plain_text = extract_plain_text(sample_text)\n",
    "print(f\"  - í”Œë ˆì¸ í…ìŠ¤íŠ¸: {plain_text}\")\n",
    "\n",
    "# 4ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜ ì €ì¥\n",
    "test_cleaning_results = {\n",
    "    'cleaned_text': cleaned_text,\n",
    "    'no_empty_lines': no_empty_lines,\n",
    "    'normalized_text': normalized_text,\n",
    "    'plain_text': plain_text\n",
    "}\n",
    "print(f\"\\nâœ… 4ë‹¨ê³„ ì™„ë£Œ: test_cleaning_results ë³€ìˆ˜ ìƒì„±ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”íƒ€ë°ì´í„° ìƒì„± í•¨ìˆ˜ë“¤\n",
    "def extract_user_type(text):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ìœ í˜•ì„ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: ì¶”ì¶œëœ ì‚¬ìš©ì ìœ í˜•\n",
    "    \"\"\"\n",
    "    # ì˜ˆì‹œ êµ¬í˜„: íŠ¹ì • í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ìœ í˜• ì¶”ì¶œ\n",
    "    if 'ê´€ë¦¬ì' in text:\n",
    "        return 'ê´€ë¦¬ì'\n",
    "    elif 'ì‚¬ìš©ì' in text:\n",
    "        return 'ì¼ë°˜ ì‚¬ìš©ì'\n",
    "    return 'ì•Œ ìˆ˜ ì—†ìŒ'\n",
    "\n",
    "def extract_manual_type(text):\n",
    "    \"\"\"\n",
    "    ë§¤ë‰´ì–¼ ìœ í˜•ì„ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        str: ì¶”ì¶œëœ ë§¤ë‰´ì–¼ ìœ í˜•\n",
    "    \"\"\"\n",
    "    # ì˜ˆì‹œ êµ¬í˜„: íŠ¹ì • í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë§¤ë‰´ì–¼ ìœ í˜• ì¶”ì¶œ\n",
    "    if 'ì„¤ì¹˜' in text:\n",
    "        return 'ì„¤ì¹˜ ë§¤ë‰´ì–¼'\n",
    "    elif 'ì‚¬ìš©' in text:\n",
    "        return 'ì‚¬ìš©ì ë§¤ë‰´ì–¼'\n",
    "    return 'ì•Œ ìˆ˜ ì—†ìŒ'\n",
    "\n",
    "def find_related_images(text):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ì—ì„œ ê´€ë ¨ ì´ë¯¸ì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: ê´€ë ¨ ì´ë¯¸ì§€ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ì˜ˆì‹œ êµ¬í˜„: ì´ë¯¸ì§€ íŒŒì¼ëª… íŒ¨í„´ ë§¤ì¹­\n",
    "    return re.findall(r'\\\\b\\\\w+\\\\.png\\\\b', text)\n",
    "\n",
    "def generate_manual_metadata(text):\n",
    "    \"\"\"\n",
    "    ë§¤ë‰´ì–¼ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: ìƒì„±ëœ ë©”íƒ€ë°ì´í„°\n",
    "    \"\"\"\n",
    "    user_type = extract_user_type(text)\n",
    "    manual_type = extract_manual_type(text)\n",
    "    images = find_related_images(text)\n",
    "    \n",
    "    return {\n",
    "        'user_type': user_type,\n",
    "        'manual_type': manual_type,\n",
    "        'related_images': images\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ ë©”íƒ€ë°ì´í„° ìƒì„± í…ŒìŠ¤íŠ¸:\n",
      "  - ìƒì„±ëœ ë©”íƒ€ë°ì´í„°: {'user_type': 'ê´€ë¦¬ì', 'manual_type': 'ì„¤ì¹˜ ë§¤ë‰´ì–¼', 'related_images': []}\n",
      "\n",
      "âœ… 5ë‹¨ê³„ ì™„ë£Œ: test_metadata_results ë³€ìˆ˜ ìƒì„±ë¨\n"
     ]
    }
   ],
   "source": [
    "# ë©”íƒ€ë°ì´í„° ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ”§ ë©”íƒ€ë°ì´í„° ìƒì„± í…ŒìŠ¤íŠ¸:\")\n",
    "sample_text = 'ì´ ë§¤ë‰´ì–¼ì€ ê´€ë¦¬ììš© ì„¤ì¹˜ ê°€ì´ë“œì…ë‹ˆë‹¤. ê´€ë ¨ ì´ë¯¸ì§€: diagram.png, setup.png'\n",
    "metadata = generate_manual_metadata(sample_text)\n",
    "print(f\"  - ìƒì„±ëœ ë©”íƒ€ë°ì´í„°: {metadata}\")\n",
    "\n",
    "# 5ë‹¨ê³„ ê²°ê³¼ ë³€ìˆ˜ ì €ì¥\n",
    "test_metadata_results = metadata\n",
    "print(f\"\\nâœ… 5ë‹¨ê³„ ì™„ë£Œ: test_metadata_results ë³€ìˆ˜ ìƒì„±ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detailed_metadata(text, section_title, file_path):\n",
    "    \"\"\"\n",
    "    ìƒì„¸í•œ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        text (str): ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ë‚´ìš©\n",
    "        section_title (str): ì„¹ì…˜ ì œëª©\n",
    "        file_path (str): íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: ìƒì„±ëœ ë©”íƒ€ë°ì´í„°\n",
    "    \"\"\"\n",
    "    # ì˜ˆì‹œë¡œ ìˆ˜ë™ìœ¼ë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±\n",
    "    metadata = {\n",
    "        'manual_type': 'login',  # ì˜ˆì‹œë¡œ ê³ ì •ëœ ê°’\n",
    "        'user_type': 'firstUser',  # ì˜ˆì‹œë¡œ ê³ ì •ëœ ê°’\n",
    "        'section': section_title,\n",
    "        'source_url': f'https://doc.tg-cloud.co.kr/manual/console/{file_path}#{section_title.replace(\" \", \"-\")}',\n",
    "        'image_urls': ['https://doc.tg-cloud.co.kr/.../login.png'],  # ì˜ˆì‹œë¡œ ê³ ì •ëœ ê°’\n",
    "        'file_path': file_path,\n",
    "        'created_at': '2024-01-15T10:30:00Z'  # ì˜ˆì‹œë¡œ ê³ ì •ëœ ê°’\n",
    "    }\n",
    "    return {\n",
    "        'text': text,\n",
    "        'metadata': metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í†µí•© í…ŒìŠ¤íŠ¸ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "============================================================\n",
      "1ë‹¨ê³„: ë°œê²¬ëœ íŒŒì¼ ìˆ˜: 1\n"
     ]
    }
   ],
   "source": [
    "# í†µí•© í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "print(\"í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1ë‹¨ê³„: íŒŒì¼ ì‹œìŠ¤í…œ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\n",
    "test_path = './manual/user/firstUser/namespaces'\n",
    "md_files = scan_directory(test_path)\n",
    "print(f\"1ë‹¨ê³„: ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(md_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– íŒŒì‹± ì¤‘: /Users/gu.han/Documents/AI.WORK/RAG_Master/manual/user/firstUser/namespaces/namespaces.md\n",
      "2ë‹¨ê³„: íŒŒì‹±ëœ íŒŒì¼ ìˆ˜: 1\n"
     ]
    }
   ],
   "source": [
    "# 2ë‹¨ê³„: íŒŒì‹± ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\n",
    "parsed_files = process_markdown_files(test_path)\n",
    "print(f\"2ë‹¨ê³„: íŒŒì‹±ëœ íŒŒì¼ ìˆ˜: {len(parsed_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   â­ï¸ ìŠ¤í‚µ: **ëª©ì°¨**\n",
      "   âœ… ìƒì„±: 1. Namespace ë©”ë‰´ ì§„ì… (5 ë¼ì¸)\n",
      "   âœ… ìƒì„±: 2. Namespace ìƒì„± ì‹ ì²­ (17 ë¼ì¸)\n",
      "   âœ… ìƒì„±: 3. Namespace ìƒì„± í™•ì¸ (5 ë¼ì¸)\n",
      "3ë‹¨ê³„: ì¶”ì¶œëœ ì„¹ì…˜ ìˆ˜: 3\n",
      "3ë‹¨ê³„: ì¶”ì¶œëœ ì„¹ì…˜: {\n",
      "  \"level\": 2,\n",
      "  \"title\": \"1. Namespace ë©”ë‰´ ì§„ì…\",\n",
      "  \"content\": [\n",
      "    \"1. ì¢Œì¸¡ ë©”ë‰´ `Namespaces` ë©”ë‰´ í´ë¦­\",\n",
      "    \"     ![](img/namespace_menu.png)\",\n",
      "    \" - ì¢Œì¸¡ ë©”ë‰´ `Namespaces` ë©”ë‰´ í´ë¦­ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™”ë©´ì— ì§„ì…í•©ë‹ˆë‹¤.\",\n",
      "    \" - ì‹ ê·œ í”„ë¡œì íŠ¸ì— í• ë‹¹ëœ ìœ ì €ì´ë©° í”„ë¡œì íŠ¸ í•˜ìœ„ì— ì†í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì—†ê¸° ë•Œë¬¸ì— ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.\",\n",
      "    \"---\"\n",
      "  ],\n",
      "  \"header_line\": 10,\n",
      "  \"content_start_line\": 11,\n",
      "  \"content_end_line\": 20,\n",
      "  \"original_content_length\": 10,\n",
      "  \"cleaned_content_length\": 5,\n",
      "  \"total_characters\": 170,\n",
      "  \"is_empty\": false,\n",
      "  \"preserve_structure\": false\n",
      "}\n",
      "3ë‹¨ê³„: ì¶”ì¶œëœ ì„¹ì…˜: {\n",
      "  \"level\": 2,\n",
      "  \"title\": \"2. Namespace ìƒì„± ì‹ ì²­\",\n",
      "  \"content\": [\n",
      "    \"1. `ìƒì„±` ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±ì€ ë°”ë¡œ ìƒì„±ë˜ëŠ”ê²ƒì´ ì•„ë‹Œ í•´ë‹¹ `ìƒì„±` ë²„íŠ¼ì„ í†µí•˜ì—¬ ì‹ ì²­ í›„ ìš´ì˜ì/í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ ìŠ¹ì¸ì„ ê±°ì¹œ í›„ì— ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
      "    \"   -  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ í›„ ìƒì„±ê¹Œì§€ì˜ ê²°ì¬ë¼ì¸ì€ ì•„ë˜ì™€ ê°™ì´ ì´ë£¨ì–´ ì§‘ë‹ˆë‹¤.\",\n",
      "    \"      > ìœ ì € ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ > portal ìš´ì˜ì 1ì°¨ ê²°ì¬ ìŠ¹ì¸ > í”„ë¡œì íŠ¸ ê´€ë¦¬ì 2ì°¨ ê²°ì¬ ìŠ¹ì¸\",\n",
      "    \"   - ì•„ë˜ì™€ ê°™ì´ `ìƒì„±` ë²„íŠ¼ì„ í´ë¦­í•˜ê²Œ ë˜ë©´ Namespace ì‹ ì²­ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤. ë¼ëŠ” ì•ˆë‚´ ë¬¸êµ¬ì™€ í•¨ê»˜ í™•ì¸ ë²„íŠ¼ì„ í†µí•˜ì—¬ ì‹ ì²­ í˜ì´ì§€ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
      "    \"     ![](img/namespace_create_button.png)\",\n",
      "    \"2. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ì€ ì•„ë˜ formì„ ì‘ì„± í›„ ì‹ ì²­í•  ìˆ˜ ìˆìœ¼ë©° í•­ëª© ì„ íƒ ë° ì…ë ¥ í›„ í™•ì¸ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì‹ ì²­ì´ ì™„ë£Œ ë©ë‹ˆë‹¤. ì£¼ìš” ì„ íƒ í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\",\n",
      "    \"   - Project: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì†í•˜ê²Œ ë  í”„ë¡œì íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” í•­ëª©ì…ë‹ˆë‹¤.\",\n",
      "    \"   - Cluster: í”„ë¡œì íŠ¸ í•˜ìœ„ì— ì†Œì†ëœ í´ëŸ¬ìŠ¤í„°ì˜ ëª©ë¡ì´ë©° ì‹¤ì œ ì‹ ì²­í•˜ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ë°°í¬ë˜ëŠ” í´ëŸ¬ìŠ¤í„° ì…ë‹ˆë‹¤.\",\n",
      "    \"   - Namespace: ì‹ ì²­í•˜ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì´ë¦„ì…ë‹ˆë‹¤. ê²€ìƒ‰ ë²„íŠ¼ì„ í†µí•˜ì—¬ í´ëŸ¬ìŠ¤í„° í•˜ìœ„ì— ë™ì¼í•œ ì´ë¦„ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì²´í¬í•©ë‹ˆë‹¤.\",\n",
      "    \"   - ì‚¬ìš©ëª©ì : ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì‚¬ìš©ë˜ëŠ” ëª©ì ì„ ì‘ì„±í•˜ëŠ” í•­ëª©ì…ë‹ˆë‹¤.\",\n",
      "    \"   - CPU: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  CPU ìš©ëŸ‰ì…ë‹ˆë‹¤.\",\n",
      "    \"   - Memory(GiB): ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  ë©”ëª¨ë¦¬ ìš©ëŸ‰ì…ë‹ˆë‹¤.\",\n",
      "    \"   - Storage(GiB): ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ì…ë‹ˆë‹¤.\",\n",
      "    \"     ![](img/namespace_application.png)\",\n",
      "    \"3. ì‹ ì²­ì„ ì™„ë£Œí•˜ë©´ ì‹ ì²­ê´€ë¦¬ í™”ë©´ìœ¼ë¡œ ì´ë™í•˜ê²Œ ë˜ë©° ë‚´ê°€ ì‹ ì²­í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª©ë¡ ë° ê²°ì¬ ë‹¨ê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš´ì˜ì > í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ 1,2ì°¨ ìŠ¹ì¸ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¶”ê°€ë˜ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
      "    \"     ![](img/namespace_application_management.png)\",\n",
      "    \"---\"\n",
      "  ],\n",
      "  \"header_line\": 21,\n",
      "  \"content_start_line\": 22,\n",
      "  \"content_end_line\": 48,\n",
      "  \"original_content_length\": 27,\n",
      "  \"cleaned_content_length\": 17,\n",
      "  \"total_characters\": 1049,\n",
      "  \"is_empty\": false,\n",
      "  \"preserve_structure\": false\n",
      "}\n",
      "3ë‹¨ê³„: ì¶”ì¶œëœ ì„¹ì…˜: {\n",
      "  \"level\": 2,\n",
      "  \"title\": \"3. Namespace ìƒì„± í™•ì¸\",\n",
      "  \"content\": [\n",
      "    \"1. ì‹ ì²­ê´€ë¦¬ í™”ë©´ì—ì„œ ìš´ì˜ì, í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ 1,2ì°¨ ìŠ¹ì¸ì´ ì™„ë£Œë˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ìƒì„±ì´ ë˜ë©° í•´ë‹¹ í™”ë©´ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
      "    \"   - ì§ì ‘ ìƒì„±í•œ í”„ë¡œì íŠ¸ ë° í•˜ìœ„ í´ëŸ¬ìŠ¤í„°, ìŠ¹ì¸ ì™„ë£Œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒë‹¨ì—ì„œ ì„ íƒì„ í•œ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë©”ë‰´ì— ì§„ì…í•˜ë©´ ìƒì„±ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
      "    \"   - ì§ì ‘ ì‹ ì²­í•˜ì—¬ ìƒì„±ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë‚´ì—ì„œì˜ ë¶€ì—¬ëœ ê¶Œí•œì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬ì ê¶Œí•œì„ ê°–ê²Œ ë©ë‹ˆë‹¤.\",\n",
      "    \"   - ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± í™•ì¸ ë° íŠ¹ì • í”„ë¡œì íŠ¸ > ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í•˜ìœ„ì— ìœ ì €ì˜ ê¶Œí•œì´ í• ë‹¹ë˜ë©´ ì˜¤í”ˆëœ ë©”ë‰´ì— í•œí•´ì„œ ê°ê°ì˜ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (<U>**ê° ìˆ˜í–‰ ê°€ëŠ¥í•œ ê¸°ëŠ¥ì€ ì¼ë°˜ ì‚¬ìš©ì ë§¤ë‰´ì–¼ ì°¸ì¡°**</U>)\",\n",
      "    \"     ![](img/namespace_create_result.png)\"\n",
      "  ],\n",
      "  \"header_line\": 49,\n",
      "  \"content_start_line\": 50,\n",
      "  \"content_end_line\": 57,\n",
      "  \"original_content_length\": 8,\n",
      "  \"cleaned_content_length\": 5,\n",
      "  \"total_characters\": 395,\n",
      "  \"is_empty\": false,\n",
      "  \"preserve_structure\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 3ë‹¨ê³„: ì„¹ì…˜ ì²˜ë¦¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\n",
    "import json\n",
    "step3_output = []\n",
    "for parsed_file in parsed_files:\n",
    "    sections = extract_sections_from_parsed_data(parsed_file['lines'], parsed_file['headers'])\n",
    "    step3_output.extend(sections)\n",
    "print(f\"3ë‹¨ê³„: ì¶”ì¶œëœ ì„¹ì…˜ ìˆ˜: {len(step3_output)}\")\n",
    "\n",
    "for section in step3_output:\n",
    "    print(f\"3ë‹¨ê³„: ì¶”ì¶œëœ ì„¹ì…˜: {json.dumps(section, indent=2, ensure_ascii=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ë‹¨ê³„: ì •ì œëœ ì„¹ì…˜ ìˆ˜: 3\n",
      "\n",
      "4ë‹¨ê³„: ì •ì œëœ ì„¹ì…˜ 1ë²ˆì§¸ ë‚´ìš©:\n",
      "--------------------------------------------------\n",
      "1. ì¢Œì¸¡ ë©”ë‰´ `Namespaces` ë©”ë‰´ í´ë¦­\\n     ![](img/namespace_menu.png)\\n - ì¢Œì¸¡ ë©”ë‰´ `Namespaces` ë©”ë‰´ í´ë¦­ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™”ë©´ì— ì§„ì…í•©ë‹ˆë‹¤.\\n - ì‹ ê·œ í”„ë¡œì íŠ¸ì— í• ë‹¹ëœ ìœ ì €ì´ë©° í”„ë¡œì íŠ¸ í•˜ìœ„ì— ì†í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì—†ê¸° ë•Œë¬¸ì— ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.\\n---\n",
      "--------------------------------------------------\n",
      "\n",
      "4ë‹¨ê³„: ì •ì œëœ ì„¹ì…˜ 2ë²ˆì§¸ ë‚´ìš©:\n",
      "--------------------------------------------------\n",
      "1. `ìƒì„±` ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±ì€ ë°”ë¡œ ìƒì„±ë˜ëŠ”ê²ƒì´ ì•„ë‹Œ í•´ë‹¹ `ìƒì„±` ë²„íŠ¼ì„ í†µí•˜ì—¬ ì‹ ì²­ í›„ ìš´ì˜ì/í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ ìŠ¹ì¸ì„ ê±°ì¹œ í›„ì— ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   -  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ í›„ ìƒì„±ê¹Œì§€ì˜ ê²°ì¬ë¼ì¸ì€ ì•„ë˜ì™€ ê°™ì´ ì´ë£¨ì–´ ì§‘ë‹ˆë‹¤.\\n      > ìœ ì € ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ > portal ìš´ì˜ì 1ì°¨ ê²°ì¬ ìŠ¹ì¸ > í”„ë¡œì íŠ¸ ê´€ë¦¬ì 2ì°¨ ê²°ì¬ ìŠ¹ì¸\\n   - ì•„ë˜ì™€ ê°™ì´ `ìƒì„±` ë²„íŠ¼ì„ í´ë¦­í•˜ê²Œ ë˜ë©´ Namespace ì‹ ì²­ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤. ë¼ëŠ” ì•ˆë‚´ ë¬¸êµ¬ì™€ í•¨ê»˜ í™•ì¸ ë²„íŠ¼ì„ í†µí•˜ì—¬ ì‹ ì²­ í˜ì´ì§€ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n     ![](img/namespace_create_button.png)\\n2. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ì€ ì•„ë˜ formì„ ì‘ì„± í›„ ì‹ ì²­í•  ìˆ˜ ìˆìœ¼ë©° í•­ëª© ì„ íƒ ë° ì…ë ¥ í›„ í™•ì¸ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì‹ ì²­ì´ ì™„ë£Œ ë©ë‹ˆë‹¤. ì£¼ìš” ì„ íƒ í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\\n   - Project: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì†í•˜ê²Œ ë  í”„ë¡œì íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” í•­ëª©ì…ë‹ˆë‹¤.\\n   - Cluster: í”„ë¡œì íŠ¸ í•˜ìœ„ì— ì†Œì†ëœ í´ëŸ¬ìŠ¤í„°ì˜ ëª©ë¡ì´ë©° ì‹¤ì œ ì‹ ì²­í•˜ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ë°°í¬ë˜ëŠ” í´ëŸ¬ìŠ¤í„° ì…ë‹ˆë‹¤.\\n   - Namespace: ì‹ ì²­í•˜ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì´ë¦„ì…ë‹ˆë‹¤. ê²€ìƒ‰ ë²„íŠ¼ì„ í†µí•˜ì—¬ í´ëŸ¬ìŠ¤í„° í•˜ìœ„ì— ë™ì¼í•œ ì´ë¦„ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì²´í¬í•©ë‹ˆë‹¤.\\n   - ì‚¬ìš©ëª©ì : ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì‚¬ìš©ë˜ëŠ” ëª©ì ì„ ì‘ì„±í•˜ëŠ” í•­ëª©ì…ë‹ˆë‹¤.\\n   - CPU: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  CPU ìš©ëŸ‰ì…ë‹ˆë‹¤.\\n   - Memory(GiB): ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  ë©”ëª¨ë¦¬ ìš©ëŸ‰ì…ë‹ˆë‹¤.\\n   - Storage(GiB): ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ì…ë‹ˆë‹¤.\\n     ![](img/namespace_application.png)\\n3. ì‹ ì²­ì„ ì™„ë£Œí•˜ë©´ ì‹ ì²­ê´€ë¦¬ í™”ë©´ìœ¼ë¡œ ì´ë™í•˜ê²Œ ë˜ë©° ë‚´ê°€ ì‹ ì²­í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª©ë¡ ë° ê²°ì¬ ë‹¨ê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš´ì˜ì > í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ 1,2ì°¨ ìŠ¹ì¸ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¶”ê°€ë˜ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n     ![](img/namespace_application_management.png)\\n---\n",
      "--------------------------------------------------\n",
      "\n",
      "4ë‹¨ê³„: ì •ì œëœ ì„¹ì…˜ 3ë²ˆì§¸ ë‚´ìš©:\n",
      "--------------------------------------------------\n",
      "1. ì‹ ì²­ê´€ë¦¬ í™”ë©´ì—ì„œ ìš´ì˜ì, í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ 1,2ì°¨ ìŠ¹ì¸ì´ ì™„ë£Œë˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ìƒì„±ì´ ë˜ë©° í•´ë‹¹ í™”ë©´ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ì§ì ‘ ìƒì„±í•œ í”„ë¡œì íŠ¸ ë° í•˜ìœ„ í´ëŸ¬ìŠ¤í„°, ìŠ¹ì¸ ì™„ë£Œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒë‹¨ì—ì„œ ì„ íƒì„ í•œ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë©”ë‰´ì— ì§„ì…í•˜ë©´ ìƒì„±ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ì§ì ‘ ì‹ ì²­í•˜ì—¬ ìƒì„±ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë‚´ì—ì„œì˜ ë¶€ì—¬ëœ ê¶Œí•œì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬ì ê¶Œí•œì„ ê°–ê²Œ ë©ë‹ˆë‹¤.\\n   - ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± í™•ì¸ ë° íŠ¹ì • í”„ë¡œì íŠ¸ > ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í•˜ìœ„ì— ìœ ì €ì˜ ê¶Œí•œì´ í• ë‹¹ë˜ë©´ ì˜¤í”ˆëœ ë©”ë‰´ì— í•œí•´ì„œ ê°ê°ì˜ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (<U>**ê° ìˆ˜í–‰ ê°€ëŠ¥í•œ ê¸°ëŠ¥ì€ ì¼ë°˜ ì‚¬ìš©ì ë§¤ë‰´ì–¼ ì°¸ì¡°**</U>)\\n     ![](img/namespace_create_result.png)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ì œ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\n",
    "cleaned_sections = []\n",
    "for section in step3_output:\n",
    "    original_content = '\\\\n'.join(section['content'])\n",
    "    cleaned_content = clean_markdown_text(original_content)\n",
    "    cleaned_sections.append(cleaned_content)\n",
    "print(f\"4ë‹¨ê³„: ì •ì œëœ ì„¹ì…˜ ìˆ˜: {len(cleaned_sections)}\")\n",
    "\n",
    "for i, section in enumerate(cleaned_sections):\n",
    "    print(f\"\\n4ë‹¨ê³„: ì •ì œëœ ì„¹ì…˜ {i+1}ë²ˆì§¸ ë‚´ìš©:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(section)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ë‹¨ê³„: ìƒì„±ëœ ë©”íƒ€ë°ì´í„° ìˆ˜: 3\n",
      "5ë‹¨ê³„: ìƒì„±ëœ ë©”íƒ€ë°ì´í„°: {'user_type': 'ê´€ë¦¬ì', 'manual_type': 'ì‚¬ìš©ì ë§¤ë‰´ì–¼', 'related_images': []}\n",
      "\n",
      "âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 5ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ìƒì„± ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\n",
    "metadata_results = []\n",
    "for cleaned_content in cleaned_sections:\n",
    "    metadata = generate_manual_metadata(cleaned_content)\n",
    "    metadata_results.append(metadata)\n",
    "print(f\"5ë‹¨ê³„: ìƒì„±ëœ ë©”íƒ€ë°ì´í„° ìˆ˜: {len(metadata_results)}\")\n",
    "\n",
    "print(f\"5ë‹¨ê³„: ìƒì„±ëœ ë©”íƒ€ë°ì´í„°: {metadata}\")\n",
    "print(f\"\\nâœ… í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def parse_markdown(manual_type: str, user_type: str, source_url: str, image_url_base: str, markdown_filepath: str) -> List[Dict[str, any]]:\n",
    "    with open(markdown_filepath, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sections = []\n",
    "    current_section = None\n",
    "    image_urls = []\n",
    "    in_toc = False\n",
    "\n",
    "    for line in lines:\n",
    "        # Check for the start of a new section\n",
    "        if line.startswith('##') and not line.startswith('## **ëª©ì°¨**'):\n",
    "            if current_section:\n",
    "                sections.append({\n",
    "                    'manual_type': manual_type,\n",
    "                    'user_type': user_type,\n",
    "                    'section': current_section.strip(),\n",
    "                    'source_url': source_url,\n",
    "                    'image_urls': image_urls\n",
    "                })\n",
    "            current_section = line.strip('# ').strip()\n",
    "            image_urls = []\n",
    "            in_toc = False\n",
    "        elif line.startswith('## **ëª©ì°¨**'):\n",
    "            in_toc = True\n",
    "        elif in_toc:\n",
    "            continue\n",
    "        elif current_section is not None:\n",
    "            # Check for image links\n",
    "            image_match = re.findall(r'!\\[\\]\\((img/[^)]+)\\)', line)\n",
    "            for img in image_match:\n",
    "                image_urls.append(f'{image_url_base}{img}')\n",
    "            #current_section += line\n",
    "            # Only add non-image lines to the section\n",
    "            if not image_match:\n",
    "                current_section += line\n",
    "    # Add the last section if it exists\n",
    "    if current_section:\n",
    "        sections.append({\n",
    "            'manual_type': manual_type,\n",
    "            'user_type': user_type,\n",
    "            'section': current_section.strip(),\n",
    "            'source_url': source_url,\n",
    "            'image_urls': image_urls\n",
    "        })\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"manual_type\": \"login\",\n",
      "    \"user_type\": \"firstUser\",\n",
      "    \"section\": \"1. Namespace ë©”ë‰´ ì§„ì…\\n1. ì¢Œì¸¡ ë©”ë‰´ `Namespaces` ë©”ë‰´ í´ë¦­\\n\\n\\n - ì¢Œì¸¡ ë©”ë‰´ `Namespaces` ë©”ë‰´ í´ë¦­ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™”ë©´ì— ì§„ì…í•©ë‹ˆë‹¤.\\n - ì‹ ê·œ í”„ë¡œì íŠ¸ì— í• ë‹¹ëœ ìœ ì €ì´ë©° í”„ë¡œì íŠ¸ í•˜ìœ„ì— ì†í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì—†ê¸° ë•Œë¬¸ì— ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.\\n\\n---\",\n",
      "    \"source_url\": \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces\",\n",
      "    \"image_urls\": [\n",
      "      \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces/img/namespace_menu.png\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"manual_type\": \"login\",\n",
      "    \"user_type\": \"firstUser\",\n",
      "    \"section\": \"2. Namespace ìƒì„± ì‹ ì²­\\n1. `ìƒì„±` ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±ì€ ë°”ë¡œ ìƒì„±ë˜ëŠ”ê²ƒì´ ì•„ë‹Œ í•´ë‹¹ `ìƒì„±` ë²„íŠ¼ì„ í†µí•˜ì—¬ ì‹ ì²­ í›„ ìš´ì˜ì/í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ ìŠ¹ì¸ì„ ê±°ì¹œ í›„ì— ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   -  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ í›„ ìƒì„±ê¹Œì§€ì˜ ê²°ì¬ë¼ì¸ì€ ì•„ë˜ì™€ ê°™ì´ ì´ë£¨ì–´ ì§‘ë‹ˆë‹¤.\\n\\n      > ìœ ì € ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ > portal ìš´ì˜ì 1ì°¨ ê²°ì¬ ìŠ¹ì¸ > í”„ë¡œì íŠ¸ ê´€ë¦¬ì 2ì°¨ ê²°ì¬ ìŠ¹ì¸\\n         \\n   - ì•„ë˜ì™€ ê°™ì´ `ìƒì„±` ë²„íŠ¼ì„ í´ë¦­í•˜ê²Œ ë˜ë©´ Namespace ì‹ ì²­ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤. ë¼ëŠ” ì•ˆë‚´ ë¬¸êµ¬ì™€ í•¨ê»˜ í™•ì¸ ë²„íŠ¼ì„ í†µí•˜ì—¬ ì‹ ì²­ í˜ì´ì§€ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n\\n2. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‹ ì²­ì€ ì•„ë˜ formì„ ì‘ì„± í›„ ì‹ ì²­í•  ìˆ˜ ìˆìœ¼ë©° í•­ëª© ì„ íƒ ë° ì…ë ¥ í›„ í™•ì¸ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì‹ ì²­ì´ ì™„ë£Œ ë©ë‹ˆë‹¤. ì£¼ìš” ì„ íƒ í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\\n   - Project: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì†í•˜ê²Œ ë  í”„ë¡œì íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” í•­ëª©ì…ë‹ˆë‹¤.  \\n   - Cluster: í”„ë¡œì íŠ¸ í•˜ìœ„ì— ì†Œì†ëœ í´ëŸ¬ìŠ¤í„°ì˜ ëª©ë¡ì´ë©° ì‹¤ì œ ì‹ ì²­í•˜ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ë°°í¬ë˜ëŠ” í´ëŸ¬ìŠ¤í„° ì…ë‹ˆë‹¤.\\n   - Namespace: ì‹ ì²­í•˜ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì´ë¦„ì…ë‹ˆë‹¤. ê²€ìƒ‰ ë²„íŠ¼ì„ í†µí•˜ì—¬ í´ëŸ¬ìŠ¤í„° í•˜ìœ„ì— ë™ì¼í•œ ì´ë¦„ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì²´í¬í•©ë‹ˆë‹¤.\\n   - ì‚¬ìš©ëª©ì : ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì‚¬ìš©ë˜ëŠ” ëª©ì ì„ ì‘ì„±í•˜ëŠ” í•­ëª©ì…ë‹ˆë‹¤.\\n   - CPU: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  CPU ìš©ëŸ‰ì…ë‹ˆë‹¤.\\n   - Memory(GiB): ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  ë©”ëª¨ë¦¬ ìš©ëŸ‰ì…ë‹ˆë‹¤.\\n   - Storage(GiB): ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í• ë‹¹í•  ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ì…ë‹ˆë‹¤.\\n\\n\\n3. ì‹ ì²­ì„ ì™„ë£Œí•˜ë©´ ì‹ ì²­ê´€ë¦¬ í™”ë©´ìœ¼ë¡œ ì´ë™í•˜ê²Œ ë˜ë©° ë‚´ê°€ ì‹ ì²­í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª©ë¡ ë° ê²°ì¬ ë‹¨ê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš´ì˜ì > í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ 1,2ì°¨ ìŠ¹ì¸ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¶”ê°€ë˜ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n\\n---\",\n",
      "    \"source_url\": \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces\",\n",
      "    \"image_urls\": [\n",
      "      \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces/img/namespace_create_button.png\",\n",
      "      \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces/img/namespace_application.png\",\n",
      "      \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces/img/namespace_application_management.png\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"manual_type\": \"login\",\n",
      "    \"user_type\": \"firstUser\",\n",
      "    \"section\": \"3. Namespace ìƒì„± í™•ì¸\\n1. ì‹ ì²­ê´€ë¦¬ í™”ë©´ì—ì„œ ìš´ì˜ì, í”„ë¡œì íŠ¸ ê´€ë¦¬ìì˜ 1,2ì°¨ ìŠ¹ì¸ì´ ì™„ë£Œë˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ìƒì„±ì´ ë˜ë©° í•´ë‹¹ í™”ë©´ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ì§ì ‘ ìƒì„±í•œ í”„ë¡œì íŠ¸ ë° í•˜ìœ„ í´ëŸ¬ìŠ¤í„°, ìŠ¹ì¸ ì™„ë£Œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒë‹¨ì—ì„œ ì„ íƒì„ í•œ í›„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë©”ë‰´ì— ì§„ì…í•˜ë©´ ìƒì„±ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ì§ì ‘ ì‹ ì²­í•˜ì—¬ ìƒì„±ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë‚´ì—ì„œì˜ ë¶€ì—¬ëœ ê¶Œí•œì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬ì ê¶Œí•œì„ ê°–ê²Œ ë©ë‹ˆë‹¤.\\n   - ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± í™•ì¸ ë° íŠ¹ì • í”„ë¡œì íŠ¸ > ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í•˜ìœ„ì— ìœ ì €ì˜ ê¶Œí•œì´ í• ë‹¹ë˜ë©´ ì˜¤í”ˆëœ ë©”ë‰´ì— í•œí•´ì„œ ê°ê°ì˜ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (<U>**ê° ìˆ˜í–‰ ê°€ëŠ¥í•œ ê¸°ëŠ¥ì€ ì¼ë°˜ ì‚¬ìš©ì ë§¤ë‰´ì–¼ ì°¸ì¡°**</U>)\",\n",
      "    \"source_url\": \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces\",\n",
      "    \"image_urls\": [\n",
      "      \"https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces/img/namespace_create_result.png\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "markdown_filepath = './manual/user/firstUser/namespaces/namespaces.md'\n",
    "manual_type = 'login'\n",
    "user_type = 'firstUser'\n",
    "source_url = 'https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces'\n",
    "image_url_base = 'https://doc.tg-cloud.co.kr/manual/console/firstUser/namespaces/'\n",
    "\n",
    "data = parse_markdown(manual_type, user_type, source_url, image_url_base, markdown_filepath)\n",
    "\n",
    "import json\n",
    "print(json.dumps(data, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
