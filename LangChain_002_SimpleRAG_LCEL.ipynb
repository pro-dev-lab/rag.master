{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a898547",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09541448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 파일 수: 1\n",
      "발견된 모든 파일들:\n",
      "['approval.md', 'approval', 'firstUser', 'user', 'manual']\n",
      "데이터 저장 중 오류가 발생했습니다: 'user_type'\n",
      "  1. filename: approval.md, filepath: /Users/gu.han/Documents/AI.WORK/RAG_Master/manual/user/firstUser/approval\n"
     ]
    }
   ],
   "source": [
    "# 2단계 테스트 - 단일 디렉토리 내 모든 파일 처리\n",
    "test_path = \"./manual/user/firstUser/approval\"\n",
    "\n",
    "md_files = scan_directory(test_path)\n",
    "print(f\"발견된 파일 수: {len(md_files)}\")\n",
    "\n",
    "if md_files:\n",
    "    print(\"발견된 모든 파일들:\")\n",
    "    for i, markdown_filepath in enumerate(md_files, 1):\n",
    "        \n",
    "        result = extract_path_components(markdown_filepath)\n",
    "        print(result)\n",
    "\n",
    "       # markdown_filepath = './manual/user/firstUser/namespaces/namespaces.md'\n",
    "        manual_type = result[2]\n",
    "        menu_type =  result[1]\n",
    "        \n",
    "        # source_base_url = 'https://doc.tg-cloud.co.kr/manual/console/'\n",
    "        # image_base_url = 'https://doc.tg-cloud.co.kr/manual/console/'\n",
    "\n",
    "        source_url = source_base_url + manual_type + '/' + menu_type + '/' + menu_type\n",
    "        image_url = image_base_url + manual_type + '/' + menu_type + '/'\n",
    "\n",
    "        # 마크다운 파싱하여 데이터 추출\n",
    "        data_dicts = parse_markdown(manual_type, user_type, source_url, image_url, markdown_filepath,True)\n",
    "        \n",
    "        # Chroma 벡터 DB 생성\n",
    "        emb_model = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\", \n",
    "        )\n",
    "\n",
    "        collection_name = \"manual_user_collection\"\n",
    "        # 컬렉션이 존재하는 경우: 기존 컬렉션을 로드\n",
    "        # 컬렉션이 존재하지 않는 경우: 새로운 컬렉션 생성\n",
    "        chroma_db = Chroma(\n",
    "            collection_name=\"manual_user_collection\",  # 컬렉션 이름 지정\n",
    "            embedding_function=emb_model,             # 임베딩 모델 설정  \n",
    "            persist_directory=\"./chroma_db\",          # 데이터 저장 경로\n",
    "        )\n",
    "\n",
    "\n",
    "        # 데이터를 Chroma DB에 적재\n",
    "        try:\n",
    "            # {\n",
    "            #     \"manual_type\": \"firstUser\",\n",
    "            #     \"user_type\": \"firstUser\",\n",
    "            #     \"section\": \"2. 로그인을 통한 인증 1. 로그인이 되어있지 않은 사용자는 로그인 창에서 ID와 PW를 입력합니다. \n",
    "            #     \"source_url\": \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/login\",\n",
    "            #     \"image_urls\": [\n",
    "            #     \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/img/login_input.png\",\n",
    "            #     \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/img/login_first_menu.png\",\n",
    "            #     \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/img/login_success.png\"\n",
    "            #     ]\n",
    "            # }\n",
    "\n",
    "            # 문서 텍스트와 메타데이터 준비\n",
    "            for data in data_dicts:\n",
    "                texts = data[\"section\"]\n",
    "                metadatas = [\n",
    "                    {\n",
    "                        #\"doc_id\": uuid.uuid4(),\n",
    "                        \"manual_type\": data[\"manual_type\"],\n",
    "                        \"menu_type\": data[\"user_type\"], \n",
    "                        \"source_url\": data[\"source_url\"],\n",
    "                        # 이미지 URL들은 항상 리스트 형태로 저장\n",
    "                        # 단일 URL인 경우에도 리스트로 변환하여 일관된 데이터 구조 유지\n",
    "                        # 예: 단일 URL \"example.com/image.jpg\" -> [\"example.com/image.jpg\"]\n",
    "                        # 예: 다중 URL [\"img1.jpg\", \"img2.jpg\"] -> [\"img1.jpg\", \"img2.jpg\"] 그대로 유지\n",
    "                        \"image_urls\": data[\"image_urls\"] if isinstance(data[\"image_urls\"], list) else [data[\"image_urls\"]]\n",
    "                    }\n",
    "                ]\n",
    "                print(texts)\n",
    "                print(metadatas)\n",
    "                print(\"--------------------------------\")\n",
    "                # Chroma DB에 문서 추가\n",
    "                # chroma_db.add_texts(\n",
    "                #     texts=texts,\n",
    "                #     metadatas=metadatas\n",
    "                # )\n",
    "            \n",
    "            print(f\"데이터베이스에 {len(data_dicts)}개의 청크가 성공적으로 저장되었습니다.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"데이터 저장 중 오류가 발생했습니다: {str(e)}\")\n",
    "        print(f\"  {i}. filename: {os.path.basename(file_path)}, filepath: {os.path.dirname(file_path)}\")\n",
    "else:\n",
    "    print(\"발견된 파일이 없습니다.\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf0a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 파일 수: 1\n",
      "발견된 모든 파일들:\n",
      "['approval.md', 'approval', 'firstUser', 'user', 'manual']\n",
      "데이터 저장 중 오류가 발생했습니다: 'user_type'\n",
      "  1. filename: approval.md, filepath: /Users/gu.han/Documents/AI.WORK/RAG_Master/manual/user/firstUser/approval\n"
     ]
    }
   ],
   "source": [
    "# 2단계 테스트 - 단일 디렉토리 내 모든 파일 처리\n",
    "test_path = \"./manual/user/firstUser/approval\"\n",
    "\n",
    "md_files = scan_directory(test_path)\n",
    "print(f\"발견된 파일 수: {len(md_files)}\")\n",
    "\n",
    "if md_files:\n",
    "    print(\"발견된 모든 파일들:\")\n",
    "    for i, markdown_filepath in enumerate(md_files, 1):\n",
    "        \n",
    "        result = extract_path_components(markdown_filepath)\n",
    "        print(result)\n",
    "\n",
    "       # markdown_filepath = './manual/user/firstUser/namespaces/namespaces.md'\n",
    "        manual_type = result[2]\n",
    "        menu_type =  result[1]\n",
    "        \n",
    "        # source_base_url = 'https://doc.tg-cloud.co.kr/manual/console/'\n",
    "        # image_base_url = 'https://doc.tg-cloud.co.kr/manual/console/'\n",
    "\n",
    "        source_url = source_base_url + manual_type + '/' + menu_type + '/' + menu_type\n",
    "        image_url = image_base_url + manual_type + '/' + menu_type + '/'\n",
    "\n",
    "        # 마크다운 파싱하여 데이터 추출\n",
    "        data_dicts = parse_markdown(manual_type, user_type, source_url, image_url, markdown_filepath,True)\n",
    "        \n",
    "        # Chroma 벡터 DB 생성\n",
    "        emb_model = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\", \n",
    "        )\n",
    "\n",
    "        collection_name = \"manual_user_collection\"\n",
    "        # 컬렉션이 존재하는 경우: 기존 컬렉션을 로드\n",
    "        # 컬렉션이 존재하지 않는 경우: 새로운 컬렉션 생성\n",
    "        chroma_db = Chroma(\n",
    "            collection_name=\"manual_user_collection\",  # 컬렉션 이름 지정\n",
    "            embedding_function=emb_model,             # 임베딩 모델 설정  \n",
    "            persist_directory=\"./chroma_db\",          # 데이터 저장 경로\n",
    "        )\n",
    "\n",
    "\n",
    "        # 데이터를 Chroma DB에 적재\n",
    "        try:\n",
    "            # {\n",
    "            #     \"manual_type\": \"firstUser\",\n",
    "            #     \"user_type\": \"firstUser\",\n",
    "            #     \"section\": \"2. 로그인을 통한 인증 1. 로그인이 되어있지 않은 사용자는 로그인 창에서 ID와 PW를 입력합니다. \n",
    "            #     \"source_url\": \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/login\",\n",
    "            #     \"image_urls\": [\n",
    "            #     \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/img/login_input.png\",\n",
    "            #     \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/img/login_first_menu.png\",\n",
    "            #     \"https://doc.tg-cloud.co.kr/manual/console/firstUser/login/img/login_success.png\"\n",
    "            #     ]\n",
    "            # }\n",
    "\n",
    "            # 문서 텍스트와 메타데이터 준비\n",
    "            for data in data_dicts:\n",
    "                texts = data[\"section\"]\n",
    "                metadatas = [\n",
    "                    {\n",
    "                        #\"doc_id\": uuid.uuid4(),\n",
    "                        \"manual_type\": data[\"manual_type\"],\n",
    "                        \"menu_type\": data[\"user_type\"], \n",
    "                        \"source_url\": data[\"source_url\"],\n",
    "                        # 이미지 URL들은 항상 리스트 형태로 저장\n",
    "                        # 단일 URL인 경우에도 리스트로 변환하여 일관된 데이터 구조 유지\n",
    "                        # 예: 단일 URL \"example.com/image.jpg\" -> [\"example.com/image.jpg\"]\n",
    "                        # 예: 다중 URL [\"img1.jpg\", \"img2.jpg\"] -> [\"img1.jpg\", \"img2.jpg\"] 그대로 유지\n",
    "                        \"image_urls\": data[\"image_urls\"] if isinstance(data[\"image_urls\"], list) else [data[\"image_urls\"]]\n",
    "                    }\n",
    "                ]\n",
    "                print(texts)\n",
    "                print(metadatas)\n",
    "                print(\"--------------------------------\")\n",
    "                # Chroma DB에 문서 추가\n",
    "                # chroma_db.add_texts(\n",
    "                #     texts=texts,\n",
    "                #     metadatas=metadatas\n",
    "                # )\n",
    "            \n",
    "            print(f\"데이터베이스에 {len(data_dicts)}개의 청크가 성공적으로 저장되었습니다.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"데이터 저장 중 오류가 발생했습니다: {str(e)}\")\n",
    "        print(f\"  {i}. filename: {os.path.basename(file_path)}, filepath: {os.path.dirname(file_path)}\")\n",
    "else:\n",
    "    print(\"발견된 파일이 없습니다.\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15f76c",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6d77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800c924",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca641c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18fd5f",
   "metadata": {},
   "source": [
    "`(3) 벡터저장소 로드`  \n",
    "- 저장해 둔 크로마 벡터저장소를 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소에 저장된 문서 수: 24\n"
     ]
    }
   ],
   "source": [
    "# langchain_chroma: 크로마 벡터 데이터베이스를 랭체인과 연동하기 위한 패키지\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# langchain_openai: OpenAI의 임베딩 모델을 랭체인에서 사용하기 위한 패키지\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    ")\n",
    "\n",
    "# Chroma 벡터 저장소의 주요 함수\n",
    "# - _collection.count(): 저장된 문서 수 확인\n",
    "# - delete(): 문서 삭제\n",
    "# - delete_collection(): 컬렉션 전체 삭제\n",
    "# - get(): 문서 조회\n",
    "# - add_documents(): 문서 추가\n",
    "# - similarity_search(): 유사도 검색\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"chroma_test\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    )\n",
    "\n",
    "print(f\"벡터 저장소에 저장된 문서 수: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8114b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0237e",
   "metadata": {},
   "source": [
    "## 2. LangChain LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db4266",
   "metadata": {},
   "source": [
    "### 2.1 Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6650c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]\n"
     ]
    }
   ],
   "source": [
    "# 다중 메시지 전송\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.3, \n",
    "    max_tokens=100,\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"{query}\"),\n",
    "]\n",
    "\n",
    "# 메시지 리스트를 템플릿으로 변환\n",
    "# messages 리스트를 ChatPromptTemplate 객체로 변환\n",
    "# ChatPromptTemplate은 LLM과 대화할 때 사용할 메시지 형식을 정의\n",
    "# from_messages() 메서드는 메시지 리스트를 받아서 템플릿 객체를 생성\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# 템플릿을 출력\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff39eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "템플릿 입력 변수: ['query']\n",
      "메시지 개수: 2\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 입력 변수를 출력\n",
    "# prompt 객체의 주요 속성들을 확인\n",
    "# input_variables: 프롬프트에서 사용되는 변수들의 리스트 (['query'])\n",
    "# template: 원본 프롬프트 템플릿 문자열\n",
    "# template_format: 템플릿의 형식 (기본값: f-string)\n",
    "# validate_template: 템플릿 유효성 검사 여부\n",
    "print(\"템플릿 입력 변수:\", prompt.input_variables)\n",
    "# template_format 속성은 더 이상 지원되지 않으므로 주석 처리\n",
    "# print(\"템플릿 형식:\", prompt.template_format)\n",
    "print(\"메시지 개수:\", len(prompt.messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n",
      "Human: 테슬라 창업자는 누구인가요?\n"
     ]
    }
   ],
   "source": [
    "# input 값을 전달하여 프롬프트를 렌더링\n",
    "# prompt 객체의 format() 메서드를 사용하여 템플릿의 변수를 실제 값으로 대체\n",
    "# prompt: ChatPromptTemplate 객체\n",
    "# format(): 템플릿의 변수를 실제 값으로 치환하는 메서드\n",
    "# query: 템플릿에서 사용할 변수 이름\n",
    "# \"테슬라 창업자는 누구인가요?\": query 변수에 할당될 실제 값\n",
    "# prompt_text: 변수가 대체된 최종 프롬프트 문자열\n",
    "prompt_text = prompt.format(query=\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f0e9bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)와 함께 마틴 에버하르드(Martin Eberhard), 마크 타페닝(Mark Tarpenning), 제프 스프랙(Jeffrey B. Straubel) 등이 있습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로서 회사를 이끌며 큰 성장을 이끌었습니다. 하지만 테슬라는 2003년에\n"
     ]
    }
   ],
   "source": [
    "# 모델에 prompt text를 직접 입력\n",
    "response = llm.invoke(prompt_text)\n",
    "\n",
    "# 모델의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27045656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['query'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]) last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1484624d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x148459b90>, root_client=<openai.OpenAI object at 0x13fb6c090>, root_async_client=<openai.AsyncOpenAI object at 0x148440990>, model_name='gpt-4o-mini', temperature=0.3, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=100)\n"
     ]
    }
   ],
   "source": [
    "# LCEL 체인을 구성\n",
    "# LCEL(LangChain Expression Language)을 사용하여 체인을 구성\n",
    "# prompt와 llm을 파이프(|) 연산자로 연결하여 순차적으로 실행되는 체인을 만듦\n",
    "# 1. prompt: 입력된 query를 포맷팅하여 프롬프트 생성\n",
    "# 2. llm: 생성된 프롬프트를 받아 LLM으로 처리하여 응답 생성\n",
    "# chain 객체는 prompt와 llm을 연결한 파이프라인입니다.\n",
    "# prompt에서 생성된 프롬프트 텍스트가 llm으로 전달되어 처리됩니다.\n",
    "# chain.invoke() 실행 시 llm의 응답이 AIMessage 형태로 반환됩니다.\n",
    "chain = prompt | llm\n",
    "\n",
    "# 체인을 출력\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a65c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'PromptInput',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# 체인의 입력 스키마를 출력\n",
    "# pprint 모듈에서 pprint 함수를 가져옵니다.\n",
    "# pprint는 Python 객체를 보기 좋게 출력해주는 함수입니다.\n",
    "# 복잡한 데이터 구조를 들여쓰기와 줄바꿈을 사용하여 가독성 있게 표시합니다.\n",
    "from pprint import pprint\n",
    "pprint(chain.input_schema.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b371cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk), 마틴 에버하르드(Martin Eberhard), 마크 타페닝(Mark Tarpenning), 제프 스프링어(Jeffrey B. Straubel) 등입니다. 테슬라는 2003년에 설립되었으며, 엘론 머스크는 2004년에 투자자로 참여한 후 CEO로 취임하여 회사를 이끌어왔습니다.\n",
      "\n",
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 주요 인물로 자리잡게 되었습니다. 따라서 테슬라의 창립자와\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 1\n",
    "# 체인의 입력 파라미터는 딕셔너리 형태로 전달\n",
    "# {\"파라미터_이름\": \"파라미터_값\"} 형식으로 작성\n",
    "# 여기서는 \"query\"가 파라미터 이름이고 \"테슬라 창업자는 누구인가요?\"가 값\n",
    "response = chain.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)\n",
    "print()\n",
    "response = chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68e91772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하르드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다. 따라서 테슬라의 창립자들 중\n"
     ]
    }
   ],
   "source": [
    "# 체인을 실행 - 옵션 2\n",
    "# 쿼리 문자열만 전달해도 동작함\n",
    "# LangChain이 내부적으로 적절한 파라미터 이름으로 매핑해주는 것으로 보임\n",
    "response = chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e0da4",
   "metadata": {},
   "source": [
    "### 2.2 Prompt + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ac6ea",
   "metadata": {},
   "source": [
    "`a) 문자열 파싱 - StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de35b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하르드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다. 따라서 테슬라의 창립자들 중', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 27, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'length', 'logprobs': None}, id='run-003959f8-91bf-4476-9108-04ad4da04a03-0', usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response 객체는 LLM의 응답을 담고 있는 AIMessage 객체입니다.\n",
    "# content: LLM이 생성한 실제 텍스트 응답\n",
    "# additional_kwargs: 추가 메타데이터 (예: refusal 등)\n",
    "# response_metadata: 토큰 사용량, 모델명 등의 상세 정보를 포함\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1a73a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 주요 인물로 자리잡게 되었습니다. 따라서 테슬라의 창립자와\n",
      "\n",
      "content='테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 주요 인물로 자리잡게 되었습니다. 따라서 테슬라의 창립자와' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 27, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'length', 'logprobs': None} id='run-8dd82068-6473-484d-b405-cf0ab709965d-0' usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127}\n"
     ]
    }
   ],
   "source": [
    "# StrOutputParser - 문자열 출력을 파싱\n",
    "# langchain_core.output_parsers 모듈에서 StrOutputParser를 가져옵니다.\n",
    "# StrOutputParser는 LLM의 출력을 단순 문자열로 변환해주는 파서입니다.\n",
    "# 복잡한 응답 객체에서 실제 텍스트 내용만 추출하고 싶을 때 유용합니다.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 출력 파서를 실행\n",
    "print(output_parser.invoke(response))\n",
    "print()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2ab22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리비안(Rivian)은 2009년에 설립되었습니다. 이 회사는 전기차를 개발하고 생산하는 기업으로, 특히 전기 픽업 트럭과 SUV에 주력하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "str_chain = prompt | llm  | output_parser\n",
    "\n",
    "query = \"리비안의 설립년도는 언제인가요?\"\n",
    "str_response = str_chain.invoke(query)\n",
    "\n",
    "print(str_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea86ac6",
   "metadata": {},
   "source": [
    "`b) JSON 출력 - JsonOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea62a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"창업자\": \"엘론 머스크\",\\n  \"회사명\": \"테슬라\",\\n  \"설립연도\": 2003,\\n  \"기타정보\": {\\n    \"공동창립자\": [\\n      \"마틴 에버하드\",\\n      \"마크 타페닝\",\\n      \"JB 스트라우벨\"\\n    ],\\n    \"CEO\": \"엘론 머스크\"\\n  }\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 34, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None} id='run-35eec226-ef91-4991-b8d1-eda93cfbd8fe-0' usage_metadata={'input_tokens': 34, 'output_tokens': 93, 'total_tokens': 127}\n",
      "{'창업자': '엘론 머스크', '회사명': '테슬라', '설립연도': 2003, '기타정보': {'공동창립자': ['마틴 에버하드', '마크 타페닝', 'JB 스트라우벨'], 'CEO': '엘론 머스크'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 출력 파서를 생성\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# 체인을 실행 (JSON 출력)\n",
    "json_response = chain.invoke(\"테슬라 창업자는 누구인가요? JSON 형식으로 출력해주세요.\") \n",
    "print(json_response)\n",
    "\n",
    "# 출력 파서를 실행\n",
    "json_parser_output = json_parser.invoke(json_response)\n",
    "print(json_parser_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809cf4f",
   "metadata": {},
   "source": [
    "`c) Schema 지정 - PydanticOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3ec0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "PydanticOutputParser 프롬프트\n",
      "----------------------------------------\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"The title or position of the person.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "========================================\n",
      "Prompt 템플릿\n",
      "----------------------------------------\n",
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"The title or position of the person.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "Human: 테슬라 창업자는 누구인가요?\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# langchain_core.output_parsers의 PydanticOutputParser:\n",
    "# - Pydantic 모델을 사용하여 LLM의 출력을 구조화된 데이터로 파싱하는 파서\n",
    "# - 미리 정의된 스키마에 따라 출력을 검증하고 변환\n",
    "\n",
    "# langchain_core.pydantic_v1의 BaseModel, Field, validator:\n",
    "# - BaseModel: Pydantic의 기본 모델 클래스로 데이터 검증과 직렬화를 제공\n",
    "# - Field: 모델 필드의 메타데이터와 검증 규칙을 정의\n",
    "# - validator: 커스텀 검증 로직을 추가할 수 있는 데코레이터\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "\n",
    "# Pydantic 모델을 생성\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    title: str = Field(..., description=\"The title or position of the person.\")\n",
    "\n",
    "# 출력 파서를 생성\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person)\n",
    "print(\"========================================\")\n",
    "print(\"PydanticOutputParser 프롬프트\")\n",
    "print(\"----------------------------------------\")\n",
    "print(person_parser.get_format_instructions())\n",
    "print(\"========================================\")\n",
    "\n",
    "\n",
    "# Prompt 템플릿을 생성 - Pydantic 모델을 사용\n",
    "# ChatPromptTemplate을 사용하여 프롬프트 템플릿 생성\n",
    "# 1. system 메시지: LLM에게 JSON 형식으로 응답하도록 지시하고, Pydantic 파서의 포맷 지침을 포함\n",
    "# 2. human 메시지: 사용자의 실제 쿼리를 받는 부분\n",
    "# partial() 메서드로 format_instructions를 미리 설정하여 재사용 가능한 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=person_parser.get_format_instructions())\n",
    "\n",
    "print(\"Prompt 템플릿\")\n",
    "print(\"----------------------------------------\")\n",
    "print(prompt.format(query=\"테슬라 창업자는 누구인가요?\"))\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b8a57e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='엘론 머스크', title='CEO 및 공동 창립자')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인을 구성\n",
    "person_chain = prompt | llm | person_parser\n",
    "\n",
    "# 체인을 실행\n",
    "response = person_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "# 체인의 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae49f4",
   "metadata": {},
   "source": [
    "## 3. Chat Completion Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9198b73",
   "metadata": {},
   "source": [
    "`(1) stream`  \n",
    "- 입력에 대한 응답을 실시간 스트림을 생성하여 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b87c23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다."
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for chunk in llm.stream(\"테슬라 창업자는 누구인가요?\"):\n",
    "    # 기본적으로 print 함수는 출력을 할 때마다 줄바꿈을 하지만, 줄바꿈 없이 출력하려면 end=\"\"를 사용하면 됩니다.\n",
    "    # flush=True 옵션을 사용하여 출력 버퍼를 즉시 비웁니다. 데이터를 지연 없이 즉시 출력하는 데 유용합니다.\n",
    "    print(chunk.content, end=\"\", flush=True)  \n",
    "    # time.sleep(0.1)  # 0.1초 대기 (100ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b01677",
   "metadata": {},
   "source": [
    "`(2) batch`  \n",
    "- 입력 리스트에 대한 응답을 배치 단위로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1477bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "테슬라의 창립자는 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)입니다. 이 두 사람은 2003년에 테슬라 모터스를 설립했습니다. 이후 일론 머스크(Elon Musk)가 2004년에 투자자로 참여하면서 회사의 주요 인물 중 하나가 되었고, 이후 CEO로 취임하여 회사의 성장에 큰 영향을 미쳤습니다.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "리비안(Rivian)의 창업자는 RJ 스칼링(RJ Scaringe)입니다. 그는 2009년에 리비안을 설립하였으며, 전기차 및 친환경 차량 개발에 주력하고 있습니다. 리비안은 전기 픽업트럭인 R1T와 전기 SUV인 R1S를 출시하여 주목받고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"테슬라의 창업자는 누구인가요?\",\n",
    "    \"리비안의 창업자는 누구인가요?\",\n",
    "]\n",
    "\n",
    "responses = llm.batch(questions)\n",
    "\n",
    "for response in responses:\n",
    "    response.pretty_print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc16413",
   "metadata": {},
   "source": [
    "## 4. Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734f412",
   "metadata": {},
   "source": [
    "`(1) RunnableParallel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f21024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.')\n"
     ]
    }
   ],
   "source": [
    "# 문서 검색기 생성\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 1}, \n",
    ")\n",
    "\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "retrieved_docs_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "pprint(retrieved_docs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcbc4d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.',\n",
       " 'question': '테슬라 창업자는 누구인가요?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "# RunnableParrellel 구성\n",
    "runnable = RunnableParallel(\n",
    "    {\"context\": itemgetter(\"context\") , \"question\": itemgetter(\"question\")}\n",
    ")\n",
    "\n",
    "# 객체를 실행\n",
    "response = runnable.invoke({\"context\": retrieved_docs_text, \"question\": query})\n",
    "\n",
    "# 응답을 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbeb7d0",
   "metadata": {},
   "source": [
    "`(2) RunnablePassthrough`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b6495f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': {'query': '테슬라 창업자는 누구인가요?'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    question=RunnablePassthrough(),\n",
    ")\n",
    "\n",
    "runnable.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458adb6e",
   "metadata": {},
   "source": [
    "`(3) RunnableLambda`\n",
    "- 정의: 파이썬의 커스텀 함수를 매핑하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "509b3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '테슬라 창업자는 누구인가요?', 'word_count': 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def count_num_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    question=RunnablePassthrough(),\n",
    "    word_count=RunnableLambda(count_num_words),\n",
    ")\n",
    "\n",
    "runnable.invoke(\"테슬라 창업자는 누구인가요?\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7177b",
   "metadata": {},
   "source": [
    "## 5. 전체 RAG 파이프라인 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a953ff",
   "metadata": {},
   "source": [
    "`(1) RAG 프롬프트 템플릿`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9b52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Answer the question based only on the following context.\n",
      "Do not use any external information or knowledge. \n",
      "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
      "\n",
      "[Context]\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "[Question] \n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "\n",
      "[Answer]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt 템플릿을 생성\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "Do not use any external information or knowledge. \n",
    "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿을 출력\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03131d4a",
   "metadata": {},
   "source": [
    "`(2) Retriever Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09b7abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 '\n",
      " '마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다. '\n",
      " '머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.\\n'\n",
      " '\\n'\n",
      " '2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 '\n",
      " '테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 '\n",
      " '세계 전기차 시장의 약 12.9%를 차지했습니다.')\n"
     ]
    }
   ],
   "source": [
    "# 벡터 검색기\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "# 문서 포맷터 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# 체인 구성\n",
    "retriever_chain = retriever | format_docs\n",
    "\n",
    "# 체인을 실행\n",
    "response = retriever_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957eeab",
   "metadata": {},
   "source": [
    "`(3) RAG Chain 연결`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d12f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=100)\n",
    "\n",
    "# 체인 생성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_chain , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "response = rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2b7fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'마틴 에버하드와 마크 타페닝입니다.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 출력\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb9f42",
   "metadata": {},
   "source": [
    "## 6. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57035b9",
   "metadata": {},
   "source": [
    "`(1) invoke 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b207180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steve2/Library/Caches/pypoetry/virtualenvs/langchain-env-9sqiXrer-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    response = rag_chain.invoke(message)\n",
    "    return response\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82f7a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f970ba",
   "metadata": {},
   "source": [
    "`(2) stream 실행` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40b11b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    partial_message = \"\"\n",
    "    for chunk in rag_chain.stream(message):\n",
    "        if chunk is not None:\n",
    "            partial_message = partial_message + chunk\n",
    "            time.sleep(0.1)\n",
    "            yield partial_message\n",
    "\n",
    "# Graiio 인터페이스 생성 \n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "\n",
    "# Graiio 실행  \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be3f36e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# Graiio 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ddd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
