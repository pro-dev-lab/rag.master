{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a898547",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e15f76c",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6d77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800c924",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca641c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0237e",
   "metadata": {},
   "source": [
    "## 2. 벡터 저장소 (Vector Store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db4266",
   "metadata": {},
   "source": [
    "### 2.1 Chroma\n",
    "\n",
    "- 사용자 편의성이 우수한 오픈소스 벡터 저장소\n",
    " - `langchain-chroma` 패키지 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eee632",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소에 문서를 저장할 때 적용할 임베딩 모델\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"ai_sample_collection\",\n",
    "    embedding_function=embeddings_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c20099d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c362a0",
   "metadata": {},
   "source": [
    "`(2) 벡터 저장소 관리`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c8fe3",
   "metadata": {},
   "source": [
    "- 문서 추가: `vector_store.add_documents(documents, ids)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c4567fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5개의 문서가 성공적으로 벡터 저장소에 추가되었습니다.\n",
      "['DOC_1', 'DOC_2', 'DOC_3', 'DOC_4', 'DOC_5']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': ['DOC_1', 'DOC_2', 'DOC_3', 'DOC_4', 'DOC_5'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 한 분야입니다.',\n",
       "  '머신러닝은 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류입니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.',\n",
       "  '컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 1', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 5', 'source': 'AI_textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# 문서 컬렉션\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\"\n",
    "]\n",
    "\n",
    "# Document 객체 생성\n",
    "doc_objects = []\n",
    "# enumerate()를 사용하여 documents 리스트를 순회하면서 인덱스와 내용을 함께 가져옴\n",
    "# start=1로 설정하여 Chapter 번호를 1부터 시작하도록 함\n",
    "for i, content in enumerate(documents, start=1):\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\"source\": \"AI_textbook\", \"chapter\": f\"Chapter {i}\"},\n",
    "    )\n",
    "    doc_objects.append(doc)\n",
    "\n",
    "\n",
    "# 순차적 ID 리스트 생성\n",
    "doc_ids = [f\"DOC_{i}\" for i in range(1, len(doc_objects) + 1)]\n",
    "\n",
    "# 문서를 벡터 저장소에 저장\n",
    "# 벡터 저장소에 문서를 추가하는 메서드\n",
    "# documents: Document 객체 리스트 - 추가할 문서들의 리스트 \n",
    "# ids: 문자열 리스트 - 각 문서에 할당할 고유 ID 리스트\n",
    "# 반환값: 추가된 문서들의 ID 리스트\n",
    "added_doc_ids = chroma_db.add_documents(documents=doc_objects, ids=doc_ids)\n",
    "\n",
    "# 벡터 저장소에 저장된 문서를 확인\n",
    "print(f\"{len(added_doc_ids)}개의 문서가 성공적으로 벡터 저장소에 추가되었습니다.\")\n",
    "print(added_doc_ids)\n",
    "\n",
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d28387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "쿼리: 인공지능과 머신러닝의 관계는?\n",
      "가장 유사한 문서:\n",
      "- 머신러닝은 인공지능의 하위 분야입니다. [출처: AI_textbook, Chapter 2]\n",
      "- 딥러닝은 머신러닝의 한 종류입니다. [출처: AI_textbook, Chapter 3]\n"
     ]
    }
   ],
   "source": [
    "# 저장된 문서 검색\n",
    "query = \"인공지능과 머신러닝의 관계는?\"\n",
    "# 코사인 유사도를 사용하여 쿼리와 가장 유사한 문서 2개를 검색\n",
    "# 코사인 유사도는 두 벡터 간의 각도를 기반으로 유사도를 측정\n",
    "# k=2는 상위 2개의 가장 유사한 문서를 반환\n",
    "\n",
    "# 코사인 유사도는 두 벡터 간의 각도의 코사인 값을 이용하여 유사도를 측정하는 방법입니다.\n",
    "# 두 벡터가 같은 방향을 가리키면 코사인 값이 1이 되고, 수직이면 0, 반대 방향이면 -1이 됩니다.\n",
    "# 즉, 코사인 유사도가 1에 가까울수록 두 벡터(문서)가 유사하다는 의미입니다.\n",
    "\n",
    "# 코사인 유사도는 벡터의 방향 유사도를 측정하는 지표입니다.\n",
    "# 두 벡터가 이루는 각도의 코사인 값을 계산하여 -1에서 1 사이의 값을 가집니다.\n",
    "# 1에 가까울수록 방향이 유사하고, -1에 가까울수록 반대 방향임을 의미합니다.\n",
    "results = chroma_db.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"\\n쿼리: {query}\")\n",
    "print(\"가장 유사한 문서:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1671f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['DOC_1', 'DOC_2', 'DOC_3', 'DOC_4', 'DOC_5'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 한 분야입니다.',\n",
       "  '머신러닝은 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류입니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.',\n",
       "  '컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 1', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 5', 'source': 'AI_textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 저장된 컬렉션 데이터 확인\n",
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7afc913",
   "metadata": {},
   "source": [
    "- 문서 수정: `vector_store.update_document(document_id, document)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6690acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 업데이트 완료\n"
     ]
    }
   ],
   "source": [
    "# 업데이트할 문서 생성\n",
    "updated_document_1 = Document(\n",
    "    page_content=\"인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다.\",\n",
    "    metadata={\"source\": \"AI_textbook\", \"chapter\": \"Chapter 1\"},\n",
    ")\n",
    "\n",
    "updated_document_2 = Document(\n",
    "    page_content=\"머신러닝은 데이터로부터 학습하여 예측과 결정을 내리는 인공지능의 하위 분야입니다.\",\n",
    "    metadata={\"source\": \"AI_textbook\", \"chapter\": \"Chapter 2\"},\n",
    ")\n",
    "\n",
    "updated_document_3 = Document(\n",
    "    page_content=\"딥러닝은 머신러닝의 한 종류로, 심층 신경망을 사용하여 학습합니다.\",\n",
    "    metadata={\"source\": \"AI_textbook\", \"chapter\": \"Chapter 3\"},\n",
    ")\n",
    "\n",
    "\n",
    "# 단일 문서 업데이트\n",
    "# update_document() 메서드를 사용하여 단일 문서를 업데이트합니다.\n",
    "# 파라미터:\n",
    "#   - document_id: 업데이트할 문서의 고유 ID (str)\n",
    "#   - document: 업데이트할 새로운 Document 객체\n",
    "#     - page_content: 문서의 내용\n",
    "#     - metadata: 문서의 메타데이터 (source, chapter 등)\n",
    "# 반환값: 없음\n",
    "chroma_db.update_document(document_id=\"DOC_1\", document=updated_document_1)\n",
    "\n",
    "# 여러 문서 한 번에 업데이트\n",
    "chroma_db.update_documents(\n",
    "    ids=[\"DOC_2\", \"DOC_3\"],\n",
    "    documents=[updated_document_2, updated_document_3]\n",
    ")\n",
    "\n",
    "print(\"문서 업데이트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "783c5317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "쿼리: 인공지능과 머신러닝의 관계는?\n",
      "가장 유사한 문서:\n",
      "- 머신러닝은 데이터로부터 학습하여 예측과 결정을 내리는 인공지능의 하위 분야입니다. [출처: AI_textbook, Chapter 2]\n",
      "- 인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다. [출처: AI_textbook, Chapter 1]\n"
     ]
    }
   ],
   "source": [
    "# 저장된 문서 검색 예시\n",
    "query = \"인공지능과 머신러닝의 관계는?\"\n",
    "results = chroma_db.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"\\n쿼리: {query}\")\n",
    "print(\"가장 유사한 문서:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e86775",
   "metadata": {},
   "source": [
    "- 문서 삭제: `vector_store.delete(ids)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f006dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db.delete(ids=[\"DOC_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "532fa81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['DOC_1', 'DOC_2', 'DOC_3', 'DOC_4'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다.',\n",
       "  '머신러닝은 데이터로부터 학습하여 예측과 결정을 내리는 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류로, 심층 신경망을 사용하여 학습합니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 1', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬렉션 확인\n",
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c52c55",
   "metadata": {},
   "source": [
    "`(3) 문서 검색`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057e97b",
   "metadata": {},
   "source": [
    "- 유사도 검색\n",
    "    - 주어진 쿼리와 가장 유사한 문서를 반환\n",
    "    -  k=2는 상위 2개의 결과를 반환하도록 지정\n",
    "    - filter를 사용하여 특정 출처의 문서만 검색 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1705538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 검색 결과:\n",
      "- 머신러닝은 데이터로부터 학습하여 예측과 결정을 내리는 인공지능의 하위 분야입니다. [출처: AI_textbook, Chapter 2]\n",
      "- 인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다. [출처: AI_textbook, Chapter 1]\n"
     ]
    }
   ],
   "source": [
    "query = \"인공지능과 머신러닝의 차이점은 무엇인가요?\"\n",
    "results = chroma_db.similarity_search(\n",
    "    query,\n",
    "    k=2,\n",
    "    # filter 파라미터:\n",
    "    # - 검색 결과를 필터링하는 조건을 지정\n",
    "    # - 메타데이터의 특정 필드를 기준으로 문서를 필터링\n",
    "    # - 예: source가 \"AI_textbook\"인 문서만 검색\n",
    "    # - 필수값 여부: 선택 사항 (Optional)\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(\"유사도 검색 결과:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadac15f",
   "metadata": {},
   "source": [
    "- 유사도 점수가 포함된 검색\n",
    "    - 유사도 점수를 함께 반환\n",
    "    - 점수가 낮을수록 더 유사한 것을 의미 (거리 기준으로 점수가 산정되기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5862d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수가 포함된 유사도 검색 결과:\n",
      "\n",
      "- 점수: 0.5772\n",
      "  내용: 딥러닝은 머신러닝의 한 종류로, 심층 신경망을 사용하여 학습합니다.\n",
      "  [출처: AI_textbook, Chapter 3]\n",
      "\n",
      "- 점수: 0.7292\n",
      "  내용: 인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다.\n",
      "  [출처: AI_textbook, Chapter 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"딥러닝은 어떤 분야에서 사용되나요?\"\n",
    "# similarity_search_with_score() 함수\n",
    "# - 용도: 주어진 쿼리와 가장 유사한 문서를 검색하고, 각 문서의 유사도 점수를 함께 반환\n",
    "# - 파라미터:\n",
    "#   - query: 검색할 텍스트 쿼리 (필수)\n",
    "#   - k: 반환할 결과의 개수 (선택, 기본값=4)\n",
    "#   - filter: 메타데이터 기반 필터링 조건 (선택)\n",
    "# - 반환값: (Document, float) 튜플의 리스트\n",
    "#   - Document: 검색된 문서 객체\n",
    "#   - float: 유사도 점수 (낮을수록 더 유사함)\n",
    "results = chroma_db.similarity_search_with_score(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(\"점수가 포함된 유사도 검색 결과:\\n\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\"  [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564e3cb",
   "metadata": {},
   "source": [
    "- 관련성 점수가 포함된 검색\n",
    "    - 문서와 함께 0에서 1 사이의 관련성 점수를 반환\n",
    "    - 0은 가장 관련성이 낮고, 1은 가장 관련성이 높음을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85309681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝은 어떤 분야에서 사용되나요?\n",
      "\n",
      "검색 결과 (관련성 점수 포함):\n",
      "- 관련성 점수: 0.5919\n",
      "  내용: 딥러닝은 머신러닝의 한 종류로, 심층 신경망을 사용하여 학습합니다.\n",
      "  [출처: AI_textbook, Chapter 3]\n",
      "\n",
      "- 관련성 점수: 0.4844\n",
      "  내용: 인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다.\n",
      "  [출처: AI_textbook, Chapter 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"딥러닝은 어떤 분야에서 사용되나요?\"\n",
    "\n",
    "# similarity_search_with_relevance_scores() 함수\n",
    "# - 용도: 주어진 쿼리와 가장 유사한 문서를 검색하고, 0~1 사이의 관련성 점수를 함께 반환\n",
    "# - 파라미터:\n",
    "#   - query: 검색할 텍스트 쿼리 (필수)\n",
    "#   - k: 반환할 결과의 개수 (선택, 기본값=4)\n",
    "#   - filter: 메타데이터 기반 필터링 조건 (선택)\n",
    "# - 반환값: (Document, float) 튜플의 리스트\n",
    "#   - Document: 검색된 문서 객체\n",
    "#   - float: 관련성 점수 (1에 가까울수록 더 관련성이 높음)\n",
    "\n",
    "# similarity_search_with_score()는 벡터 간 거리(L2/유클리디안)를 점수로 사용\n",
    "# similarity_search_with_relevance_scores()는 코사인 유사도를 0~1로 정규화한 점수 사용\n",
    "results = chroma_db.similarity_search_with_relevance_scores(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"\\n검색 결과 (관련성 점수 포함):\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 관련성 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\"  [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c61a6",
   "metadata": {},
   "source": [
    "`(4) 벡터 저장소 로드`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d89ec8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['DOC_1', 'DOC_2', 'DOC_3', 'DOC_4'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다.',\n",
       "  '머신러닝은 데이터로부터 학습하여 예측과 결정을 내리는 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류로, 심층 신경망을 사용하여 학습합니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 1', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db2 = Chroma(\n",
    "    collection_name=\"ai_sample_collection\",\n",
    "    embedding_function=embeddings_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "chroma_db2.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fba19e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝은 어떤 분야에서 사용되나요?\n",
      "\n",
      "검색 결과 (관련성 점수 포함):\n",
      "- 관련성 점수: 0.5919\n",
      "  내용: 딥러닝은 머신러닝의 한 종류로, 심층 신경망을 사용하여 학습합니다.\n",
      "  [출처: AI_textbook, Chapter 3]\n",
      "\n",
      "- 관련성 점수: 0.4844\n",
      "  내용: 인공지능은 컴퓨터 과학의 핵심 분야 중 하나로, 기계학습과 딥러닝을 포함합니다.\n",
      "  [출처: AI_textbook, Chapter 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 미리 임베딩된 쿼리 벡터를 사용하여 검색\n",
    "query = \"딥러닝은 어떤 분야에서 사용되나요?\"\n",
    "results = chroma_db2.similarity_search_with_relevance_scores(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"\\n검색 결과 (관련성 점수 포함):\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 관련성 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\"  [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80551893",
   "metadata": {},
   "source": [
    "### 2.2 FAISS(Facebook AI Similarity Search)\n",
    "\n",
    "- 효율적인 벡터 유사도 검색 및 클러스터링을 위한 오픈소스 벡터 저장소 \n",
    "- `faiss-cpu` 패키지 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ecb88",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 초기화`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "392cd940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 인덱스 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "# 벡터 저장소에 문서를 저장할 때 적용할 임베딩 모델\n",
    "# langchain_huggingface.embeddings: HuggingFace의 임베딩 모델을 LangChain에서 사용할 수 있게 해주는 패키지\n",
    "# HuggingFaceEmbeddings: 텍스트를 벡터로 변환하는 임베딩 모델 클래스\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")  # bge-m3 모델 사용\n",
    "\n",
    "# faiss: Facebook AI가 개발한 효율적인 벡터 유사도 검색 라이브러리\n",
    "import faiss\n",
    "\n",
    "# langchain_community.docstore.in_memory: 문서를 메모리에 저장하는 문서 저장소\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# langchain_community.vectorstores: 다양한 벡터 저장소를 제공하는 패키지\n",
    "# FAISS: Facebook의 벡터 검색 라이브러리를 LangChain에서 사용할 수 있게 래핑한 클래스\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 인덱스 초기화 (유클리드 거리 사용)\n",
    "# FAISS 벡터 저장소를 위한 인덱스를 초기화합니다.\n",
    "# - IndexFlatL2: L2(유클리드) 거리를 사용하는 기본 인덱스 타입\n",
    "#   - L2 거리: 두 벡터 간의 직선 거리를 계산하는 방식\n",
    "# - \"hello world\"는 임베딩 모델의 출력 차원을 알아내기 위한 샘플 텍스트\n",
    "#   - 임베딩 모델은 어떤 입력이든 동일한 차원(1024)의 벡터를 출력\n",
    "#   - 실제 내용은 중요하지 않음, 차원 수만 필요\n",
    "faiss_index = faiss.IndexFlatL2(len(embeddings_model.embed_query(\"hello world\")))\n",
    "print(\"FAISS 인덱스 초기화 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc3e9a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAISS 벡터 저장소의 벡터 차원 수 (임베딩 차원 수)\n",
    "# FAISS 벡터 저장소의 벡터 차원 수를 확인합니다.\n",
    "# - faiss_index.d: FAISS 인덱스의 벡터 차원 수를 반환하는 속성\n",
    "# - bge-m3 모델은 1024 차원의 벡터를 생성합니다.\n",
    "faiss_index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed65547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAISS 벡터 저장소 생성\n",
    "# FAISS 클래스의 주요 파라미터:\n",
    "# - embedding_function: 텍스트를 벡터로 변환하는 임베딩 모델\n",
    "#   - HuggingFaceEmbeddings 모델(bge-m3)을 사용하여 1024차원 벡터 생성\n",
    "# - index: FAISS 인덱스 객체 \n",
    "#   - IndexFlatL2를 사용하여 L2(유클리드) 거리 기반 유사도 검색\n",
    "# - docstore: 문서 저장소\n",
    "#   - InMemoryDocstore()를 사용하여 문서를 메모리에 저장\n",
    "# - index_to_docstore_id: 인덱스 ID와 문서 ID 간의 매핑\n",
    "#   - 빈 딕셔너리로 시작하고 문서 추가시 자동으로 매핑 생성\n",
    "faiss_db = FAISS(\n",
    "    embedding_function=embeddings_model,  # 텍스트 임베딩 모델\n",
    "    index=faiss_index,                   # FAISS 인덱스\n",
    "    docstore=InMemoryDocstore(),         # 메모리 기반 문서 저장소\n",
    "    # docstore=DocstoreExplorer(\"./docstore\"),  # 디스크 기반 문서 저장소\n",
    "    index_to_docstore_id={},             # 인덱스-문서 ID 매핑\n",
    ")\n",
    "\n",
    "# 저장된 문서의 갯수 확인\n",
    "# index.ntotal: FAISS 인덱스에 저장된 전체 벡터의 수를 반환\n",
    "faiss_db.index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1690c0",
   "metadata": {},
   "source": [
    "`(2) 벡터 저장소 관리`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf59cf4",
   "metadata": {},
   "source": [
    "- 문서 추가: `vector_store.add_documents(documents, ids)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ce50ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5개의 문서가 성공적으로 벡터 저장소에 추가되었습니다.\n",
      "['DOC_1', 'DOC_2', 'DOC_3', 'DOC_4', 'DOC_5']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# langchain_core.documents에서 Document 클래스를 임포트합니다.\n",
    "# Document 클래스는 텍스트 콘텐츠와 메타데이터를 포함하는 문서 객체를 생성하는데 사용됩니다.\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 인공지능 관련 텍스트로 구성된 문서 컬렉션을 리스트로 정의합니다.\n",
    "# 각 문자열은 인공지능의 다양한 분야에 대한 설명을 담고 있습니다.\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\", \n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 방법을 연구합니다.\"\n",
    "]\n",
    "\n",
    "# Document 객체의 리스트를 생성합니다.\n",
    "# enumerate를 사용하여 각 문서에 1부터 시작하는 인덱스를 부여합니다.\n",
    "doc_objects = []\n",
    "for i, content in enumerate(documents, start=1):\n",
    "    # 각 문서마다 Document 객체를 생성합니다.\n",
    "    # - page_content: 실제 문서 내용\n",
    "    # - metadata: 문서의 출처(AI_textbook)와 장 번호(Chapter N) 정보\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\"source\": \"AI_textbook\", \"chapter\": f\"Chapter {i}\"},\n",
    "    )\n",
    "    doc_objects.append(doc)\n",
    "\n",
    "# 문서 식별을 위한 고유 ID 리스트를 생성합니다.\n",
    "# 'DOC_1'부터 'DOC_5'까지의 ID를 생성합니다.\n",
    "doc_ids = [f\"DOC_{i}\" for i in range(1, len(doc_objects) + 1)]\n",
    "\n",
    "# 생성된 Document 객체들을 FAISS 벡터 저장소에 추가합니다.\n",
    "# add_documents 메서드는 문서와 해당 ID를 받아 벡터화하여 저장합니다.\n",
    "added_doc_ids = faiss_db.add_documents(documents=doc_objects, ids=doc_ids)\n",
    "\n",
    "# 벡터 저장소에 추가된 문서의 수와 ID 목록을 출력합니다.\n",
    "print(f\"{len(added_doc_ids)}개의 문서가 성공적으로 벡터 저장소에 추가되었습니다.\")\n",
    "print(added_doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c16ef7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 문서의 갯수 확인\n",
    "# faiss_db.index.ntotal: FAISS 벡터 저장소에 저장된 총 벡터(문서)의 수를 반환\n",
    "# ntotal 속성은 현재 인덱스에 포함된 벡터의 총 개수를 나타냄\n",
    "faiss_db.index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f41f02",
   "metadata": {},
   "source": [
    "- 문서 삭제: `vector_store.delete(ids)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "572dd45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_db.delete(ids=[\"DOC_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de547f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬렉션 확인\n",
    "faiss_db.index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6187ee82",
   "metadata": {},
   "source": [
    "`(3) 문서 검색`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24f7fb",
   "metadata": {},
   "source": [
    "- 유사도 검색\n",
    "    - 주어진 쿼리와 가장 유사한 문서를 반환\n",
    "    - k=2는 상위 2개의 결과를 반환하도록 지정\n",
    "    - filter를 사용하여 특정 출처의 문서만 검색 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c30909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 검색 결과:\n",
      "- 머신러닝은 인공지능의 하위 분야입니다. [출처: AI_textbook, Chapter 2]\n",
      "- 딥러닝은 머신러닝의 한 종류입니다. [출처: AI_textbook, Chapter 3]\n"
     ]
    }
   ],
   "source": [
    "query = \"인공지능과 머신러닝의 차이점은 무엇인가요?\"\n",
    "results = faiss_db.similarity_search(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(\"유사도 검색 결과:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab435b13",
   "metadata": {},
   "source": [
    "- 유사도 점수가 포함된 검색\n",
    "    - 유사도 점수를 함께 반환\n",
    "    - 점수가 낮을수록 더 유사한 것을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d4f9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수가 포함된 유사도 검색 결과:\n",
      "\n",
      "- 점수: 0.6517\n",
      "  내용: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "  [출처: AI_textbook, Chapter 3]\n",
      "\n",
      "- 점수: 0.8442\n",
      "  내용: 머신러닝은 인공지능의 하위 분야입니다.\n",
      "  [출처: AI_textbook, Chapter 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"딥러닝은 어떤 분야에서 사용되나요?\"\n",
    "\n",
    "# similarity_search_with_score() 함수는 similarity_search()와 유사하지만 \n",
    "# 검색 결과와 함께 유사도 점수를 반환한다는 점이 다릅니다.\n",
    "# similarity_search()는 문서만 반환하는 반면,\n",
    "# similarity_search_with_score()는 (문서, 점수) 튜플의 리스트를 반환합니다.\n",
    "# 점수는 L2 거리를 나타내며 값이 작을수록 더 유사함을 의미합니다.\n",
    "results = faiss_db.similarity_search_with_score(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(\"점수가 포함된 유사도 검색 결과:\\n\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\"  [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc4a46",
   "metadata": {},
   "source": [
    "- 관련성 점수가 포함된 검색\n",
    "    - 문서와 함께 0에서 1 사이의 관련성 점수를 반환\n",
    "    - 0은 가장 관련성이 낮고, 1은 가장 관련성이 높음을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e35b303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝은 어떤 분야에서 사용되나요?\n",
      "\n",
      "검색 결과 (관련성 점수 포함):\n",
      "- 관련성 점수: 0.5392\n",
      "  내용: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "  [출처: AI_textbook, Chapter 3]\n",
      "\n",
      "- 관련성 점수: 0.4031\n",
      "  내용: 머신러닝은 인공지능의 하위 분야입니다.\n",
      "  [출처: AI_textbook, Chapter 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"딥러닝은 어떤 분야에서 사용되나요?\"\n",
    "# similarity_search_with_relevance_scores() 함수는 검색 결과와 함께 0~1 사이의 관련성 점수를 반환합니다.\n",
    "# similarity_search_with_score()는 L2 거리 기반 점수(낮을수록 유사)를 반환하는 반면,\n",
    "# 이 함수는 코사인 유사도 기반의 정규화된 점수(높을수록 유사)를 반환합니다.\n",
    "#\n",
    "# 파라미터:\n",
    "# - query: 검색할 쿼리 문자열\n",
    "# - k: 반환할 최대 문서 수 (기본값: 4)\n",
    "# - filter: 검색 결과를 필터링할 조건 (예: {\"source\": \"AI_textbook\"})\n",
    "# 코사인 유사도는 두 벡터 간의 각도를 기반으로 유사도를 측정합니다.\n",
    "# - 값의 범위: -1 ~ 1 (1에 가까울수록 유사)\n",
    "# - 방향의 유사성을 측정하며 크기는 고려하지 않음\n",
    "# - 정규화된 벡터에서 잘 동작\n",
    "\n",
    "# L2 거리(유클리디안 거리)는 두 벡터 간의 실제 거리를 계산합니다.\n",
    "# - 값의 범위: 0 ~ ∞ (0에 가까울수록 유사) \n",
    "# - 벡터의 크기와 방향 모두 고려\n",
    "# - 스케일에 민감하므로 정규화가 중요\n",
    "\n",
    "# similarity_search_with_relevance_scores는 코사인 유사도 기반으로\n",
    "# 0~1 사이로 정규화된 점수를 반환합니다 (1이 가장 유사)\n",
    "results = faiss_db.similarity_search_with_relevance_scores(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"\\n검색 결과 (관련성 점수 포함):\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 관련성 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\"  [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f13e6f6",
   "metadata": {},
   "source": [
    "`(4) 로컬에 저장 및 로드`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a781dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬에 저장\n",
    "faiss_db.save_local(\"faiss_ai_samaple_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "785ef1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬에 저장된 FAISS 벡터 저장소 불러오기\n",
    "# FAISS.load_local() 함수를 사용하여 로컬에 저장된 벡터 저장소를 불러옵니다.\n",
    "# \n",
    "# 파라미터:\n",
    "# - folder_path: 벡터 저장소가 저장된 로컬 폴더 경로 (예: \"faiss_ai_samaple_index\")\n",
    "# - embeddings: 임베딩 모델 객체 (텍스트를 벡터로 변환하는데 사용)\n",
    "# - allow_dangerous_deserialization: 직렬화된 객체의 안전하지 않은 역직렬화를 허용할지 여부 (기본값: False)\n",
    "#   - True로 설정하면 보안상 위험할 수 있으나, 저장된 모든 객체를 완전히 복원할 수 있음\n",
    "#   - False로 설정하면 안전하게 역직렬화하나 일부 기능이 제한될 수 있음\n",
    "#\n",
    "# 반환값:\n",
    "# - FAISS: 로드된 FAISS 벡터 저장소 객체\n",
    "\n",
    "faiss_db2 = FAISS.load_local(\n",
    "    # allow_dangerous_deserialization=True 설정은 보안상 위험할 수 있습니다.\n",
    "    # - 악의적인 코드가 포함된 직렬화된 객체를 역직렬화할 경우 시스템이 손상될 수 있음\n",
    "    # - 신뢰할 수 있는 소스의 데이터만 역직렬화하는 것이 안전\n",
    "    # - 개발 환경에서만 사용하고 프로덕션 환경에서는 False로 설정 권장\n",
    "    \"faiss_ai_samaple_index\", embeddings_model, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f2fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOC_1': Document(metadata={'source': 'AI_textbook', 'chapter': 'Chapter 1'}, page_content='인공지능은 컴퓨터 과학의 한 분야입니다.'),\n",
       " 'DOC_2': Document(metadata={'source': 'AI_textbook', 'chapter': 'Chapter 2'}, page_content='머신러닝은 인공지능의 하위 분야입니다.'),\n",
       " 'DOC_3': Document(metadata={'source': 'AI_textbook', 'chapter': 'Chapter 3'}, page_content='딥러닝은 머신러닝의 한 종류입니다.'),\n",
       " 'DOC_4': Document(metadata={'source': 'AI_textbook', 'chapter': 'Chapter 4'}, page_content='자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 문서 객체를 확인\n",
    "# 저장된 문서 객체를 딕셔너리 형태로 확인\n",
    "# docstore._dict는 내부 구현에 의존적이므로 권장되지 않음\n",
    "faiss_db2.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "985146b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝은 어떤 분야에서 사용되나요?\n",
      "\n",
      "검색 결과 (관련성 점수 포함):\n",
      "- 관련성 점수: 0.5392\n",
      "  내용: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "  [출처: AI_textbook, Chapter 3]\n",
      "\n",
      "- 관련성 점수: 0.4031\n",
      "  내용: 머신러닝은 인공지능의 하위 분야입니다.\n",
      "  [출처: AI_textbook, Chapter 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"딥러닝은 어떤 분야에서 사용되나요?\"\n",
    "results = faiss_db2.similarity_search_with_relevance_scores(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter={\"source\": \"AI_textbook\"}\n",
    ")\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"\\n검색 결과 (관련성 점수 포함):\")\n",
    "for doc, score in results:\n",
    "    print(f\"- 관련성 점수: {score:.4f}\")\n",
    "    print(f\"  내용: {doc.page_content}\")\n",
    "    print(f\"  [출처: {doc.metadata['source']}, {doc.metadata['chapter']}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1114cf",
   "metadata": {},
   "source": [
    "## 3. RAG 검색기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb386558",
   "metadata": {},
   "source": [
    "### 3.1 Semantic Search(의미론적 검색) \n",
    "- Vector Store 검색기 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e55d88",
   "metadata": {},
   "source": [
    "`(1) 벡터 저장소 초기화`\n",
    "- cosine distance 기준으로 인덱싱 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad15c9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문서 수: 8\n"
     ]
    }
   ],
   "source": [
    "# 문서 로딩을 위한 TextLoader 임포트\n",
    "from langchain_community.document_loaders import TextLoader  # 텍스트 파일을 로드하기 위한 도구\n",
    "\n",
    "# 텍스트 분할을 위한 CharacterTextSplitter 임포트 \n",
    "from langchain_text_splitters import CharacterTextSplitter  # 텍스트를 청크 단위로 분할하는 도구\n",
    "\n",
    "# Hugging Face 토크나이저 임포트\n",
    "from transformers import AutoTokenizer  # 텍스트를 토큰화하기 위한 Hugging Face의 자동 토크나이저\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "def load_text_files(txt_files):\n",
    "    data = []\n",
    "\n",
    "    for text_file in txt_files:\n",
    "        loader = TextLoader(text_file, encoding='utf-8')\n",
    "        data += loader.load()\n",
    "\n",
    "    return data\n",
    "\n",
    "korean_txt_files = glob(os.path.join('data', '*_KR.txt')) \n",
    "korean_data = load_text_files(korean_txt_files)\n",
    "\n",
    "\n",
    "# Hugging Face의 임베딩 모델이 사용한 토크나이저 지정 \n",
    "# AutoTokenizer.from_pretrained() 함수:\n",
    "# - 목적: Hugging Face의 사전 학습된 토크나이저를 로드\n",
    "# - 인자: \n",
    "#   - \"BAAI/bge-m3\": 사용할 토크나이저 모델의 이름\n",
    "# - 반환: 토크나이저 객체\n",
    "# - 기능: 텍스트를 토큰화하여 모델이 이해할 수 있는 형태로 변환\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "#from tiktoken import get_encoding\n",
    "# tokenizer = get_encoding(\"cl100k_base\")  # OpenAI의 gpt-4, text-embedding-ada-002 등에서 사용하는 토크나이저\n",
    "# 사용 예:\n",
    "# encoded = tokenizer.encode(\"안녕하세요\")  # 텍스트를 토큰으로 인코딩\n",
    "# decoded = tokenizer.decode(encoded)      # 토큰을 다시 텍스트로 디코딩\n",
    "# token_count = len(encoded)              # 토큰 수 계산\n",
    "\n",
    "\n",
    "\n",
    "# 문장을 구분하여 분할 (마침표, 느낌표, 물음표 다음에 공백이 오는 경우 문장의 끝으로 판단)\n",
    "# CharacterTextSplitter를 사용하여 텍스트를 청크 단위로 분할\n",
    "# 입력 파라미터:\n",
    "# - tokenizer: Hugging Face 토크나이저 객체 (텍스트를 토큰화하는데 사용)\n",
    "# - separator: 문장 구분자로 사용할 정규식 패턴 ([.!?] 뒤에 공백이 오는 경우)\n",
    "# - chunk_size: 각 청크의 최대 토큰 수 (100개로 제한)\n",
    "# - chunk_overlap: 청크 간 중복되는 토큰 수 (0으로 설정하여 중복 없음)\n",
    "# - is_separator_regex: separator가 정규식 패턴임을 나타내는 플래그\n",
    "# - keep_separator: 구분자를 청크에 포함할지 여부\n",
    "\n",
    "# 사용 목적:\n",
    "# 1. 긴 텍스트를 의미 있는 청크로 분할하여 벡터 저장소에 효율적으로 저장\n",
    "# 2. 문장 단위로 분할하여 의미적 일관성 유지\n",
    "# 3. 토큰 수 제한으로 임베딩 모델의 입력 제약 준수\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    separator=r\"[.!?]\\s+\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    "    is_separator_regex=True,\n",
    "    keep_separator=True,\n",
    ")\n",
    "\n",
    "korean_docs = text_splitter.split_documents(korean_data)\n",
    "\n",
    "print(\"한국어 문서 수:\", len(korean_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "783bdbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Hugging Face의 임베딩 모델 생성\n",
    "embeddings_huggingface = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "# Chroma 벡터 저장소 생성하기\n",
    "# Chroma 벡터 저장소 생성\n",
    "# 입력 파라미터:\n",
    "# - documents: 벡터화할 문서 리스트 (korean_docs)\n",
    "# - embedding: 문서를 벡터화할 임베딩 모델 (HuggingFace의 bge-m3 모델 사용)\n",
    "# - collection_name: 벡터 저장소의 컬렉션 이름 \n",
    "# - persist_directory: 벡터 DB를 저장할 디렉토리 경로\n",
    "# - collection_metadata: 벡터 유사도 계산 방식 설정\n",
    "#   - hnsw:space: 'cosine' (코사인 유사도), 'l2' (유클리디안 거리), 'ip' (내적) 중 선택\n",
    "\n",
    "# 사용 목적:\n",
    "# 1. 문서를 벡터화하여 Chroma DB에 저장\n",
    "# 2. 벡터 간 유사도 검색을 위한 인덱스 구축\n",
    "# 3. 영구 저장소에 벡터 DB 보관\n",
    "\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=korean_docs,\n",
    "    embedding=embeddings_huggingface,    # huggingface 임베딩 사용\n",
    "    collection_name=\"db_korean_cosine\", \n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata = {'hnsw:space': 'cosine'}, # l2, ip, cosine 중에서 선택 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd1b80",
   "metadata": {},
   "source": [
    "`(2) Top K`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "978859b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data/리비안_KR.txt]\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [출처: data/리비안_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ee428",
   "metadata": {},
   "source": [
    "`(3) 임계값 지정`\n",
    "- Similarity score threshold (기준 스코어 이상인 문서를 대상으로 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a8987f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [유사도: 0.6734]\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [유사도: 0.5955]\n"
     ]
    }
   ],
   "source": [
    "# langchain_community.utils.math 패키지에서 cosine_similarity 함수를 임포트\n",
    "# cosine_similarity: 두 벡터 간의 코사인 유사도를 계산하는 함수\n",
    "# - 입력: 두 개의 벡터 또는 벡터 배열\n",
    "# - 출력: -1 ~ 1 사이의 유사도 점수 (1에 가까울수록 유사)\n",
    "# - 용도: 문서 검색, 텍스트 유사도 비교 등에 활용\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "chroma_threshold_retriever = chroma_db.as_retriever(\n",
    "    search_type='similarity_score_threshold',       # 검색 방식: 유사도 점수 기반 필터링\n",
    "                                                   # - 문서와 쿼리 간의 유사도를 계산하여 일정 점수 이상인 문서만 추출\n",
    "                                                   # - 관련성이 높은 문서만을 선별적으로 검색하기 위해 사용\n",
    "    search_kwargs={\n",
    "        'score_threshold': 0.5,  # 유사도 점수 임계값 (0~1 사이)\n",
    "                                # - 0.5로 설정하면 쿼리와 50% 이상 유사한 문서만 추출\n",
    "                                # - 임계값이 높을수록 더 엄격한 필터링 (예: 0.8은 매우 유사한 문서만 추출)\n",
    "                                # - 검색 정확도와 검색 결과 수의 균형을 맞추기 위해 적절한 임계값 설정 필요\n",
    "        \n",
    "        'k': 2                   # 반환할 최대 문서 개수 \n",
    "                                # - 임계값을 넘는 문서들 중에서 상위 2개만 반환\n",
    "                                # - 너무 많은 검색 결과를 방지하고 가장 관련성 높은 문서만 선별\n",
    "                                # - 사용자에게 제공할 정보의 양을 제한하여 효율적인 검색 결과 제공\n",
    "    }\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_threshold_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    #  score = cosine_similarity(\n",
    "    #     [embeddings_model.embed_query(query)], \n",
    "    #     [embeddings_model.embed_query(doc.page_content)]\n",
    "    #     )[0][0]\n",
    "    # 쿼리와 문서 내용의 임베딩 벡터 간 코사인 유사도 계산\n",
    "    # 1. 쿼리 임베딩\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    # 2. 문서 임베딩 \n",
    "    doc_embedding = embeddings_model.embed_query(doc.page_content)\n",
    "\n",
    "\n",
    "    # 3. 코사인 유사도 계산 (2차원 배열로 변환 후 첫 번째 요소 추출)\n",
    "    # cosine_similarity 함수는 두 벡터 간의 코사인 유사도를 계산\n",
    "    # 입력 파라미터:\n",
    "    # - query_embedding: 쿼리 텍스트의 임베딩 벡터 (1차원 배열)\n",
    "    # - doc_embedding: 문서 텍스트의 임베딩 벡터 (1차원 배열)\n",
    "    # 동작:\n",
    "    # 1. [query_embedding], [doc_embedding]으로 각각을 2차원 배열로 변환 \n",
    "    # 2. 두 벡터 간 코사인 유사도 계산하여 2차원 배열 [[score]] 반환\n",
    "    # 3. [0][0] 인덱싱으로 실제 스코어값(float)을 추출\n",
    "    # 반환값: -1 ~ 1 사이의 유사도 점수 (1에 가까울수록 유사)\n",
    "\n",
    "    # 쿼리와 문서 간의 의미적 유사도를 수치화하여 검색 결과의 관련성을 평가\n",
    "    # - 높은 유사도 점수: 쿼리의 의도/주제와 문서 내용이 잘 일치함을 의미\n",
    "    # - 낮은 유사도 점수: 쿼리와 문서가 의미적으로 관련성이 낮음을 의미\n",
    "    # 이를 통해 사용자 질문에 가장 적절한 문서를 선별하고 검색 품질을 정량적으로 측정 가능\n",
    "    score = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "    \n",
    "    # 결과 출력 - 문서 내용과 유사도 점수\n",
    "    print(f\"- {doc.page_content} [유사도: {score:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d4655",
   "metadata": {},
   "source": [
    "`(4) MMR(Maximal Marginal Relevance) 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd230a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader([\"https://python.langchain.com/\", \"https://js.langchain.com/\"])\n",
    "\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "len(web_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader([\"https://python.langchain.com/\", \"https://js.langchain.com/\"])\n",
    "\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "len(web_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9dc086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader([\"https://python.langchain.com/\", \"https://js.langchain.com/\"])\n",
    "\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "len(web_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f258d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader([\"https://python.langchain.com/\", \"https://js.langchain.com/\"])\n",
    "\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "len(web_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38156a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_loader = WebBaseLoader([\"https://python.langchain.com/\", \"https://js.langchain.com/\"])\n",
    "\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "len(web_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ccc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [유사도: 0.6734]\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [유사도: 0.5955]\n",
      "- .\n",
      "\n",
      "리비안은 2021년 10월 첫 번째 양산 차량인 R1T 트럭을 고객에게 인도하기 시작했습니다. [유사도: 0.5690]\n"
     ]
    }
   ],
   "source": [
    "# MMR - 다양성 고려 (lambda_mult 작을수록 더 다양하게 추출)\n",
    "chroma_mmr = chroma_db.as_retriever(\n",
    "    # MMR(Maximal Marginal Relevance) 알고리즘은 검색 결과의 관련성과 다양성을 동시에 고려하는 검색 방식입니다.\n",
    "    # - 관련성: 쿼리와 문서 간의 유사도\n",
    "    # - 다양성: 검색된 문서들 간의 중복성을 최소화\n",
    "    # 목적:\n",
    "    # 1. 검색 결과의 다양성 확보\n",
    "    # 2. 중복되는 정보 제거\n",
    "    # 3. 포괄적인 정보 제공\n",
    "    # MMR 검색은 다음과 같은 경우에는 사용하지 않는 것이 좋습니다:\n",
    "    # 1. 검색 속도가 중요한 경우 - MMR은 추가 연산이 필요해 속도가 느림\n",
    "    # 2. 정확도가 가장 중요한 경우 - 다양성을 위해 관련성이 다소 떨어지는 결과도 포함될 수 있음\n",
    "    # 3. 검색 결과의 수가 매우 적은 경우 - 다양성을 고려할 필요가 없음\n",
    "    # 4. 실시간 처리가 필요한 경우 - 계산 비용이 높아 지연이 발생할 수 있음\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        'k': 3,                 # 최종적으로 반환할 문서의 수\n",
    "\n",
    "        # fetch_k는 선택적 파라미터입니다. \n",
    "        # 기본값은 k의 2배로 설정됩니다.\n",
    "        # 다양성을 더 확보하고 싶다면 k보다 큰 값으로 명시적 설정이 필요합니다.\n",
    "        'fetch_k': 8,           # MMR 알고리즘이 처리할 후보 문서의 수 (k보다 커야 다양성 확보 가능)\n",
    "        \n",
    "        'lambda_mult': 0.5,     # 관련성과 다양성의 균형을 조절하는 파라미터\n",
    "                               # 1에 가까울수록 관련성 중시\n",
    "                               # 0에 가까울수록 다양성 중시\n",
    "                               # 0.5는 둘의 균형을 맞춤\n",
    "        },\n",
    ")\n",
    "\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_mmr.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    score = cosine_similarity(\n",
    "        [embeddings_model.embed_query(query)], \n",
    "        [embeddings_model.embed_query(doc.page_content)]\n",
    "        )[0][0]\n",
    "    print(f\"- {doc.page_content} [유사도: {score:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) metadata 필터링 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "994408c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data/리비안_KR.txt]\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [출처: data/리비안_KR.txt]\n",
      "- .\n",
      "\n",
      "리비안은 2021년 10월 첫 번째 양산 차량인 R1T 트럭을 고객에게 인도하기 시작했습니다. [출처: data/리비안_KR.txt]\n",
      "- . 리비안은 디젤 하이브리드 버전, 브라질 원메이크 시리즈를 위한 R1 GT 레이싱 버전, 4도어 세단 및 크로스오버 등 다양한 버전을 고려했습니다. 2011년에 프로토타입 해치백도 공개되었지만, R1과의 관계는 불명확합니다 [출처: data/리비안_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "# 문서 객체의 metadata를 이용한 필터링\n",
    "chrom_metadata = chroma_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        'filter': {'source': 'data/리비안_KR.txt'},\n",
    "        'k': 8, \n",
    "        }\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chrom_metadata.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275ac2c",
   "metadata": {},
   "source": [
    "`(6) page_content 본문 필터링 검색`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d282211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data/리비안_KR.txt]\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [출처: data/리비안_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "# page_content를 이용한 필터링\n",
    "chroma_content = chroma_db.as_retriever(\n",
    "    search_kwargs={\n",
    "        'k': 2,\n",
    "        'where_document': {'$contains': '리비안'},\n",
    "        }\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_content.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bd76e",
   "metadata": {},
   "source": [
    "### 3.2 Keyword Search(키워드 검색) \n",
    "- BM25 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb2182",
   "metadata": {},
   "source": [
    "`(1) BM25 검색기 생성`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd9088",
   "metadata": {},
   "source": [
    "- BM25: TF-IDF (Term Frequency-Inverse Document Frequency)의 확장된 버전\n",
    "- `rank_bm25` 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c2a2d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'metadatas', 'documents', 'uris', 'data', 'included'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터 저장소에 저정한 문서 객체를 로드하여 확인\n",
    "chroma_db.get().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc67b98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 8\n",
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색 결과:\n",
      "- .\n",
      "\n",
      "리비안은 2021년 10월 첫 번째 양산 차량인 R1T 트럭을 고객에게 인도하기 시작했습니다. [출처: data/리비안_KR.txt]\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data/리비안_KR.txt]\n",
      "- . 리비안은 디젤 하이브리드 버전, 브라질 원메이크 시리즈를 위한 R1 GT 레이싱 버전, 4도어 세단 및 크로스오버 등 다양한 버전을 고려했습니다. 2011년에 프로토타입 해치백도 공개되었지만, R1과의 관계는 불명확합니다 [출처: data/리비안_KR.txt]\n",
      "- . [출처: data/테슬라_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "# BM25 검색기 생성을 위해 문서 객체를 로드\n",
    "documents = chroma_db.get()[\"documents\"]\n",
    "metadatas = chroma_db.get()[\"metadatas\"]\n",
    "\n",
    "# Document 객체로 변환\n",
    "from langchain_core.documents import Document\n",
    "docs = [Document(page_content=content, metadata=meta) for content, meta in zip(documents, metadatas)]\n",
    "\n",
    "print(\"문서의 수:\" , len(docs))\n",
    "\n",
    "# BM25 검색기 생성\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "\n",
    "# BM25 검색기를 사용하여 검색\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "\n",
    "retrieved_docs = bm25_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df741945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['리비안은', '언제', '사업을', '시작했나요?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(7, 0.5782203609632524),\n",
       " (5, 0.5616794524521536),\n",
       " (3, 0.4308683105054156),\n",
       " (0, 0.0),\n",
       " (1, 0.0),\n",
       " (2, 0.0),\n",
       " (4, 0.0),\n",
       " (6, 0.0)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BM25 점수를 확인\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "tokenized_query = query.split()\n",
    "print(tokenized_query)\n",
    "\n",
    "doc_scores = bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "doc_scores_sorted = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)\n",
    "doc_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70a3e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안이 설립된 연도는?\n",
      "검색 결과:\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다 [출처: data/테슬라_KR.txt]\n",
      "- .\n",
      "\n",
      "리비안은 2021년 10월 첫 번째 양산 차량인 R1T 트럭을 고객에게 인도하기 시작했습니다. [출처: data/리비안_KR.txt]\n",
      "- . [출처: data/테슬라_KR.txt]\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data/리비안_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "# 같은 의미를 갖는 쿼리로 변경하여 대시 검색 \n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "retrieved_docs = bm25_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f5e11c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['리비안이', '설립된', '연도는?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1.5086146557386926),\n",
       " (0, 0.0),\n",
       " (2, 0.0),\n",
       " (3, 0.0),\n",
       " (4, 0.0),\n",
       " (5, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BM25 점수를 확인\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "tokenized_query = query.split()\n",
    "print(tokenized_query)\n",
    "\n",
    "doc_scores = bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "doc_scores_sorted = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)\n",
    "doc_scores_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d173899",
   "metadata": {},
   "source": [
    "`(2) kiwi 한국어 토크나이저`\n",
    "- `kiwipiepy` 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60fee22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안이 설립된 연도는?\n",
      "검색 결과:\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다 [출처: data/테슬라_KR.txt]\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data/리비안_KR.txt]\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다 [출처: data/테슬라_KR.txt]\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [출처: data/리비안_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "# 한국어 토크나이저를 사용하여 문장을 토큰화하는 함수\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "def bm25_process_func(text):\n",
    "    \"\"\"\n",
    "    BM25Retriever에서 사용할 전처리 함수\n",
    "    한국어 토크나이저를 사용하여 문장을 토큰화\n",
    "    :param text: 토큰화할 문장\n",
    "    :param kwii_model: Kiwi 객체 (from kiwipiepy import Kiwi 사용)\n",
    "    \"\"\"\n",
    "    kiwi_model = Kiwi()\n",
    "\n",
    "    kiwi_model.add_user_word('리비안', 'NNP')  # NNP: 고유명사\n",
    "    kiwi_model.add_user_word('테슬라', 'NNP')  # NNP: 고유명사\n",
    "\n",
    "    return [t.form for t in kiwi_model.tokenize(text)]\n",
    "\n",
    "\n",
    "# BM25Retriever 객체 생성\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    documents=docs,\n",
    "    preprocess_func=bm25_process_func,\n",
    "    )\n",
    "\n",
    "# 이전에 사용한 검색어를 입력하여 문서를 검색\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "retrieved_docs = bm25_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf000939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['리비안', '이', '설립', '되', 'ᆫ', '연도', '는', '?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 2.3579578398183014),\n",
       " (5, 2.039726152975322),\n",
       " (4, 1.4391924308060922),\n",
       " (0, 1.1066940406176984),\n",
       " (7, 0.8168622949775345),\n",
       " (3, 0.7815426133191743),\n",
       " (2, 0.2789860806919751),\n",
       " (6, 0.0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BM25 점수를 확인\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "kiwi_model = Kiwi()\n",
    "\n",
    "kiwi_model.add_user_word('리비안', 'NNP')  # NNP: 고유명사\n",
    "kiwi_model.add_user_word('테슬라', 'NNP')  # NNP: 고유명사\n",
    "\n",
    "tokenized_query = [t.form for t in kiwi_model.tokenize(query)]\n",
    "print(tokenized_query)\n",
    "\n",
    "doc_scores = bm25_retriever.vectorizer.get_scores(tokenized_query)\n",
    "doc_scores_sorted = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)\n",
    "doc_scores_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afab2ed",
   "metadata": {},
   "source": [
    "### 3.3 Hybrid Search \n",
    "- 키워드 기반 검색과 시맨틱 검색을 결합하여 보다 정확하고 관련성 높은 결과를 제공하는 방법\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb4e26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안이 설립된 연도는?\n",
      "검색 결과:\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data/리비안_KR.txt]\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [출처: data/리비안_KR.txt]\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다 [출처: data/테슬라_KR.txt]\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다 [출처: data/테슬라_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retrievers = [chroma_threshold_retriever, bm25_retriever]\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=ensemble_retrievers, \n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "query = \"리비안이 설립된 연도는?\"\n",
    "\n",
    "retrieved_docs = ensemble_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333ae4d",
   "metadata": {},
   "source": [
    "## 4. 검색 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1264f7",
   "metadata": {},
   "source": [
    "### 4-1 테스트 데이터\n",
    "\n",
    "- QA 데이터셋 합성\n",
    "- 합성 데이터에 대한 검증 및 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d747cf",
   "metadata": {},
   "source": [
    "`(1) 데이터 준비`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2df397a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/리비안_KR.txt'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73092e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'리비안'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meatadata에서 정보 추출 -> 문서 본문에 추가\n",
    "os.path.split(docs[0].metadata['source'])[1].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d24dadb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)\n",
      "--------------------------------------------------\n",
      "{'source': 'data/리비안_KR.txt', 'doc_id': 0}\n",
      "==================================================\n",
      "\n",
      "테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.)\n",
      "--------------------------------------------------\n",
      "{'source': 'data/테슬라_KR.txt', 'doc_id': 1}\n",
      "==================================================\n",
      "\n",
      ".\n",
      "\n",
      "2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 세계 전기차 시장의 약 12.9%를 차지했습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.)\n",
      "--------------------------------------------------\n",
      "{'source': 'data/테슬라_KR.txt', 'doc_id': 2}\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    new_doc = doc.copy()\n",
    "    # metadata에 doc id를 추가\n",
    "    new_doc.metadata['doc_id'] = i\n",
    "    # 문장 구분 기호를 줄바꿈 문자로 변경\n",
    "    new_doc.page_content = str(new_doc.page_content).replace(\"[.!?]\\\\s+\", \"\\n\")\n",
    "    # metadata에서 정보를 추출하여 page_content에 추가\n",
    "    corp_name = str(os.path.split(new_doc.metadata['source'])[1].split('_')[0])\n",
    "    new_doc.page_content = f\"{new_doc.page_content}\\n\\n(참고: 이 문서는 {corp_name}에 대한 정보를 담고 있습니다.)\"\n",
    "    final_docs.append(new_doc)\n",
    "\n",
    "\n",
    "# 각 문서를 출력\n",
    "for doc in final_docs[:3]:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(doc.metadata)\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b84daf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 저장\n",
    "import json\n",
    "with open('./data/final_docs_ver2.jsonl', 'wb') as f:\n",
    "    for doc in final_docs:\n",
    "        f.write(json.dumps(dict(doc)).encode('utf-8'))\n",
    "        f.write(b'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94e32134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 8\n",
      "--------------------------------------------------\n",
      ".\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)\n",
      "--------------------------------------------------\n",
      "{'source': 'data/리비안_KR.txt', 'doc_id': 0}\n",
      "==================================================\n",
      "\n",
      "테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.)\n",
      "--------------------------------------------------\n",
      "{'source': 'data/테슬라_KR.txt', 'doc_id': 1}\n",
      "==================================================\n",
      "\n",
      ".\n",
      "\n",
      "2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 세계 전기차 시장의 약 12.9%를 차지했습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.)\n",
      "--------------------------------------------------\n",
      "{'source': 'data/테슬라_KR.txt', 'doc_id': 2}\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JSONL 파일 로드하기\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata = record.get(\"metadata\")\n",
    "    return metadata\n",
    "\n",
    "json_loader = JSONLoader(\n",
    "    file_path=\"./data/final_docs_ver2.jsonl\",\n",
    "    jq_schema=\".\",\n",
    "    content_key=\"page_content\",\n",
    "    json_lines=True,\n",
    "    metadata_func=metadata_func,\n",
    ")\n",
    "\n",
    "json_docs = json_loader.load()\n",
    "\n",
    "print(\"문서의 수:\", len(json_docs))\n",
    "print(\"-\" * 50)\n",
    "for doc in json_docs[:3]:\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)\n",
    "    print(doc.metadata)\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b8da900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌...</td>\n",
       "      <td>data/리비안_KR.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차...</td>\n",
       "      <td>data/테슬라_KR.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\n\\n2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해...</td>\n",
       "      <td>data/테슬라_KR.txt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. 리비안은 디젤 하이브리드 버전, 브라질 원메이크 시리즈를 위한 R1 GT 레이싱...</td>\n",
       "      <td>data/리비안_KR.txt</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>. 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이...</td>\n",
       "      <td>data/테슬라_KR.txt</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context               source  \\\n",
       "0  .\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌...  data/리비안_KR.txt   \n",
       "1  테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차...  data/테슬라_KR.txt   \n",
       "2  .\\n\\n2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해...  data/테슬라_KR.txt   \n",
       "3  . 리비안은 디젤 하이브리드 버전, 브라질 원메이크 시리즈를 위한 R1 GT 레이싱...  data/리비안_KR.txt   \n",
       "4  . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이...  data/테슬라_KR.txt   \n",
       "\n",
       "  doc_id  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임으로 변환\n",
    "import pandas as pd\n",
    "\n",
    "test_data = []\n",
    "for doc in json_docs:\n",
    "    test_data.append({\n",
    "        'context': str(doc.page_content),\n",
    "        'source': str(doc.metadata.get('source', '')),\n",
    "        'doc_id': str(doc.metadata.get('doc_id', '')),\n",
    "    })\n",
    "\n",
    "df_test = pd.DataFrame(test_data)\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac00e5",
   "metadata": {},
   "source": [
    "`(2) question - answer 합성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b60b78ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컨텍스트: .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)\n",
      "\n",
      "생성된 QA 쌍:\n",
      "질문: 리비안의 초기 모델은 무엇인가요?\n",
      "답변: 리비안의 초기 모델은 스포츠카 R1입니다.\n",
      "\n",
      "질문: 스포츠카 R1의 디자인은 누구에 의해 이루어졌나요?\n",
      "답변: 스포츠카 R1의 디자인은 피터 스티븐스에 의해 이루어졌습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# 질문-답변 쌍을 위한 Pydantic 모델 정의\n",
    "class QAPair(BaseModel):\n",
    "    \"\"\" 질문-답변 Pair\"\"\"\n",
    "    question: str = Field(description=\"생성된 질문 (write your question in KOREAN)\")\n",
    "    answer: str = Field(description=\"질문에 대한 답변 (write the answer to the fact-based question in KOREAN, making sure it reflects the essence of the question)\")\n",
    "\n",
    "class QASet(BaseModel):\n",
    "    qa_pairs: List[QAPair] = Field(description=\"질문-답변 Pair의 리스트\")\n",
    "\n",
    "\n",
    "# QA 생성 템플릿\n",
    "QA_generation_template = \"\"\"\n",
    "Your task is to create {num_questions_per_chunk} fact-based question-answer pairs based on the provided context.\n",
    "Each fact-based question should be answerable with a specific, concise piece of factual information from the context.\n",
    "Formulate your questions in the style that users might use when asking a search engine.\n",
    "Avoid including phrases like \"according to the passage\" or \"based on the context\" in your questions.\n",
    "Ensure that the answer includes the essence of the question to provide clear and complete information.\n",
    "\n",
    "---------------------------------------------------------\n",
    "Provide your output in the following format:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "---------------------------------------------------------\n",
    "이제 컨텍스트를 제공합니다:\n",
    "\n",
    "컨텍스트: {context}\n",
    "\"\"\"\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "qa_generator = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# Pydantic 출력 파서 설정\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=QASet)\n",
    "\n",
    "# QA 생성 프롬프트 템플릿 생성\n",
    "QA_generation_prompt = ChatPromptTemplate.from_template(\n",
    "    template=QA_generation_template,\n",
    "    partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# QA 생성 체인 구성\n",
    "QA_generate_chain = QA_generation_prompt | qa_generator | pydantic_parser\n",
    "\n",
    "# 테스트 데이터셋 생성 함수\n",
    "def generate_qa_dataset(context: str, num_questions: int) -> QASet:\n",
    "    response = QA_generate_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"num_questions_per_chunk\": num_questions\n",
    "    })\n",
    "    return response\n",
    "\n",
    "\n",
    "# QA 생성 테스트\n",
    "test_context = df_test['context'][0]\n",
    "print(\"컨텍스트:\", test_context)\n",
    "print()\n",
    "\n",
    "qa_set = generate_qa_dataset(test_context, 2)\n",
    "print(\"생성된 QA 쌍:\")\n",
    "for qa_pair in qa_set.qa_pairs:\n",
    "    print(f\"질문: {qa_pair.question}\")\n",
    "    print(f\"답변: {qa_pair.answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "499c927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 ...</td>\n",
       "      <td>[data/리비안_KR.txt]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>리비안의 초기 모델은 무엇인가요?</td>\n",
       "      <td>리비안의 초기 모델은 스포츠카 R1입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 ...</td>\n",
       "      <td>[data/리비안_KR.txt]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>R1의 좌석 구성은 어떻게 되나요?</td>\n",
       "      <td>R1은 2+2 좌석 구성입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 ...</td>\n",
       "      <td>[data/리비안_KR.txt]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>R1은 어떤 구조를 특징으로 하나요?</td>\n",
       "      <td>R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기...</td>\n",
       "      <td>[data/테슬라_KR.txt]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>테슬라는 어디에 본사를 두고 있나요?</td>\n",
       "      <td>테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기...</td>\n",
       "      <td>[data/테슬라_KR.txt]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>테슬라는 언제 설립되었나요?</td>\n",
       "      <td>테슬라는 2003년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context                 source  \\\n",
       "0  [.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 ...  [data/리비안_KR.txt]   \n",
       "1  [.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 ...  [data/리비안_KR.txt]   \n",
       "2  [.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 ...  [data/리비안_KR.txt]   \n",
       "3  [테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기...  [data/테슬라_KR.txt]   \n",
       "4  [테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기...  [data/테슬라_KR.txt]   \n",
       "\n",
       "  doc_id              question                                        answer  \n",
       "0    [0]    리비안의 초기 모델은 무엇인가요?                       리비안의 초기 모델은 스포츠카 R1입니다.  \n",
       "1    [0]   R1의 좌석 구성은 어떻게 되나요?                             R1은 2+2 좌석 구성입니다.  \n",
       "2    [0]  R1은 어떤 구조를 특징으로 하나요?  R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.  \n",
       "3    [1]  테슬라는 어디에 본사를 두고 있나요?                   테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.  \n",
       "4    [1]       테슬라는 언제 설립되었나요?                          테슬라는 2003년에 설립되었습니다.  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문서에 대해 QA 생성 - Chunk 당 3개의 질문-답변 쌍 생성\n",
    "\n",
    "NUM_QUESTIONS_PER_CHUNK = 3\n",
    "outputs = []\n",
    "for row in df_test.iterrows():\n",
    "\n",
    "    qa_set = generate_qa_dataset(row[1]['context'], NUM_QUESTIONS_PER_CHUNK)\n",
    "\n",
    "    for qa_pair in qa_set.qa_pairs:\n",
    "        outputs.append({\n",
    "            'context': [row[1]['context']],\n",
    "            'source': [row[1]['source']],\n",
    "            'doc_id': [row[1]['doc_id']],\n",
    "            'question': qa_pair.question,\n",
    "            'answer': qa_pair.answer\n",
    "        })\n",
    "\n",
    "\n",
    "df_qa_test = pd.DataFrame(outputs)\n",
    "print(df_qa_test.shape)\n",
    "\n",
    "df_qa_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2ed12245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_test.to_excel(\"./data/qa_test.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f8c80",
   "metadata": {},
   "source": [
    "`(3) 테스트 데이터 검토 및 수정`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c29c92cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 5)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터셋에 대한 QA 생성 결과를 리뷰한 후 다시 로드\n",
    "df_qa_test = pd.read_excel(\"./data/qa_test_revised.xlsx\")\n",
    "df_qa_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c9541952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>리비안의 초기 모델은 무엇인가요?</td>\n",
       "      <td>리비안의 초기 모델은 스포츠카 R1입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1의 좌석 구성은 어떻게 되나요?</td>\n",
       "      <td>R1은 2+2 좌석 구성입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1은 어떤 구조를 특징으로 하나요?</td>\n",
       "      <td>R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 어디에 본사를 두고 있나요?</td>\n",
       "      <td>테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 언제 설립되었나요?</td>\n",
       "      <td>테슬라는 2003년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context                   source  \\\n",
       "0  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "1  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "2  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "3  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "4  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "\n",
       "  doc_id              question                                        answer  \n",
       "0  ['0']    리비안의 초기 모델은 무엇인가요?                       리비안의 초기 모델은 스포츠카 R1입니다.  \n",
       "1  ['0']   R1의 좌석 구성은 어떻게 되나요?                             R1은 2+2 좌석 구성입니다.  \n",
       "2  ['0']  R1은 어떤 구조를 특징으로 하나요?  R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.  \n",
       "3  ['1']  테슬라는 어디에 본사를 두고 있나요?                   테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.  \n",
       "4  ['1']       테슬라는 언제 설립되었나요?                          테슬라는 2003년에 설립되었습니다.  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef2263",
   "metadata": {},
   "source": [
    "### 4-2 Information Retrieval 평가지표\n",
    "\n",
    "- K-RAG 패키지 사용 (pip install krag)\n",
    "- Hit Rate, MRR, mAP@k, NDCG@k 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278557b",
   "metadata": {},
   "source": [
    "#### 1) 평가도구 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ec1f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 샘플 문서 데이터\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 각 쿼리에 대한 정답 문서 \n",
    "actual_docs = [\n",
    "    # Query 1\n",
    "    [\n",
    "        Document(metadata={'id': 1}, page_content='Doc_1'),\n",
    "    ],\n",
    "    # Query 2\n",
    "    [\n",
    "        Document(metadata={'id': 2}, page_content='Doc_2'),\n",
    "        Document(metadata={'id': 5}, page_content='Doc_5'),\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "# 각 쿼리에 대한 검색 결과 \n",
    "predicted_docs = [\n",
    "    # Query 1\n",
    "    [\n",
    "        Document(metadata={'id': 1}, page_content='Doc_1'),\n",
    "        Document(metadata={'id': 5}, page_content='Doc_5'),\n",
    "    ],\n",
    "\n",
    "    # Query 2\n",
    "    [\n",
    "        Document(metadata={'id': 4}, page_content='Doc_4'),\n",
    "        Document(metadata={'id': 1}, page_content='Doc_1'),\n",
    "        Document(metadata={'id': 5}, page_content='Doc_5'),\n",
    "        Document(metadata={'id': 2}, page_content='Doc_2'),\n",
    "        Document(metadata={'id': 3}, page_content='Doc_3'),\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cfceec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 섬플 데이터로 평가 (2개의 쿼리에 대한 검색 결과)\n",
    "from krag.evaluators import OfflineRetrievalEvaluators\n",
    "\n",
    "# 평가자 인스턴스 생성\n",
    "evaluator = OfflineRetrievalEvaluators(\n",
    "    actual_docs=actual_docs,\n",
    "    predicted_docs=predicted_docs,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5469c",
   "metadata": {},
   "source": [
    "`(1) Hit Rate`\n",
    "- 각 쿼리에 대한 검색 문서 중에 실제 정답 문서가 포함되어 있으면 1, 그렇지 않으면 0으로 계산\n",
    "- 전체 검색 쿼리에 대해서 평가를 진행하고 평균을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "28d1eb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 방법 (k=1)\n",
    "(1 + 0) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a992374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 방법 (k=2)\n",
    "(1 + 0) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0b18655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 방법 (k=3)\n",
    "(1 + 0) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5bd7c9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 방법 (k=4) -> 2번째 쿼리에 대해서 4개의 문서를 검색했을 때 정답이 모두 포함되어 있음\n",
    "(1 + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "654b42cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate @1: 0.500\n",
      "Hit Rate @2: 0.500\n",
      "Hit Rate @3: 0.500\n",
      "Hit Rate @4: 1.000\n",
      "Hit Rate @5: 1.000\n"
     ]
    }
   ],
   "source": [
    "# 'Hit Rate' 계산\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "for k in k_values:\n",
    "    hit_rate = evaluator.calculate_hit_rate(k=k)\n",
    "    print(f\"Hit Rate @{k}: {hit_rate['hit_rate']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c30fa",
   "metadata": {},
   "source": [
    "`(2) MRR (Mean Reciprocal Rank)`\n",
    "- 각 쿼리에 대해서 관련 문서가 처음 반환된 순위의 역수를 계산한 후 그 평균을 구하는 방법\n",
    "- MRR은 사용자가 원하는 결과를 얼마나 빨리 찾을 수 있는지를 평가 (순서를 고려)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea566407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 방법 (k=1)\n",
    "(1/1 + 0/1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8083e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 방법 (k=3) -> 2번째 쿼리에 대해서 3번째 검색 문서가 관련 문서임 (첫 번째 정답만 고려) \n",
    "(1/1 + 1/3) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "650d7eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR @1: 0.500\n",
      "MRR @2: 0.500\n",
      "MRR @3: 0.667\n",
      "MRR @4: 0.667\n",
      "MRR @5: 0.667\n"
     ]
    }
   ],
   "source": [
    "# 'Mean Reciprocal Rank' 계산\n",
    "for k in k_values:\n",
    "    mrr = evaluator.calculate_mrr(k=k)\n",
    "    print(f\"MRR @{k}: {mrr['mrr']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86dec2",
   "metadata": {},
   "source": [
    "`(3) mAP@k`\n",
    "- mAP@k (Mean Average Precision at k)는 검색 결과의 평균 정밀도(AP, Average Precision)를 측정하는 지표\n",
    "- 각 쿼리에 대한 평균 정밀도를 계산하고, 이들의 평균을 계산 (특히 k개의 상위 예측 문서 내에서 측정)\n",
    "- 검색된 결과의 순서가 중요. 관련 문서가 상위에 있을수록 높은 정밀도를 획득\n",
    "- 상위 k개의 결과에 집중하여 평가하므로, 사용자에게 우선적으로 보여지는 결과의 품질을 반영"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833e5a9",
   "metadata": {},
   "source": [
    "- mAP@3 계산 과정:\n",
    "\n",
    "   1. 쿼리 1에 대한 AP@3 계산:\n",
    "      * 예측 결과: [Doc_1, Doc_5]\n",
    "      * 실제 정답: [Doc_1]\n",
    "      * Precision@1 = 1/1 = 1 (첫 번째 문서가 정답)\n",
    "      * AP@3 = 1/1 = 1 (정답 문서가 첫 번째 위치에 있음)\n",
    "\n",
    "   2. 쿼리 2에 대한 AP@3 계산:\n",
    "      * 예측 결과: [Doc_4, Doc_1, Doc_5]\n",
    "      * 실제 정답: [Doc_2, Doc_5]\n",
    "      * Precision@1 = 0/1 = 0 (첫 번째 문서가 정답이 아님)\n",
    "      * Precision@2 = 0/2 = 0 (두 번째 문서도 정답이 아님)\n",
    "      * Precision@3 = 1/3 (세 번째 문서가 정답)\n",
    "      * AP@3 = (0 + 0 + 1/3) / 2 = 1/6 ≈ 0.1667\n",
    "      (정답 문서 중 하나만 상위 3개 안에 있고, 그 위치에서의 정밀도를 정답 문서 수로 나눔)\n",
    "\n",
    "   3. mAP@3 계산:\n",
    "      mAP@3 = (AP@3_쿼리1 + AP@3_쿼리2) / 2\n",
    "            = (1 + 0.1667) / 2\n",
    "            ≈ 0.5833\n",
    "   \n",
    "- 설명:\n",
    "   - AP@k는 각 정답 문서의 위치(순서)에서의 정밀도를 합산한 후, 정답 문서의 총 개수로 나눕니다.\n",
    "   - 쿼리 1의 경우, 유일한 정답 문서가 첫 번째 위치에 있어 완벽한 점수를 얻었습니다.\n",
    "   - 쿼리 2의 경우, 두 개의 정답 문서 중 하나만 상위 3개 안에 포함되어 있어 낮은 점수를 받았습니다.\n",
    "   - mAP@3은 이 두 쿼리의 AP@3 값의 평균입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "24fb9e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@1: 0.500\n",
      "mAP@2: 0.500\n",
      "mAP@3: 0.583\n",
      "mAP@4: 0.708\n",
      "mAP@5: 0.708\n"
     ]
    }
   ],
   "source": [
    "# mAP 계산\n",
    "for k in k_values:\n",
    "    map_score = evaluator.calculate_map(k=k)\n",
    "    print(f\"mAP@{k}: {map_score['map']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce1691",
   "metadata": {},
   "source": [
    "`(4) NDCG`\n",
    "- NDCG(Normalized Discounted Cumulative Gain)는 추천 시스템에서 결과의 순서가 얼마나 잘 맞는지를 평가하는 지표\n",
    "- 각 문서의 순위에 따라 가중치를 부여하여 순위가 높은 관련 문서가 더 큰 영향을 주는 것으로 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41a4dd",
   "metadata": {},
   "source": [
    "- NDCG@3 계산 과정: 이진 관련성(0 또는 1)을 사용\n",
    "\n",
    "   1. 쿼리 1:\n",
    "      - 예측 결과: [Doc_1, Doc_5]\n",
    "      - 실제 정답: [Doc_1]\n",
    "      - 관련성 점수: [1, 0]\n",
    "      - 이상적인 관련성 점수: [1, 0] (정답 문서가 하나만 있으므로)\n",
    "      - DCG = (2^1 - 1) / log2(2) = 1\n",
    "      - IDCG = (2^1 - 1) / log2(2) = 1\n",
    "      - NDCG = 1 / 1 = 1\n",
    "\n",
    "   2. 쿼리 2:\n",
    "      - 예측 결과: [Doc_4, Doc_1, Doc_5]\n",
    "      - 실제 정답: [Doc_2, Doc_5]\n",
    "      - 관련성 점수: [0, 0, 1]\n",
    "      - 이상적인 관련성 점수: [1, 0, 0] (정답 문서가 하나만 있으므로)\n",
    "      - DCG = (2^0 - 1) / log2(2) + (2^0 - 1) / log2(3) + (2^1 - 1) / log2(4) = 0.5\n",
    "      - IDCG = (2^1 - 1) / log2(2) + (2^0 - 1) / log2(3) + (2^0 - 1) / log2(4) = 1\n",
    "      - NDCG = 0.5 / 1 = 0.5\n",
    "\n",
    "   3. 평균 NDCG:\n",
    "      (1 + 0.5) / 2 = 0.75\n",
    "\n",
    "- 설명:\n",
    "   - 쿼리 1에 대해서는 완벽한 순위를 보여줍니다 (NDCG = 1).\n",
    "   - 쿼리 2에 대해서는 관련 문서가 상위 3개 안에 포함되어 있지만, 최적의 위치(첫 번째)는 아니라는 것을 반영 (NDCG = 0.5)\n",
    "   - 0.75라는 최종 점수는 시스템이 전반적으로 양호한 성능을 보이고 있음을 나타냄. 완벽하지는 않지만, 관련 문서를 상위 순위에 배치하는 데 어느 정도 성공하고 있음을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0dc8659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG @1: 0.500\n",
      "NDCG @2: 0.500\n",
      "NDCG @3: 0.750\n",
      "NDCG @4: 0.785\n",
      "NDCG @5: 0.785\n"
     ]
    }
   ],
   "source": [
    "for k in k_values:\n",
    "    ndcg = evaluator.calculate_ndcg(k=k)\n",
    "    print(f\"NDCG @{k}: {ndcg['ndcg']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c3884",
   "metadata": {},
   "source": [
    "- NDCG, mAP, MRR 비교\n",
    "    - 목적:\n",
    "        - NDCG는 전체 검색 결과의 순서와 관련성에 대한 정확도를 평가. 특히, 관련 문서가 상위에 위치할수록 높은 점수.\n",
    "        - mAP는 상위 k개의 검색 결과에서 정밀도를 평가하여 관련 문서의 반환 정확성을 측정.\n",
    "        - MRR은 첫 번째 관련 문서가 얼마나 빨리 나타나는지를 평가.\n",
    "\n",
    "    - 특징:\n",
    "        - NDCG는 순위에 따라 가중치를 부여하며, 순서에 따라 문서의 중요도가 감소하도록 설계.\n",
    "        - mAP는 순서에 따른 가중치를 부여하지 않고, 각 쿼리의 정밀도 평균을 계산.\n",
    "        - MRR은 첫 번째 관련 문서의 순위에 집중하며, 그 이후의 문서 순위는 고려하지 않음.\n",
    "\n",
    "    - 적용 분야:\n",
    "        - NDCG는 검색 결과의 전반적인 순서가 중요한 상황에 적합\n",
    "        - mAP는 검색된 문서들이 얼마나 잘 맞는지를 종합적으로 평가할 때 사용\n",
    "        - MRR은 사용자가 원하는 정보를 얼마나 빨리 찾는지를 평가할 때 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4201213",
   "metadata": {},
   "source": [
    "#### 2) 테스트 데이터셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "37c1b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>리비안의 초기 모델은 무엇인가요?</td>\n",
       "      <td>리비안의 초기 모델은 스포츠카 R1입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1의 좌석 구성은 어떻게 되나요?</td>\n",
       "      <td>R1은 2+2 좌석 구성입니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context                   source  \\\n",
       "0  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "1  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "\n",
       "  doc_id             question                   answer  \n",
       "0  ['0']   리비안의 초기 모델은 무엇인가요?  리비안의 초기 모델은 스포츠카 R1입니다.  \n",
       "1  ['0']  R1의 좌석 구성은 어떻게 되나요?        R1은 2+2 좌석 구성입니다.  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c2c15617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 행의 컨텍스트 데이터:\n",
      "['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\\n\\n(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)']\n",
      "--------------------------------------------------\n",
      "\n",
      "첫 번째 행의 컨텍스트 문서 객체:\n",
      ".\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)\n",
      "{'source': 'data/리비안_KR.txt', 'doc_id': '0'}\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋의 특정 행에 있는 컨텍스트 데이터를 Document 객체 리스트로 변환\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def context_to_document(df_test: pd.DataFrame, idx: int) -> List[Document]:\n",
    "    \"\"\"\n",
    "    테스트 데이터셋의 특정 행에 있는 컨텍스트 데이터를 Document 객체 리스트로 변환\n",
    "    \"\"\"\n",
    "\n",
    "    context = eval(df_test['context'].iloc[idx])\n",
    "    source = eval(df_test['source'].iloc[idx])\n",
    "    doc_id = eval(df_test['doc_id'].iloc[idx])\n",
    "\n",
    "    context_docs = []\n",
    "    for c, s, d in zip(context, source, doc_id):\n",
    "        doc = Document(page_content=c, metadata={'source': s, 'doc_id': d})\n",
    "        context_docs.append(doc)\n",
    "\n",
    "    return context_docs\n",
    "\n",
    "#  0번 행의 테스트 데이터를 문서 객체로 변환\n",
    "print(\"첫 번째 행의 컨텍스트 데이터:\") \n",
    "print(df_qa_test['context'].iloc[0])\n",
    "print(\"-\" * 50)\n",
    "print()\n",
    "\n",
    "context_docs = context_to_document(df_qa_test, 0)\n",
    "print(\"첫 번째 행의 컨텍스트 문서 객체:\")\n",
    "print(context_docs[0].page_content) \n",
    "print(context_docs[0].metadata)\n",
    "print(\"=\" * 50)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e776459",
   "metadata": {},
   "source": [
    "`- Kiwi 토크나이저 + BM25 검색기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7becfba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from krag.tokenizers import KiwiTokenizer\n",
    "from krag.retrievers import KiWiBM25RetrieverWithScore\n",
    "\n",
    "# BM25 검색기 초기화 (k=5)\n",
    "retriever_bm25_kiwi = KiWiBM25RetrieverWithScore(\n",
    "    documents=final_docs, \n",
    "    kiwi_tokenizer=KiwiTokenizer(model_type='knlm', typos='basic'), \n",
    "    k=5, \n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5a356fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 리비안의 초기 모델은 무엇인가요?\n",
      "==============================================\n",
      "관련 문서: ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\\n\\n(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)']\n",
      "==============================================\n",
      "4.418403726253867\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: data/리비안_KR.txt, doc_id: 0]\n",
      "------------------------------\n",
      "3.4940325225324993\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: data/리비안_KR.txt, doc_id: 5]\n",
      "------------------------------\n",
      "1.551364854060795\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: data/테슬라_KR.txt, doc_id: 4]\n",
      "------------------------------\n",
      "1.3854513147996235\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: data/테슬라_KR.txt, doc_id: 1]\n",
      "------------------------------\n",
      "1.2815842740284276\n",
      "- .\n",
      "\n",
      "2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 세계 전기차 시장의 약 12.9%를 차지했습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: data/테슬라_KR.txt, doc_id: 2]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# BM25 검색기를 사용하여 문서 검색\n",
    "question = df_qa_test['question'].iloc[0]\n",
    "print(\"질문:\", question)\n",
    "print(\"==============================================\")\n",
    "context = df_qa_test['context'].iloc[0]\n",
    "print(\"관련 문서:\", context)\n",
    "print(\"==============================================\")\n",
    "\n",
    "# BM25 검색\n",
    "retrieved_docs = retriever_bm25_kiwi.invoke(question)\n",
    "\n",
    "# 검색 결과 출력 \n",
    "for doc in retrieved_docs:\n",
    "    print(doc.metadata[\"bm25_score\"])    \n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}, doc_id: {doc.metadata['doc_id']}]\")\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d25757a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 테스트 데이터셋에 대하여 평가지표 계산\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "def evaluate_qa_test(df_qa_test: pd.DataFrame, retriever: BaseRetriever, k=2) -> dict:\n",
    "    \"\"\"\n",
    "    테스트 데이터셋에 대한 검색 결과 평가\n",
    "    \"\"\"\n",
    "\n",
    "    context_docs = []\n",
    "    retrieved_docs = []\n",
    "\n",
    "    df_test = df_qa_test.copy()\n",
    "    \n",
    "    for idx, _ in df_test.iterrows():\n",
    "        question = df_test['question'].iloc[idx]\n",
    "        context_doc = context_to_document(df_test, idx)\n",
    "        context_docs.append(context_doc)\n",
    "        retrieved_doc = retriever.invoke(question)  \n",
    "        retrieved_docs.append(retrieved_doc)  \n",
    "\n",
    "\n",
    "    # 평가자 인스턴스 생성\n",
    "    evaluator = OfflineRetrievalEvaluators(\n",
    "        actual_docs=context_docs,\n",
    "        predicted_docs=retrieved_docs,      \n",
    "    )\n",
    "\n",
    "\n",
    "    # 평가지표 계산\n",
    "    hit_rate = evaluator.calculate_hit_rate(k=k)['hit_rate']\n",
    "    mrr = evaluator.calculate_mrr(k=k)['mrr']\n",
    "    map_score = evaluator.calculate_map(k=k)['map']\n",
    "    ndcg = evaluator.calculate_ndcg(k=k)['ndcg']\n",
    "\n",
    "    print(f\"K={k}\")\n",
    "    print(\"------------------------------------------------------------\")\n",
    "    print(f\"Hit Rate: {hit_rate:.3f}\")\n",
    "    print(f\"MRR: {mrr:.3f}\")\n",
    "    print(f\"MAP: {map_score:.3f}\")\n",
    "    print(f\"NDCG: {ndcg:.3f}\")\n",
    "    print(\"============================================================\")\n",
    "    print()\n",
    "\n",
    "    result = {\n",
    "        'hit_rate': hit_rate,\n",
    "        'mrr': mrr,\n",
    "        'map': map_score,\n",
    "        'ndcg': ndcg,\n",
    "        \n",
    "    }\n",
    "\n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fda3ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.875\n",
      "MRR: 0.875\n",
      "MAP: 0.875\n",
      "NDCG: 0.875\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (k=1)\n",
    "retriever_bm25_kiwi.k = 1\n",
    "result_bm25_k1 = evaluate_qa_test(df_qa_test, retriever_bm25_kiwi, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8420197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.875\n",
      "MRR: 0.875\n",
      "MAP: 0.875\n",
      "NDCG: 0.875\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (k=2)\n",
    "retriever_bm25_kiwi.k = 2\n",
    "result_bm25_k2 = evaluate_qa_test(df_qa_test, retriever_bm25_kiwi, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72792a",
   "metadata": {},
   "source": [
    "`- Chroma 벡터저장소 검색기`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7b5b49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어 로드\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=final_docs,\n",
    "    embedding=embeddings_model,\n",
    "    collection_name=\"hf_bge_m3\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "# Chroma 검색기 초기화\n",
    "retriever_chroma_hf = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "06da3159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.792\n",
      "MRR: 0.792\n",
      "MAP: 0.792\n",
      "NDCG: 0.792\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (k=1)\n",
    "result_chroma_hf_k1 = evaluate_qa_test(df_qa_test, retriever_chroma_hf, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2c2e3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.875\n",
      "MRR: 0.833\n",
      "MAP: 0.833\n",
      "NDCG: 0.844\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (k=2)\n",
    "result_chroma_hf_k2 = evaluate_qa_test(df_qa_test, retriever_chroma_hf, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0357c6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=3\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.875\n",
      "MRR: 0.833\n",
      "MAP: 0.833\n",
      "NDCG: 0.844\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (k=3)\n",
    "result_chroma_hf_k3 = evaluate_qa_test(df_qa_test, retriever_chroma_hf, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "04bad3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.833\n",
      "MRR: 0.833\n",
      "MAP: 0.833\n",
      "NDCG: 0.833\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_bm25_kiwi.k = 5\n",
    "ensemble_retrievers = [retriever_chroma_hf, retriever_bm25_kiwi]\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=ensemble_retrievers, \n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# 평가 (k=1)\n",
    "result_ensemble_k1 = evaluate_qa_test(df_qa_test, ensemble_retriever, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5191b377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2\n",
      "------------------------------------------------------------\n",
      "Hit Rate: 0.875\n",
      "MRR: 0.854\n",
      "MAP: 0.854\n",
      "NDCG: 0.860\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 (k=2)\n",
    "result_ensemble_k2 = evaluate_qa_test(df_qa_test, ensemble_retriever, k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
